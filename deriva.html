<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Deriva Genética | Introducción a la Genética de Poblaciones y a la Genética Cuantitativa</title>
  <meta name="description" content="Apuntes del curso Genética II. Contenido teórico mínimo para el seguimiento del curso" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Deriva Genética | Introducción a la Genética de Poblaciones y a la Genética Cuantitativa" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apuntes del curso Genética II. Contenido teórico mínimo para el seguimiento del curso" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Deriva Genética | Introducción a la Genética de Poblaciones y a la Genética Cuantitativa" />
  
  <meta name="twitter:description" content="Apuntes del curso Genética II. Contenido teórico mínimo para el seguimiento del curso" />
  

<meta name="author" content="Hugo Naya" />
<meta name="author" content="(Federica Marín)" />
<meta name="author" content="(Jorge Urioste, María André, Washington Bell, Ana Laura Sanchez)" />
<meta name="author" content="(Clara Pritsch, Paola Gaiero, Marianella Quezada)" />


<meta name="date" content="2022-02-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variación-y-equilibrio-de-hardy-weinberg.html"/>
<link rel="next" href="seleccion.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio (leer antes de arrancar)</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nuestra-filosofía-del-no-tanto"><i class="fa fa-check"></i>Nuestra filosofía del NO (tanto)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#qué-es-y-qué-no-es-este-libro"><i class="fa fa-check"></i>¿Qué ES y qué NO ES este libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bibliografía-recomendada-para-este-curso"><i class="fa fa-check"></i>Bibliografía recomendada para este curso</a></li>
</ul></li>
<li class="part"><span><b>Parte I: Genómica</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción a la Genómica</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#variabilidad-genética"><i class="fa fa-check"></i><b>1.1</b> Variabilidad genética</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#detectando-la-variabilidad-diferentes-técnicas"><i class="fa fa-check"></i><b>1.1.1</b> Detectando la variabilidad: diferentes técnicas</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#metagenómica-y-metatranscriptómica"><i class="fa fa-check"></i><b>1.1.2</b> Metagenómica y Metatranscriptómica</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#genómica-composicional"><i class="fa fa-check"></i><b>1.2</b> Genómica composicional</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#contenido-gc-genómico-génico-correlaciones-gcskew"><i class="fa fa-check"></i>Contenido GC genómico, génico, correlaciones, GCskew</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#uso-de-codones"><i class="fa fa-check"></i>Uso de codones</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#exploración-multivariada-análisis-de-correspondencia"><i class="fa fa-check"></i>Exploración multivariada: Análisis de Correspondencia</a></li>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#composición-de-proteínas"><i class="fa fa-check"></i><b>1.2.1</b> Composición de proteínas</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#diferencias-en-propiedades-de-los-aas"><i class="fa fa-check"></i>Diferencias en propiedades de los AAs</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#diferencias-de-composición-entre-clases-de-proteínas"><i class="fa fa-check"></i>Diferencias de composición entre clases de proteínas</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#genómica-comparativa"><i class="fa fa-check"></i><b>1.3</b> Genómica comparativa</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#comparación-de-secuencias-génicas"><i class="fa fa-check"></i>Comparación de secuencias génicas</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#selección-positiva"><i class="fa fa-check"></i>Selección Positiva</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#vías"><i class="fa fa-check"></i>Vías</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#genómica-funcional"><i class="fa fa-check"></i><b>1.4</b> Genómica funcional</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#estudios-epigenéticos-y-epigenómicos"><i class="fa fa-check"></i>Estudios epigenéticos y epigenómicos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#ejercicios-1"><i class="fa fa-check"></i>Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#ejercicio-1.1"><i class="fa fa-check"></i>Ejercicio 1.1</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Parte II: Genética de Poblaciones</b></span></li>
<li class="chapter" data-level="2" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html"><i class="fa fa-check"></i><b>2</b> Variación y equilibrio de Hardy-Weinberg</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#el-equilibrio-de-hardy-weinberg"><i class="fa fa-check"></i><b>2.1</b> El equilibrio de Hardy-Weinberg</a>
<ul>
<li class="chapter" data-level="" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#supuestos-que-asumimos-se-cumplen-para-h-w"><i class="fa fa-check"></i>Supuestos que asumimos se cumplen para H-W</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#hardy-weinberg-en-especies-dioicas-dos-sexos"><i class="fa fa-check"></i><b>2.2</b> Hardy-Weinberg en especies dioicas (dos sexos)</a></li>
<li class="chapter" data-level="2.3" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#h-w-la-frecuencia-de-heterocigotas-en-función-de-la-frecuencia-alélica"><i class="fa fa-check"></i><b>2.3</b> H-W: la frecuencia de heterocigotas en función de la frecuencia alélica</a></li>
<li class="chapter" data-level="2.4" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#el-equilibrio-de-hardy-weinberg-en-cromosomas-ligados-al-sexo"><i class="fa fa-check"></i><b>2.4</b> El equilibrio de Hardy-Weinberg en cromosomas ligados al sexo</a></li>
<li class="chapter" data-level="2.5" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#tres-o-más-alelos"><i class="fa fa-check"></i><b>2.5</b> Tres o más alelos</a></li>
<li class="chapter" data-level="2.6" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#la-estimación-de-frecuencias-y-el-equilibrio-o-no"><i class="fa fa-check"></i><b>2.6</b> La estimación de frecuencias y el equilibrio (o no)</a></li>
<li class="chapter" data-level="2.7" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#el-sistema-abo"><i class="fa fa-check"></i><b>2.7</b> El sistema ABO</a></li>
<li class="chapter" data-level="2.8" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#dónde-se-esconden-los-alelos-recesivos"><i class="fa fa-check"></i><b>2.8</b> ¿Dónde se “esconden” los alelos recesivos?</a></li>
<li class="chapter" data-level="2.9" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#hardy-weinberg-en-especies-poliploides"><i class="fa fa-check"></i><b>2.9</b> Hardy-Weinberg en especies poliploides</a></li>
<li class="chapter" data-level="2.10" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#geometría-y-genética-los-diagramas-de-de-finetti-para-cuando-estés-aburrido"><i class="fa fa-check"></i><b>2.10</b> <strong>Geometría y Genética: los diagramas de <em>de Finetti</em></strong> (para cuando estés aburrido)</a></li>
<li class="chapter" data-level="2.11" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#la-estimación-de-frecuencias-en-el-locus-abo-para-cuando-estés-muy-aburrido"><i class="fa fa-check"></i><b>2.11</b> <strong>La estimación de frecuencias en el locus ABO</strong> (para cuando estés MUY aburrido)</a></li>
<li class="chapter" data-level="" data-path="variación-y-equilibrio-de-hardy-weinberg.html"><a href="variación-y-equilibrio-de-hardy-weinberg.html#ejercicios-2"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="deriva.html"><a href="deriva.html"><i class="fa fa-check"></i><b>3</b> Deriva Genética</a>
<ul>
<li class="chapter" data-level="3.1" data-path="deriva.html"><a href="deriva.html#el-rol-de-los-procesos-estocásticos-en-la-genética"><i class="fa fa-check"></i><b>3.1</b> El rol de los procesos estocásticos en la genética</a></li>
<li class="chapter" data-level="3.2" data-path="deriva.html"><a href="deriva.html#el-modelo-de-wright-fisher"><i class="fa fa-check"></i><b>3.2</b> El modelo de Wright-Fisher</a></li>
<li class="chapter" data-level="3.3" data-path="deriva.html"><a href="deriva.html#el-rol-de-la-subdivisión-poblacional-en-la-evolución-de-las-frecuencias-alélicas"><i class="fa fa-check"></i><b>3.3</b> El rol de la subdivisión poblacional en la evolución de las frecuencias alélicas</a>
<ul>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#homocigosidad-y-heterocigosidad"><i class="fa fa-check"></i>Homocigosidad y Heterocigosidad</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="deriva.html"><a href="deriva.html#cadenas-de-markov"><i class="fa fa-check"></i><b>3.4</b> Cadenas de Markov</a></li>
<li class="chapter" data-level="3.5" data-path="deriva.html"><a href="deriva.html#tamaño-efectivo-poblacional"><i class="fa fa-check"></i><b>3.5</b> Tamaño efectivo poblacional</a></li>
<li class="chapter" data-level="3.6" data-path="deriva.html"><a href="deriva.html#aproximación-de-difusión"><i class="fa fa-check"></i><b>3.6</b> Aproximación de difusión</a>
<ul>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#caminatas-al-azar-y-procesos-de-difusión"><i class="fa fa-check"></i>Caminatas al azar y procesos de difusión</a></li>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#kolmogorov-forward-equation"><i class="fa fa-check"></i>Kolmogorov Forward Equation</a></li>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#kolmogorov-backward-equation"><i class="fa fa-check"></i>Kolmogorov Backward Equation</a></li>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#solución-de-las-ecuaciones"><i class="fa fa-check"></i>Solución de las ecuaciones</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="deriva.html"><a href="deriva.html#probabilidad-de-fijación-y-tiempos-de-fijación"><i class="fa fa-check"></i><b>3.7</b> Probabilidad de fijación y tiempos de fijación</a></li>
<li class="chapter" data-level="3.8" data-path="deriva.html"><a href="deriva.html#el-modelo-coalescente"><i class="fa fa-check"></i><b>3.8</b> El modelo coalescente</a></li>
<li class="chapter" data-level="" data-path="deriva.html"><a href="deriva.html#ejercicios-3"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="seleccion.html"><a href="seleccion.html"><i class="fa fa-check"></i><b>4</b> Selección Natural</a>
<ul>
<li class="chapter" data-level="4.1" data-path="seleccion.html"><a href="seleccion.html#el-concepto-de-fitness"><i class="fa fa-check"></i><b>4.1</b> El concepto de “fitness”</a></li>
<li class="chapter" data-level="4.2" data-path="seleccion.html"><a href="seleccion.html#selección-natural-en-el-modelo-de-un-locus-con-dos-alelos"><i class="fa fa-check"></i><b>4.2</b> Selección natural en el modelo de un locus con dos alelos</a></li>
<li class="chapter" data-level="4.3" data-path="seleccion.html"><a href="seleccion.html#diferentes-formas-de-selección"><i class="fa fa-check"></i><b>4.3</b> Diferentes formas de selección</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="seleccion.html"><a href="seleccion.html#selección-direccional"><i class="fa fa-check"></i><b>4.3.1</b> Selección direccional</a></li>
<li class="chapter" data-level="4.3.2" data-path="seleccion.html"><a href="seleccion.html#selección-estabilizadora"><i class="fa fa-check"></i><b>4.3.2</b> Selección estabilizadora</a></li>
<li class="chapter" data-level="4.3.3" data-path="seleccion.html"><a href="seleccion.html#selección-disruptiva"><i class="fa fa-check"></i><b>4.3.3</b> Selección disruptiva</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="seleccion.html"><a href="seleccion.html#el-teorema-fundamental-de-la-selección-natural"><i class="fa fa-check"></i><b>4.4</b> El teorema fundamental de la selección natural</a></li>
<li class="chapter" data-level="4.5" data-path="seleccion.html"><a href="seleccion.html#equilibrio-selección-mutación"><i class="fa fa-check"></i><b>4.5</b> Equilibrio selección-mutación</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="seleccion.html"><a href="seleccion.html#el-principio-de-haldane-muller"><i class="fa fa-check"></i><b>4.5.1</b> El principio de Haldane-Muller</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="seleccion.html"><a href="seleccion.html#la-fuerza-de-la-selección-natural"><i class="fa fa-check"></i><b>4.6</b> La fuerza de la selección natural</a></li>
<li class="chapter" data-level="4.7" data-path="seleccion.html"><a href="seleccion.html#equilibrio-selección-deriva"><i class="fa fa-check"></i><b>4.7</b> Equilibrio selección-deriva</a></li>
<li class="chapter" data-level="4.8" data-path="seleccion.html"><a href="seleccion.html#otros-tipos-de-selección-y-complejidades"><i class="fa fa-check"></i><b>4.8</b> Otros tipos de selección y complejidades</a></li>
<li class="chapter" data-level="" data-path="seleccion.html"><a href="seleccion.html#ejercicios-4"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dosloci.html"><a href="dosloci.html"><i class="fa fa-check"></i><b>5</b> Dinámica de 2 <em>loci</em></a>
<ul>
<li class="chapter" data-level="5.1" data-path="dosloci.html"><a href="dosloci.html#desequilibrio-de-ligamiento-y-recombinación"><i class="fa fa-check"></i><b>5.1</b> Desequilibrio de ligamiento y recombinación</a></li>
<li class="chapter" data-level="5.2" data-path="dosloci.html"><a href="dosloci.html#la-evolución-en-el-tiempo-del-desequilibrio-de-ligamiento"><i class="fa fa-check"></i><b>5.2</b> La evolución en el tiempo del desequilibrio de ligamiento</a></li>
<li class="chapter" data-level="5.3" data-path="dosloci.html"><a href="dosloci.html#otras-medidas-de-asociación"><i class="fa fa-check"></i><b>5.3</b> Otras medidas de asociación</a>
<ul>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#ejemplo-5.3"><i class="fa fa-check"></i>Ejemplo 5.3</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dosloci.html"><a href="dosloci.html#selección-en-modelos-de-dos-loci"><i class="fa fa-check"></i><b>5.4</b> Selección en modelos de dos <em>loci</em></a>
<ul>
<li><a href="dosloci.html#selección-en-un-locus-impacto-en-loci-en-desequilibrio-de-ligamiento">Selección en un locus: impacto en <em>loci</em> en desequilibrio de ligamiento</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="dosloci.html"><a href="dosloci.html#arrastre-genético-genetic-hitchhiking-o-genetic-draft"><i class="fa fa-check"></i><b>5.5</b> Arrastre genético (“genetic hitchhiking” o “genetic draft”)</a></li>
<li class="chapter" data-level="5.6" data-path="dosloci.html"><a href="dosloci.html#causas-del-desequilibrio-de-ligamiento"><i class="fa fa-check"></i><b>5.6</b> Causas del desequilibrio de ligamiento</a>
<ul>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#desequilibrio-debido-al-mestizaje"><i class="fa fa-check"></i>Desequilibrio debido al mestizaje</a></li>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#desequilibrio-inducido-por-el-sistema-de-apareamiento"><i class="fa fa-check"></i>Desequilibrio inducido por el sistema de apareamiento</a></li>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#el-cromosoma-y"><i class="fa fa-check"></i>El cromosoma Y</a></li>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#desequilibrio-debido-a-recombinación-reducida"><i class="fa fa-check"></i>Desequilibrio debido a recombinación reducida</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dosloci.html"><a href="dosloci.html#ejercicios-5"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="aparnoalazar.html"><a href="aparnoalazar.html"><i class="fa fa-check"></i><b>6</b> Apareamientos no-aleatorios</a>
<ul>
<li class="chapter" data-level="6.1" data-path="aparnoalazar.html"><a href="aparnoalazar.html#el-concepto-de-identidad-por-ascendencia-ibd"><i class="fa fa-check"></i><b>6.1</b> El concepto de “identidad por ascendencia” (IBD)</a></li>
<li class="chapter" data-level="6.2" data-path="aparnoalazar.html"><a href="aparnoalazar.html#generalización-de-hardy-weinberg-para-apareamientos-no-aleatorios"><i class="fa fa-check"></i><b>6.2</b> Generalización de Hardy-Weinberg para apareamientos no-aleatorios</a></li>
<li class="chapter" data-level="6.3" data-path="aparnoalazar.html"><a href="aparnoalazar.html#f-como-correlación-entre-gametos-unidos"><i class="fa fa-check"></i><b>6.3</b> <em>F</em> como correlación entre gametos unidos</a></li>
<li class="chapter" data-level="6.4" data-path="aparnoalazar.html"><a href="aparnoalazar.html#endocría-y-depresión-endogámica"><i class="fa fa-check"></i><b>6.4</b> Endocría y depresión endogámica</a></li>
<li class="chapter" data-level="6.5" data-path="aparnoalazar.html"><a href="aparnoalazar.html#un-caso-extremo-la-autogamia"><i class="fa fa-check"></i><b>6.5</b> Un caso extremo: la autogamia</a></li>
<li class="chapter" data-level="6.6" data-path="aparnoalazar.html"><a href="aparnoalazar.html#el-coeficiente-de-endocría-y-estadísticos-f"><i class="fa fa-check"></i><b>6.6</b> El Coeficiente de endocría y estadísticos <em>F</em></a></li>
<li class="chapter" data-level="6.7" data-path="aparnoalazar.html"><a href="aparnoalazar.html#el-efecto-wahlund"><i class="fa fa-check"></i><b>6.7</b> El efecto Wahlund</a></li>
<li class="chapter" data-level="6.8" data-path="aparnoalazar.html"><a href="aparnoalazar.html#subdivisión-migración-y-el-modelo-de-islas"><i class="fa fa-check"></i><b>6.8</b> Subdivisión, migración y el modelo de islas</a></li>
<li class="chapter" data-level="6.9" data-path="aparnoalazar.html"><a href="aparnoalazar.html#mecanismos-de-especiación"><i class="fa fa-check"></i><b>6.9</b> Mecanismos de especiación</a></li>
<li class="chapter" data-level="" data-path="aparnoalazar.html"><a href="aparnoalazar.html#ejercicios-6"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="microbial.html"><a href="microbial.html"><i class="fa fa-check"></i><b>7</b> Genética de Poblaciones Microbianas</a>
<ul>
<li class="chapter" data-level="7.1" data-path="microbial.html"><a href="microbial.html#genómica-y-mecanismos-de-herencia-en-procariotas"><i class="fa fa-check"></i><b>7.1</b> Genómica y mecanismos de herencia en procariotas</a></li>
<li class="chapter" data-level="7.2" data-path="microbial.html"><a href="microbial.html#dinámica-de-las-poblaciones-bacterianas"><i class="fa fa-check"></i><b>7.2</b> Dinámica de las poblaciones bacterianas</a>
<ul>
<li class="chapter" data-level="" data-path="microbial.html"><a href="microbial.html#el-modelo-exponencial"><i class="fa fa-check"></i>El modelo exponencial</a></li>
<li class="chapter" data-level="" data-path="microbial.html"><a href="microbial.html#el-modelo-logístico"><i class="fa fa-check"></i>El modelo logístico</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="microbial.html"><a href="microbial.html#modelos-haploides-de-selección-natural"><i class="fa fa-check"></i><b>7.3</b> Modelos haploides de selección natural</a>
<ul>
<li class="chapter" data-level="" data-path="microbial.html"><a href="microbial.html#selección-haploide-modelo-discreto"><i class="fa fa-check"></i>Selección haploide: modelo discreto</a></li>
<li class="chapter" data-level="" data-path="microbial.html"><a href="microbial.html#selección-haploide-modelo-continuo"><i class="fa fa-check"></i>Selección haploide: modelo continuo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="microbial.html"><a href="microbial.html#los-modelos-de-moran-y-de-fisión-versus-el-de-wright-fisher"><i class="fa fa-check"></i><b>7.4</b> Los modelos de Moran y de Fisión versus el de Wright-Fisher</a></li>
<li class="chapter" data-level="7.5" data-path="microbial.html"><a href="microbial.html#el-rol-de-la-transferencia-horizontal"><i class="fa fa-check"></i><b>7.5</b> El rol de la transferencia horizontal</a></li>
<li class="chapter" data-level="7.6" data-path="microbial.html"><a href="microbial.html#selección-vs-neutralismo-los-procariotas-en-el-debate"><i class="fa fa-check"></i><b>7.6</b> Selección vs Neutralismo: los procariotas en el debate</a></li>
<li class="chapter" data-level="7.7" data-path="microbial.html"><a href="microbial.html#genómica-poblacional"><i class="fa fa-check"></i><b>7.7</b> Genómica poblacional</a></li>
<li class="chapter" data-level="7.8" data-path="microbial.html"><a href="microbial.html#genes-de-resistencia"><i class="fa fa-check"></i><b>7.8</b> Genes de resistencia</a></li>
<li class="chapter" data-level="7.9" data-path="microbial.html"><a href="microbial.html#introducción-a-la-epidemiología-modelos-compartimentales"><i class="fa fa-check"></i><b>7.9</b> Introducción a la epidemiología: modelos compartimentales</a></li>
<li class="chapter" data-level="" data-path="microbial.html"><a href="microbial.html#ejercicios-7"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>Parte III: Genética Cuantitativa</b></span></li>
<li class="chapter" data-level="8" data-path="modelogenbas.html"><a href="modelogenbas.html"><i class="fa fa-check"></i><b>8</b> El Modelo Genético Básico</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modelogenbas.html"><a href="modelogenbas.html#variación-continua-y-discreta"><i class="fa fa-check"></i><b>8.1</b> Variación continua y discreta</a></li>
<li class="chapter" data-level="8.2" data-path="modelogenbas.html"><a href="modelogenbas.html#el-modelo-genético-básico"><i class="fa fa-check"></i><b>8.2</b> El modelo genético básico</a></li>
<li class="chapter" data-level="8.3" data-path="modelogenbas.html"><a href="modelogenbas.html#modelo-genético-básico-un-locus-con-dos-alelos"><i class="fa fa-check"></i><b>8.3</b> Modelo Genético Básico: un <em>locus</em> con dos alelos</a>
<ul>
<li class="chapter" data-level="" data-path="modelogenbas.html"><a href="modelogenbas.html#media-de-la-población"><i class="fa fa-check"></i>Media de la población</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="modelogenbas.html"><a href="modelogenbas.html#efecto-medio"><i class="fa fa-check"></i><b>8.4</b> Efecto medio</a></li>
<li class="chapter" data-level="8.5" data-path="modelogenbas.html"><a href="modelogenbas.html#valor-reproductivo-o-valor-de-cría"><i class="fa fa-check"></i><b>8.5</b> Valor reproductivo (o valor de cría)</a>
<ul>
<li class="chapter" data-level="" data-path="modelogenbas.html"><a href="modelogenbas.html#derivación-de-los-efectos-medios-por-mínimos-cuadrados"><i class="fa fa-check"></i>Derivación de los efectos medios por mínimos cuadrados</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="modelogenbas.html"><a href="modelogenbas.html#desvío-de-dominancia"><i class="fa fa-check"></i><b>8.6</b> Desvío de dominancia</a></li>
<li class="chapter" data-level="8.7" data-path="modelogenbas.html"><a href="modelogenbas.html#interacción-genotipo-x-ambiente"><i class="fa fa-check"></i><b>8.7</b> Interacción Genotipo x Ambiente</a></li>
<li class="chapter" data-level="8.8" data-path="modelogenbas.html"><a href="modelogenbas.html#la-varianza-en-el-modelo-genético-básico"><i class="fa fa-check"></i><b>8.8</b> La Varianza en el modelo genético básico</a>
<ul>
<li><a href="modelogenbas.html#componentes-genéticos-de-la-varianza-un-locus-con-dos-alelos">Componentes genéticos de la varianza: un <em>locus</em> con dos alelos</a></li>
<li class="chapter" data-level="" data-path="modelogenbas.html"><a href="modelogenbas.html#la-varianza-ambiental"><i class="fa fa-check"></i>La varianza ambiental</a></li>
<li class="chapter" data-level="" data-path="modelogenbas.html"><a href="modelogenbas.html#la-varianza-de-la-interacción"><i class="fa fa-check"></i>La Varianza de la interacción</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modelogenbas.html"><a href="modelogenbas.html#ejercicios-8"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="parentesco.html"><a href="parentesco.html"><i class="fa fa-check"></i><b>9</b> Parentesco y Semejanza entre Parientes</a>
<ul>
<li class="chapter" data-level="9.1" data-path="parentesco.html"><a href="parentesco.html#parentesco-1"><i class="fa fa-check"></i><b>9.1</b> Parentesco</a></li>
<li class="chapter" data-level="9.2" data-path="parentesco.html"><a href="parentesco.html#parentesco-aditivo"><i class="fa fa-check"></i><b>9.2</b> Parentesco aditivo</a>
<ul>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#consanguinidad"><i class="fa fa-check"></i>Consanguinidad</a></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#diagramas-de-flechas"><i class="fa fa-check"></i>Diagramas de flechas</a></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#el-método-tabular"><i class="fa fa-check"></i>El método tabular</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="parentesco.html"><a href="parentesco.html#parentesco-de-dominancia"><i class="fa fa-check"></i><b>9.3</b> Parentesco de dominancia</a></li>
<li class="chapter" data-level="9.4" data-path="parentesco.html"><a href="parentesco.html#semejanza-entre-parientes"><i class="fa fa-check"></i><b>9.4</b> Semejanza entre parientes</a></li>
<li class="chapter" data-level="9.5" data-path="parentesco.html"><a href="parentesco.html#estimación-de-las-varianzas-aditiva-y-de-dominancia"><i class="fa fa-check"></i><b>9.5</b> Estimación de las varianzas aditiva y de dominancia</a>
<ul>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i>Propiedades deseables de los estimadores</a></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#estimación-de-la-varianza-aditiva-a-partir-del-análisis-de-varianza-anova"><i class="fa fa-check"></i>Estimación de la varianza aditiva a partir del análisis de varianza (ANOVA)</a></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#estimaciones-basadas-en-modelos-mixtos-lineales"><i class="fa fa-check"></i>Estimaciones basadas en modelos mixtos lineales</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="parentesco.html"><a href="parentesco.html#parentesco-genómico"><i class="fa fa-check"></i><b>9.6</b> Parentesco genómico</a>
<ul>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#contenido-génico"><i class="fa fa-check"></i>Contenido génico</a></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#la-matriz-de-similaridad-genómica"><i class="fa fa-check"></i>La matriz de similaridad genómica</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="parentesco.html"><a href="parentesco.html#ejercicios-9"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pargen.html"><a href="pargen.html"><i class="fa fa-check"></i><b>10</b> Parámetros Genéticos: Heredabilidad y Repetibilidad</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pargen.html"><a href="pargen.html#heredabilidad"><i class="fa fa-check"></i><b>10.1</b> Heredabilidad</a>
<ul>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-heredabilidad-como-relación-de-varianzas"><i class="fa fa-check"></i>La heredabilidad como relación de varianzas</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-heredabilidad-como-regresión"><i class="fa fa-check"></i>La heredabilidad como regresión</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#regresión-del-valor-de-cría-en-el-fenotipo-individual"><i class="fa fa-check"></i>Regresión del valor de cría en el fenotipo individual</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#regresión-del-valor-fenotípico-de-los-hijos-sobre-el-fenotipo-de-un-progenitor"><i class="fa fa-check"></i>Regresión del valor fenotípico de los hijos sobre el fenotipo de un progenitor</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#regresión-del-valor-fenotípico-de-los-hijos-sobre-el-fenotipo-de-ambos-progenitores"><i class="fa fa-check"></i>Regresión del valor fenotípico de los hijos sobre el fenotipo de ambos progenitores</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#precisión-en-las-estimaciones-de-heredabilidad-varianza-del-estimador"><i class="fa fa-check"></i>Precisión en las estimaciones de heredabilidad: varianza del estimador</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="pargen.html"><a href="pargen.html#heredabilidad-en-sentido-amplio-y-sentido-estricto"><i class="fa fa-check"></i><b>10.2</b> Heredabilidad en sentido amplio y sentido estricto</a></li>
<li class="chapter" data-level="10.3" data-path="pargen.html"><a href="pargen.html#heredabilidad-lograda"><i class="fa fa-check"></i><b>10.3</b> Heredabilidad lograda</a></li>
<li class="chapter" data-level="10.4" data-path="pargen.html"><a href="pargen.html#heredabilidad-en-poblaciones-agronómicas-y-de-laboratorio-vs-poblaciones-naturales"><i class="fa fa-check"></i><b>10.4</b> Heredabilidad en poblaciones agronómicas y de laboratorio vs poblaciones naturales</a>
<ul>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#estimaciones-de-heredabilidad-en-animales-domésticos"><i class="fa fa-check"></i>Estimaciones de heredabilidad en animales domésticos</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#estimaciones-de-heredabilidad-en-plantas"><i class="fa fa-check"></i>Estimaciones de heredabilidad en plantas</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#estimaciones-de-heredabilidad-en-condiciones-naturales"><i class="fa fa-check"></i>Estimaciones de heredabilidad en condiciones naturales</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="pargen.html"><a href="pargen.html#heredabilidad-y-filogenética"><i class="fa fa-check"></i><b>10.5</b> Heredabilidad y filogenética</a></li>
<li class="chapter" data-level="10.6" data-path="pargen.html"><a href="pargen.html#heredabilidad-en-la-era-genómica"><i class="fa fa-check"></i><b>10.6</b> Heredabilidad en la era genómica</a></li>
<li class="chapter" data-level="10.7" data-path="pargen.html"><a href="pargen.html#métodos-más-avanzados-de-estimación"><i class="fa fa-check"></i><b>10.7</b> Métodos más avanzados de estimación</a></li>
<li class="chapter" data-level="10.8" data-path="pargen.html"><a href="pargen.html#repetibilidad"><i class="fa fa-check"></i><b>10.8</b> Repetibilidad</a>
<ul>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-repetibilidad-como-cociente-de-varianzas"><i class="fa fa-check"></i>La repetibilidad como cociente de varianzas</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-repetibilidad-como-coeficiente-de-correlación-intraclase"><i class="fa fa-check"></i>La repetibilidad como coeficiente de correlación intraclase</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-relación-entre-la-heredabilidad-y-la-repetibilidad"><i class="fa fa-check"></i>La relación entre la heredabilidad y la repetibilidad</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#la-reducción-en-la-varianza-fenotípica-con-varias-medidas"><i class="fa fa-check"></i>La reducción en la varianza fenotípica con varias medidas</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="pargen.html"><a href="pargen.html#la-repetibilidad-como-herramienta-en-la-predicción"><i class="fa fa-check"></i><b>10.9</b> La repetibilidad como herramienta en la predicción</a></li>
<li class="chapter" data-level="10.10" data-path="pargen.html"><a href="pargen.html#evolucionabilidad"><i class="fa fa-check"></i><b>10.10</b> Evolucionabilidad</a></li>
<li class="chapter" data-level="" data-path="pargen.html"><a href="pargen.html#ejercicios-10"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="selartifI.html"><a href="selartifI.html"><i class="fa fa-check"></i><b>11</b> Selección Artificial I</a>
<ul>
<li class="chapter" data-level="11.1" data-path="selartifI.html"><a href="selartifI.html#factores-de-corrección"><i class="fa fa-check"></i><b>11.1</b> Factores de corrección</a>
<ul>
<li class="chapter" data-level="" data-path="selartifI.html"><a href="selartifI.html#factores-de-corrección-aditivos"><i class="fa fa-check"></i>Factores de corrección aditivos</a></li>
<li class="chapter" data-level="" data-path="selartifI.html"><a href="selartifI.html#factores-de-corrección-multiplicativos"><i class="fa fa-check"></i>Factores de corrección multiplicativos</a></li>
<li class="chapter" data-level="" data-path="selartifI.html"><a href="selartifI.html#factores-de-corrección-lineales"><i class="fa fa-check"></i>Factores de corrección lineales</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="selartifI.html"><a href="selartifI.html#la-respuesta-a-la-selección-y-su-predicción"><i class="fa fa-check"></i><b>11.2</b> La respuesta a la selección y su predicción</a></li>
<li class="chapter" data-level="11.3" data-path="selartifI.html"><a href="selartifI.html#diferencial-de-selección-e-intensidad-de-selección"><i class="fa fa-check"></i><b>11.3</b> Diferencial de selección e intensidad de selección</a></li>
<li class="chapter" data-level="11.4" data-path="selartifI.html"><a href="selartifI.html#intensidad-de-selección-y-proporción-seleccionada"><i class="fa fa-check"></i><b>11.4</b> Intensidad de selección y proporción seleccionada</a>
<ul>
<li><a href="selartifI.html#de-dónde-sale-la-relación-ifraczp">¿De dónde sale la relación <span class="math inline">\(i=\frac{z}{p}\)</span>?</a></li>
<li class="chapter" data-level="" data-path="selartifI.html"><a href="selartifI.html#la-relación-entre-diferentes-formas-de-calcular-la-intensidad-de-selección"><i class="fa fa-check"></i>La relación entre diferentes formas de calcular la intensidad de selección</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="selartifI.html"><a href="selartifI.html#intervalo-generacional"><i class="fa fa-check"></i><b>11.5</b> Intervalo generacional</a></li>
<li class="chapter" data-level="11.6" data-path="selartifI.html"><a href="selartifI.html#medidas-de-la-respuesta"><i class="fa fa-check"></i><b>11.6</b> Medidas de la respuesta</a></li>
<li class="chapter" data-level="11.7" data-path="selartifI.html"><a href="selartifI.html#progreso-genético-generacional-y-anual"><i class="fa fa-check"></i><b>11.7</b> Progreso genético generacional y anual</a></li>
<li class="chapter" data-level="11.8" data-path="selartifI.html"><a href="selartifI.html#cambio-en-las-frecuencias-alélicas-bajo-selección-artificial"><i class="fa fa-check"></i><b>11.8</b> Cambio en las frecuencias alélicas bajo selección artificial</a></li>
<li class="chapter" data-level="11.9" data-path="selartifI.html"><a href="selartifI.html#el-diferencial-de-selección-direccional-y-la-identidad-de-robertson-price"><i class="fa fa-check"></i><b>11.9</b> El diferencial de selección direccional y la identidad de Robertson-Price</a></li>
<li class="chapter" data-level="" data-path="selartifI.html"><a href="selartifI.html#ejercicios-11"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="correlacionada.html"><a href="correlacionada.html"><i class="fa fa-check"></i><b>12</b> Correlaciones y Respuesta Correlacionada</a>
<ul>
<li class="chapter" data-level="12.1" data-path="correlacionada.html"><a href="correlacionada.html#causas-genéticas-y-ambientales-de-las-correlaciones"><i class="fa fa-check"></i><b>12.1</b> Causas genéticas y ambientales de las correlaciones</a>
<ul>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#causas-de-las-correlaciones-genéticas"><i class="fa fa-check"></i>Causas de las correlaciones genéticas</a></li>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#causas-de-las-correlaciones-ambientales"><i class="fa fa-check"></i>Causas de las correlaciones ambientales</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="correlacionada.html"><a href="correlacionada.html#introducción-al-path-analysis"><i class="fa fa-check"></i><b>12.2</b> Introducción al “path analysis”</a>
<ul>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#la-relación-entre-las-correlaciones-fenotípica-genética-y-ambiental"><i class="fa fa-check"></i>La relación entre las correlaciones fenotípica, genética y ambiental</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="correlacionada.html"><a href="correlacionada.html#métodos-para-determinar-la-correlación-genética"><i class="fa fa-check"></i><b>12.3</b> Métodos para determinar la correlación genética</a></li>
<li class="chapter" data-level="12.4" data-path="correlacionada.html"><a href="correlacionada.html#la-correlación-fenotípica-y-su-relación-con-la-correlación-genética-aditiva-y-ambiental"><i class="fa fa-check"></i><b>12.4</b> La correlación fenotípica y su relación con la correlación genética aditiva y ambiental</a></li>
<li class="chapter" data-level="12.5" data-path="correlacionada.html"><a href="correlacionada.html#respuesta-correlacionada"><i class="fa fa-check"></i><b>12.5</b> Respuesta correlacionada</a>
<ul>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#eficiencia-en-relación-a-la-selección-directa"><i class="fa fa-check"></i>Eficiencia en relación a la selección directa</a></li>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#el-signo-de-la-correlación-y-el-beneficio-demérito-de-la-misma"><i class="fa fa-check"></i>El signo de la correlación y el beneficio-demérito de la misma</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="correlacionada.html"><a href="correlacionada.html#matrices-de-varianza-covarianza"><i class="fa fa-check"></i><b>12.6</b> Matrices de varianza-covarianza</a></li>
<li class="chapter" data-level="12.7" data-path="correlacionada.html"><a href="correlacionada.html#la-forma-generalizada-de-la-ecuación-del-criador"><i class="fa fa-check"></i><b>12.7</b> La forma generalizada de la ecuación del criador</a></li>
<li class="chapter" data-level="" data-path="correlacionada.html"><a href="correlacionada.html#ejercicios-12"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="selartifII.html"><a href="selartifII.html"><i class="fa fa-check"></i><b>13</b> Selección Artificial II</a>
<ul>
<li class="chapter" data-level="13.1" data-path="selartifII.html"><a href="selartifII.html#criterios-y-objetivos-de-selección"><i class="fa fa-check"></i><b>13.1</b> Criterios y objetivos de selección</a></li>
<li class="chapter" data-level="13.2" data-path="selartifII.html"><a href="selartifII.html#selección-basada-en-un-solo-tipo-de-fuente-de-información"><i class="fa fa-check"></i><b>13.2</b> Selección basada en un solo tipo de fuente de información</a>
<ul>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#diferentes-tipos-de-selección-basados-en-estructuras-de-parentesco-definidas"><i class="fa fa-check"></i>Diferentes tipos de selección basados en estructuras de parentesco definidas</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#cálculo-de-las-heredabilidades-en-los-distintos-tipos-de-selección"><i class="fa fa-check"></i>Cálculo de las heredabilidades en los distintos tipos de selección</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="selartifII.html"><a href="selartifII.html#combinando-la-información-proporcionada-por-diferentes-tipos-de-parientes"><i class="fa fa-check"></i><b>13.3</b> Combinando la información proporcionada por diferentes tipos de parientes</a>
<ul>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#cálculo-de-los-elementos-de-la-matriz-de-varianzas-covarianzas-fenotípica"><i class="fa fa-check"></i>Cálculo de los elementos de la matriz de varianzas-covarianzas fenotípica</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#cálculo-de-los-elementos-del-vector-de-varianzas-covarianzas-genéticas"><i class="fa fa-check"></i>Cálculo de los elementos del vector de varianzas-covarianzas genéticas</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#información-propia-y-de-un-progenitor"><i class="fa fa-check"></i>Información propia y de un progenitor</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#información-propia-y-de-varios-hermanos-enteros"><i class="fa fa-check"></i>Información propia y de varios hermanos enteros</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#pruebas-de-progenie"><i class="fa fa-check"></i>Pruebas de progenie</a></li>
<li class="chapter" data-level="13.3.1" data-path="selartifII.html"><a href="selartifII.html#límites-de-la-eficiencia-en-pruebas-de-progenie"><i class="fa fa-check"></i><b>13.3.1</b> Límites de la eficiencia en pruebas de progenie</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#precisión-del-valor-de-cría-a-partir-del-índice"><i class="fa fa-check"></i>Precisión del valor de cría a partir del índice</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="selartifII.html"><a href="selartifII.html#métodos-de-selección-para-varias-características"><i class="fa fa-check"></i><b>13.4</b> Métodos de selección para varias características</a>
<ul>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#selección-en-tandem"><i class="fa fa-check"></i>Selección en tandem</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#niveles-independientes-de-rechazo"><i class="fa fa-check"></i>Niveles Independientes de Rechazo</a></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#índices-de-selección"><i class="fa fa-check"></i>Índices de Selección</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="selartifII.html"><a href="selartifII.html#índices-de-selección-para-múltiples-características"><i class="fa fa-check"></i><b>13.5</b> Índices de selección para múltiples características</a>
<ul>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#el-índice-de-smith-hazel"><i class="fa fa-check"></i>El índice de Smith-Hazel</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="selartifII.html"><a href="selartifII.html#métodos-y-técnicas-avanzadas-de-selección"><i class="fa fa-check"></i><b>13.6</b> Métodos y técnicas avanzadas de selección</a>
<ul>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#blup-las-ecuaciones-del-modelo-mixto-lineal"><i class="fa fa-check"></i>BLUP: las ecuaciones del modelo mixto lineal</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="selartifII.html"><a href="selartifII.html#ejercicios-13"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="endoexo.html"><a href="endoexo.html"><i class="fa fa-check"></i><b>14</b> Endocría, exocría, consanguinidad y depresión endogámica</a>
<ul>
<li class="chapter" data-level="14.1" data-path="endoexo.html"><a href="endoexo.html#el-aumento-de-la-consanguinidad-a-partir-del-número-de-individuos"><i class="fa fa-check"></i><b>14.1</b> El aumento de la consanguinidad a partir del número de individuos</a>
<ul>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#qué-proporción-de-machos-es-necesaria-para-mantener-un-tamaño-efectivo-poblacional-mínimo"><i class="fa fa-check"></i>¿Qué proporción de machos es necesaria para mantener un tamaño efectivo poblacional mínimo?</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="endoexo.html"><a href="endoexo.html#el-coeficiente-de-consanguinidad-en-razas-lecheras"><i class="fa fa-check"></i><b>14.2</b> El coeficiente de consanguinidad en razas lecheras</a></li>
<li class="chapter" data-level="14.3" data-path="endoexo.html"><a href="endoexo.html#depresión-endogámica"><i class="fa fa-check"></i><b>14.3</b> Depresión endogámica</a>
<ul>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#los-riesgos-del-uso-masivo-de-reproductores-y-la-endogamia-elevada"><i class="fa fa-check"></i>Los riesgos del uso masivo de reproductores y la endogamia elevada</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#redistribución-en-la-varianza-genética"><i class="fa fa-check"></i>Redistribución en la varianza genética</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="endoexo.html"><a href="endoexo.html#exocría-y-heterosis"><i class="fa fa-check"></i><b>14.4</b> Exocría y Heterosis</a>
<ul>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#el-modelo-del-templo-griego"><i class="fa fa-check"></i>El modelo del templo griego</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#un-modelo-sencillo-de-heterosis-bajo-exocría"><i class="fa fa-check"></i>Un modelo sencillo de heterosis bajo exocría</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#complementariedad"><i class="fa fa-check"></i>Complementariedad</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#tipos-de-cruzamientos"><i class="fa fa-check"></i>Tipos de cruzamientos</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="endoexo.html"><a href="endoexo.html#modelo-genético-de-cruzamientos"><i class="fa fa-check"></i><b>14.5</b> Modelo genético de cruzamientos</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#ejercicios-14"><i class="fa fa-check"></i>Ejercicios</a></li>
<li class="chapter" data-level="" data-path="endoexo.html"><a href="endoexo.html#notas-al-pie"><i class="fa fa-check"></i>Notas al pie</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="GxE.html"><a href="GxE.html"><i class="fa fa-check"></i><b>15</b> Normas de reacción e interacción Genotipo x Ambiente</a>
<ul>
<li class="chapter" data-level="15.1" data-path="GxE.html"><a href="GxE.html#plasticidad-fenotípica-y-normas-de-reacción"><i class="fa fa-check"></i><b>15.1</b> Plasticidad fenotípica y normas de reacción</a></li>
<li class="chapter" data-level="15.2" data-path="GxE.html"><a href="GxE.html#interacción-gxe-en-dos-ambientes"><i class="fa fa-check"></i><b>15.2</b> Interacción GxE en dos ambientes</a></li>
<li class="chapter" data-level="15.3" data-path="GxE.html"><a href="GxE.html#correlación-genética-a-través-de-dos-ambientes"><i class="fa fa-check"></i><b>15.3</b> Correlación genética a través de dos ambientes</a>
<ul>
<li class="chapter" data-level="" data-path="GxE.html"><a href="GxE.html#procedimientos-de-estimación"><i class="fa fa-check"></i>Procedimientos de estimación</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="GxE.html"><a href="GxE.html#genética-cuantitativa-de-la-interacción-gxe"><i class="fa fa-check"></i><b>15.4</b> Genética cuantitativa de la interacción GxE</a></li>
<li class="chapter" data-level="15.5" data-path="GxE.html"><a href="GxE.html#otros-ejemplos-de-interacción-genotipo-ambiente"><i class="fa fa-check"></i><b>15.5</b> Otros ejemplos de interacción genotipo-ambiente</a></li>
<li class="chapter" data-level="" data-path="GxE.html"><a href="GxE.html#ejercicios-15"><i class="fa fa-check"></i>Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apendice-a-conceptos-matemáticos-básicos.html"><a href="apendice-a-conceptos-matemáticos-básicos.html"><i class="fa fa-check"></i>APENDICE A: Conceptos Matemáticos Básicos</a></li>
<li class="chapter" data-level="" data-path="apendice-b-cálculo-diferencial-e-integral-ecuaciones-diferenciales.html"><a href="apendice-b-cálculo-diferencial-e-integral-ecuaciones-diferenciales.html"><i class="fa fa-check"></i>APENDICE B: Cálculo Diferencial e Integral, ecuaciones diferenciales</a></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción a la Genética de Poblaciones y a la Genética Cuantitativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deriva" class="section level1" number="3">
<h1><span class="header-section-number">Capítulo 3</span> Deriva Genética</h1>
<p>En el capítulo anterior (<a href="variación-y-equilibrio-de-hardy-weinberg.html#variación-y-equilibrio-de-hardy-weinberg">Variación y equilibrio de Hardy-Weinberg</a>) comenzamos a entender los procesos que hay por detrás del mantenimiento de la variabilidad en las poblaciones de distintas especies. En particular, a partir de las reglas mecanísticas de la herencia mendeliana<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> vimos que una vez alcanzado el equilibrio, si no aparecen otras fuerzas, las frecuencias alélicas y genotípicas se mantienen. Para esto hemos asumido varias cosas (<a href="variación-y-equilibrio-de-hardy-weinberg.html#supuestos-que-asumimos-se-cumplen-para-h-w">Supuestos que asumimos se cumplen para H-W</a>), algunas más razonables que otras. En particular, una de las cosas que asumimos es que el tamaño de nuestra población es prácticamente infinito (con esto queremos decir un número realmente muy alto de individuos), una situación que no siempre se cumple en la práctica. Más aún, esto nos lleva al concepto de población en nuestro contexto: el conjunto de individuos que potencialmente podrían aparearse en igualdad de condiciones con cualquier otro de la misma población para dejar descendencia. Se trata de un concepto fácil de comprender pero que en la práctica suele ser bastante más complejo de delimitar sus alcances: pensemos, por ejemplo en las poblaciones de Corriedale (ovinos), Angus (bovino de carne) o de Holando (bovino de leche) del Uruguay, ¿se cumplen los supuestos de Hardy-Weinberg? ¿cuál sería mi población si el rebaño o rodeo es cerrado, es decir produce sus propios reemplazos?.</p>
<p>Habiendo definido en forma operativa lo que consideramos una población, rápidamente podemos llegar a ver que en muchas poblaciones asumir un tamaño casi infinito de las mismas es algo absurdo y por lo tanto veremos que en las mismas empieza a jugar una de las fuerzas siempre presente en biología: el azar.</p>
<div id="el-rol-de-los-procesos-estocásticos-en-la-genética" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> El rol de los procesos estocásticos en la genética</h2>
<p>Para estudiar el alcance del azar en nuestro contexto propongamos un experimento conceptual sencillo, que cada uno de nosotros puede reproducir en su casa. Tomemos una jarra o vaso grande y coloquemos 20 bolitas de vidrio azules y 20 bolitas de vidrio rojas, <strong>idénticas excepto por el color</strong> (si como es de esperar no tienes tantas bolitas de diferentes colores, alcanza con hacer bolitas de papel coloreado o cosas similares, aunque nosotros nos seguiremos refiriendo a las bolitas). Por lo tanto, el estado inicial de nuestro experimento (la jarra) es:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">azul</th>
<th align="center">roja</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Cantidad</strong></td>
<td align="center">20</td>
<td align="center">20</td>
</tr>
<tr class="even">
<td><strong>Proporción</strong></td>
<td align="center"><span class="math inline">\(\frac{20}{40}\)</span></td>
<td align="center"><span class="math inline">\(\frac{20}{40}\)</span></td>
</tr>
</tbody>
</table>
<p>Ahora, si sacas una bolita sin mirar el color ¿Qué esperas que ocurra? ¿Será roja o será azul? La extracción de una bolita de nuestra jarra se trata de un fenómeno aleatorio (no podemos saber el resultado con certeza), aunque en algunos casos podemos hacer conjeturas razonables. Por ejemplo, en nuestra jarra hay 20 bolitas azules y 20 rojas (<span class="math inline">\(20+20=40\)</span> bolitas), por lo que la proporción de azules es <span class="math inline">\(p_{azul}=\frac{20}{40}=\frac{1}{2}=0,5\)</span> y lo mismo para las rojas <span class="math inline">\(p_{roja}=\frac{20}{40}=\frac{1}{2}=0,5\)</span> (obviamente habríamos llegado a lo mismo sabiendo que <span class="math inline">\(p_{azul}+p_{roja}=1 \therefore p_{roja}=1-p_{azul}=1-\frac{1}{2}=\frac{1}{2}\)</span>). Por lo tanto, como elegimos al azar que bolita agarramos y no hay nada (en principio) que me lleve a tener preferencias por el color al elegirlas (recordar que las estamos agarrando sin verlas) la probabilidad de tomar unas u otras será esencialmente la proporción de las mismas. Como la proporción de azules es igual a la de rojas (<span class="math inline">\(\frac{1}{2}\)</span> en cada caso), lo único que podría conjeturar razonablemente es que hay tanta probabilidad de que apareza una roja como una azul. Además, si la <strong>reponemos</strong> en la jarra la situación vuelve a ser como al principio (20 rojas y 20 azules), por lo que podemos repetir la lógica tantas veces como queramos.</p>
<p>Supongamos ahora que la bolita que sacamos antes fue azul y que <strong>en lugar de reponerla la dejamos afuera del juego</strong> (la puedes colocar en una caja). Tenemos ahora como estado del sistema antes de extraer la siguiente bolita:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">azul</th>
<th align="center">roja</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Cantidad</strong></td>
<td align="center">19</td>
<td align="center">20</td>
</tr>
<tr class="even">
<td><strong>Proporción</strong></td>
<td align="center"><span class="math inline">\(\frac{19}{39}\)</span></td>
<td align="center"><span class="math inline">\(\frac{20}{39}\)</span></td>
</tr>
</tbody>
</table>
<p>¿cuál será la probabilidad, en una nueva extracción de la jarra, de sacar una bolita azul? ¿será nuevamente equiprobable sacar una roja que una azul? Para responder a estas preguntas debemos volver a hacer las cuentas. La probabilidad de sacar una azul en la segunda extracción, <strong>dado que la primera fue azul y que no la repusimos</strong> es de <span class="math inline">\(p_{azul}=\frac{19}{39} \sim 0,4872\)</span> y la probabilidad de sacar una roja será por lo tanto <span class="math inline">\(p_{roja}=\frac{20}{39} \sim 0,5128\)</span> (notar que ahora en lugar de 40 bolitas solo teníamos 39 antes de sacar la segunda). La diferencia de probabilidades respecto al experimento original son relativamente pequeñas, pero aún así reales: <span class="math inline">\(p_{azul}=0,5\)</span> en la primer extracción, mientras que <span class="math inline">\(p_{azul} \sim 0,4872\)</span> en la segunda.</p>
<p>Supongamos que, una vez más, en la segunda extracción volvió a aparecer una bolita azul, algo nada extraño ya que existían aún en la jarra casi tantas bolitas rojas como azules y nuevamente la dejamos afuera de la jarra (la guardamos en la caja, junto a la primera).</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">azul</th>
<th align="center">roja</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Cantidad</strong></td>
<td align="center">18</td>
<td align="center">20</td>
</tr>
<tr class="even">
<td><strong>Proporción</strong></td>
<td align="center"><span class="math inline">\(\frac{18}{38}\)</span></td>
<td align="center"><span class="math inline">\(\frac{20}{38}\)</span></td>
</tr>
</tbody>
</table>
<p>Ahora, si volvemos a hacer las cuentas previas a la tercer extracción, tenemos que <span class="math inline">\(p_{azul}=\frac{18}{38} \sim 0,47372\)</span> y la probabilidad de sacar una roja será por lo tanto <span class="math inline">\(p_{roja}=\frac{20}{38} \sim 0,5263\)</span> (siempre la suma de <span class="math inline">\(p_{azul}+p_{roja}=1\)</span>). Claramente, si empezamos (por azar) a extraer más bolitas azules que rojas (o más rojas que azules) <strong>y no reponemos</strong>, la probabilidad de volver a sacar una del mismo color que las que venían saliendo tiende a bajar.</p>
<p>Vayamos para atrás en el tiempo (afortundamente podemos hacerlo porque se trata de un experimento conceptual). Supongamos en cambio que luego de haber sacado la primera bolita azul, la segunda hubiese sido roja y por supuesto no repusimos ninguna de las dos. Ahora, la probabilidad de sacar azul en la tercera extracción hubiese sido <span class="math inline">\(p_{azul}=\frac{19}{38}=\frac{1}{2}=0,5\)</span> y la de sacar una roja hubiese sido también <span class="math inline">\(p_{roja}=\frac{19}{38}=\frac{1}{2}=0\)</span>. En otras palabras, como volvimos a igualar las proporciones respecto al estado inicial de la jarra (cuando había 40 bolitas), la probabilidad de extraer alguno de los dos colores hubiese sido la misma.</p>
<p>Hasta ahora habíamos parado nuestro experimento luego de la extracción de dos bolitas. Veamos un experimento real, pero sigámoslo hasta que no queden más bolitas en la jarra. Las extracciones han seguido el orden que aparece en la primer columna ("bolita) de la tabla <a href="deriva.html#tab:tabla3p1">3.1</a>. Es fundamental entender que este es el resultado de <strong>un</strong> experimento en particular. Si repetimos el experimento el resultado (orden de salida de las bolitas) posiblemente sea muy distinto. Tenemos solo 39 filas y no 40 porque la última extracción ya no es aleatoria y porque además no tiene sentido calcular las proporciones luego de esa última extracción (ya no quedan más bolitas).</p>
<table>
<caption><span id="tab:tabla3p1">Table 3.1: </span>La realización de un experimento en particular. Partimos de 20 bolitas azules y 20 bolitas rojas. En la columna “bolita” aparece que bolita sacamos (sin reposición) y en las otras columnas cuantas nos quedan luego de esa extracción de cada color, así como su proporción</caption>
<thead>
<tr class="header">
<th align="left">bolita</th>
<th align="right">rojas</th>
<th align="right">azules</th>
<th align="right">p.roja</th>
<th align="right">p.azul</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">azul</td>
<td align="right">20</td>
<td align="right">19</td>
<td align="right">0.5128</td>
<td align="right">0.4872</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">19</td>
<td align="right">19</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">18</td>
<td align="right">19</td>
<td align="right">0.4865</td>
<td align="right">0.5135</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">18</td>
<td align="right">18</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">18</td>
<td align="right">17</td>
<td align="right">0.5143</td>
<td align="right">0.4857</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">18</td>
<td align="right">16</td>
<td align="right">0.5294</td>
<td align="right">0.4706</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">17</td>
<td align="right">16</td>
<td align="right">0.5152</td>
<td align="right">0.4848</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">16</td>
<td align="right">16</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">16</td>
<td align="right">15</td>
<td align="right">0.5161</td>
<td align="right">0.4839</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">14</td>
<td align="right">15</td>
<td align="right">0.4828</td>
<td align="right">0.5172</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">14</td>
<td align="right">14</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">13</td>
<td align="right">14</td>
<td align="right">0.4815</td>
<td align="right">0.5185</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">13</td>
<td align="right">13</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">12</td>
<td align="right">13</td>
<td align="right">0.4800</td>
<td align="right">0.5200</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">11</td>
<td align="right">13</td>
<td align="right">0.4583</td>
<td align="right">0.5417</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">11</td>
<td align="right">12</td>
<td align="right">0.4783</td>
<td align="right">0.5217</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">11</td>
<td align="right">11</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">10</td>
<td align="right">11</td>
<td align="right">0.4762</td>
<td align="right">0.5238</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">9</td>
<td align="right">11</td>
<td align="right">0.4500</td>
<td align="right">0.5500</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">8</td>
<td align="right">11</td>
<td align="right">0.4211</td>
<td align="right">0.5789</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">7</td>
<td align="right">11</td>
<td align="right">0.3889</td>
<td align="right">0.6111</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">7</td>
<td align="right">10</td>
<td align="right">0.4118</td>
<td align="right">0.5882</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">6</td>
<td align="right">10</td>
<td align="right">0.3750</td>
<td align="right">0.6250</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">5</td>
<td align="right">10</td>
<td align="right">0.3333</td>
<td align="right">0.6667</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">5</td>
<td align="right">9</td>
<td align="right">0.3571</td>
<td align="right">0.6429</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">5</td>
<td align="right">8</td>
<td align="right">0.3846</td>
<td align="right">0.6154</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">5</td>
<td align="right">7</td>
<td align="right">0.4167</td>
<td align="right">0.5833</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">0.4545</td>
<td align="right">0.5455</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">0.4444</td>
<td align="right">0.5556</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">3</td>
<td align="right">5</td>
<td align="right">0.3750</td>
<td align="right">0.6250</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0.4286</td>
<td align="right">0.5714</td>
</tr>
<tr class="even">
<td align="left">roja</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">0.3333</td>
<td align="right">0.6667</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0.4000</td>
<td align="right">0.6000</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">0.5000</td>
<td align="right">0.5000</td>
</tr>
<tr class="odd">
<td align="left">azul</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0.6667</td>
<td align="right">0.3333</td>
</tr>
<tr class="even">
<td align="left">azul</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.0000</td>
<td align="right">0.0000</td>
</tr>
<tr class="odd">
<td align="left">roja</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.0000</td>
<td align="right">0.0000</td>
</tr>
</tbody>
</table>
<p>El resultado de graficar las proporciones de bolitas azules remanentes (probabilidades de extraer una bolita azul) la podemos ver en la <a href="deriva.html#fig:figura3p1">3.1</a>. Claramente, arrancando desde una proporción de <span class="math inline">\(p_{azul}=\frac{1}{2}\)</span>, como tenemos muchas bolitas, al comienzo las variaciones en las proporciones son relativamente pequeñas en cada extracción. A medida de que van quedando cada veez menos bolitas (porque se trata de un <strong>muestreo sin reposición</strong>), las oscilaciones son cada vez mayores hasta que llegamos a una de las dos <strong>barreras absorbentes</strong> que tiene nuestro experimento, las proporciones de 0 (0%) y de 1 (100%). Les llamamos barreras absorbentes porque luego de llegar a ese valor no podremos escaparnos hacia otros valores (insistiremos en este concepto en breve). Es decir, luego de que llegamos a la proporción de 0 bolitas azules (y por lo tanto una proporción de 0), no hay forma de incrementar esa proporción. Lo mismo para la proporción de 1, cuando todas las bolitas que quedan son azules, seguirá así hasta el final del experimento.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p1"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p1-1.png" alt="Probabilidad de sacar una bolita azul en la próxima extracción, para un experimento al azar dado (notar que estas probabilidades cambian de experimento en experimento. En el eje de las abscisas aparece la distribución de bolitas que fuimos sacando. La línea negra horizontal representa la proporción 1/2 desde la que partimos." width="672" />
<p class="caption">
Figure 3.1: Probabilidad de sacar una bolita azul en la próxima extracción, para un experimento al azar dado (notar que estas probabilidades cambian de experimento en experimento. En el eje de las abscisas aparece la distribución de bolitas que fuimos sacando. La línea negra horizontal representa la proporción 1/2 desde la que partimos.
</p>
</div>
<p>Veamos que pasa ahora si repetimos este experimento una vez más, cuyo resultado gráfico aparece en la figura <a href="deriva.html#fig:figura3p2">3.2</a>, pero en color más oscuro, así podemos comparar los dos experimentos</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p2"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p2-1.png" alt="Probabilidad de sacar una bolita azul en la próxima extracción, para un nuevo experimento (en azul oscuro), con las mismas condiciones iniciales." width="672" />
<p class="caption">
Figure 3.2: Probabilidad de sacar una bolita azul en la próxima extracción, para un nuevo experimento (en azul oscuro), con las mismas condiciones iniciales.
</p>
</div>
<p>Claramente, el inicio del experimento es igual al del anterior (porque en los dos partimos de <span class="math inline">\(p_{azul}=\frac{1}{2}\)</span>) y debemos terminar en 0 o en 1, cuando no queden más bolitas azules o cuando todas las que queden sean azules (esa es la razón también por la que no ploteamos hasta después de la última extracción).</p>
<p>¿Qué ocurriría con nuestro experimento si hubiésemos partido de otro lugar (distinto número de bolitas azules que rojas), o si hubiésemos arrancado desde un número mayor o menor de bolitas. Afortunadamente es muy fácil realizar estos experimentos en la computadora y analizar los resultados, al menos para tener una primera impresión del comportamiento cualitativo. En la figura <a href="deriva.html#fig:figura3p3">3.3</a> podemos ver que ocurre la variar el número de bolitas en nuestra jarra (columna de la izquierda 20 bolitas,columna de la derecha 120 bolitas) y variando la frecuencia (proporción) de bolitas azules al comienzo (<span class="math inline">\(p_{azul}=\frac{1}{2}\)</span> fila de arriba, <span class="math inline">\(p_{azul}=\frac{3}{4}\)</span> fila de abajo).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p3"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p3-1.png" alt="Probabilidad de sacar una bolita azul en la próxima extracción, para 10 experimentos, para 4 condiciones: p=1/2 (arriba) y p=3/4 abajo, en 20 (izquierda) y 120 (derecha) bolitas." width="672" />
<p class="caption">
Figure 3.3: Probabilidad de sacar una bolita azul en la próxima extracción, para 10 experimentos, para 4 condiciones: p=1/2 (arriba) y p=3/4 abajo, en 20 (izquierda) y 120 (derecha) bolitas.
</p>
</div>
<p>A partir de la figura <a href="deriva.html#fig:figura3p3">3.3</a> podemos empezar a sacar algunas conclusiones de este experimento aleatorio que nos servirán de referencia en seguida. La primera conclusión se relaciona con algo que ya habíamos visto: a medida de que tengo menos bolitas en la jarra, tanto porque arranque con pocas o porque me voy arrimando al final del experimento, las variaciones en frecuencias suelen ser más drásticas. En este sentido, observar por ejemplo en la figura de arriba a la derecha, que al principio las variaciones entre distintas replicas del experimento apenas se apartan de la línea a trazos, mientras que a medida que van quedando menos bolitas (el avance del número de experimentos que ya realizamos) las proporciones en cada experimento empiezan a ser cada vez más variables (hay mayor dispersión en torno a la línea a trazos). La segunda conclusión tiene que ver con el punto de partida del experimento: a medida de que nos alejamos del punto medio (igual proporción de bolitas azules que rojas), mayor es la probabilidad de que la última bolita que quede en la jarra sea la bolita con mayor proporción inicial. De hecho, la probabilidad de que la última bolita sea de uno de los dos colores si realizamos repetidas veces el mismo experimento es la probabilidad inicial. Esto es muy claro si lo ponemos en un ejemplo. Supongamos que tenemos al inicio 10 bolitas en la jarra, 9 de ellas azules y una roja. Para que la roja sea la última en salir, todas las anteriores extracciones deben ser azules. La probabilidad de que la bolita roja sobreviva a la primer extracción (o sea, que salga azul la primera) es <span class="math inline">\(\frac{9}{10}\)</span> (ya que hay 9 bolitas azules y solo una roja). La de la segunda, asumiendo que la primera fue azul y que por lo tanto la bolita roja sobrevivio a la primer tirada es de <span class="math inline">\(\frac{8}{9}\)</span>. La de la tercera será entonces <span class="math inline">\(\frac{7}{8}\)</span> y así sucesivamente hasta que queden dos bolitas, una roja y otra azul, donde la probabilidad de que se “salve” la roja es de <span class="math inline">\(\frac{1}{2}\)</span>. Puesto todo junto tenemos:</p>
<p><span class="math display">\[\begin{equation}
P(\text{última=roja})=\frac{9}{10} \frac{8}{9} \frac{7}{8} ... \frac{1}{2}=\frac{\prod_{1}^9}{\prod_{2}^{10}}=\frac{9!}{10!}=\frac{1}{10}
\end{equation}\]</span></p>
<p>que es la proporción de bolitas rojas al inicio (recuerda que el símbolo <span class="math inline">\(\prod_a^b\)</span> implica la productoria, el equivalente a la sumatoria, pero en lugar de sumar multiplicamos, entre los números <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>). La utilidad de todo este razonamiento lo veremos en la siguiente sección (<a href="deriva.html#el-modelo-de-wright-fisher">El modelo de Wright-Fisher</a>).</p>
</div>
<div id="el-modelo-de-wright-fisher" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> El modelo de Wright-Fisher</h2>
<p>A esta altura, ya habrás comenzado a imaginarte la relación entre los experimentos aleatorios de la sección anterior y nuestro modelo de poblaciones con un número relativamente pequeño de individuos. Si bien es posible imaginarse y modelar todo el proceso de gametogénesis, apareamientos al azar para constituir los genotipos de la próxima generación y repetir esto tantas veces como queramos, Sewall Wright<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> y Ronald Fisher<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> imaginaron un procedimiento mucho más sencillo pero que permite arribar a las misma conclusiones con mucho menos esfuerzo de cálculo.</p>
<p>La primera suposición que hace el modelo de Wright-Fisher es que más allá del número de individuos, el <strong>pool de gametos</strong> (el conjunto de todos los gametos en la población) es infinito. Si bien esto te puede parecer extraño, si recuerdas que el número de espermatozoides (gametos masculinos) que producen los machos es virtualmente enorme y el número de óvulos que produce cada hembra es de órdenes de magnitud superior que su descendencia, entonces no parece un supuesto arriesgado. Los otros supuestos incluyen ausencia de selección, sin mutaciones, ausencia de migración, con tiempos de generación no superpuestos y bajo apareamiento aleatorio. Si bien no suena realista que se cumplan todas estas condiciones en la vida real, el apartamiento de las mismas suelen ser lo suficientemente menor como para considerar el modelo como una buena aproximación inicial. El proceso que plantean Wright-Fisher para el modelo de un gen con dos alelos es el siguiente: para una población de <span class="math inline">\(N\)</span> individuos de una especie diploide, dada una frecuencia de uno de los alelos muestrear al azar del <strong>pool infinito</strong> <span class="math inline">\(2N\)</span> alelos. Está será nuestra nueva población. Podemos repetir el problema tantas veces como queramos para estudiar el comportamiento a lo largo del tiempo de nuestro modelo.</p>
<p>Ahora, suponemos que ya te habrás preguntado cómo hacemos para muestrear de un pool infinito a partir de un número limitado de alelos disponibles (<span class="math inline">\(N\)</span>). El truco es muy sencillo, la diferencia entre un muestreo <strong>con reposición</strong> y un muestreo <strong>sin reposición</strong> (el que hicimos en la sección precedente) es que mientras que en este último las frecuencias van variando a medida de que vamos extrayendo muestras, en el primero (<strong>con reposición</strong>) las frecuencias permanecen incambiadas definitivamente. Claramente, cuando el muestreo es de a una bolita (o alelo) esto se asemeja a muestrear de un pool infinito de bolitas (o alelos).</p>
<p>Veamos como funciona en la práctica. Supongamos que tenemos una población de <span class="math inline">\(N=5\)</span> individuos. Supongamos además de que se trata de un <em>locus</em> con dos alelos, <span class="math inline">\(A\)</span> representado por bolitas azules y <span class="math inline">\(a\)</span> representado por las bolitas rojas. Para simplificar y que se fije la idea del procedimiento vamos a comenzar con una frecuencia inicial de <span class="math inline">\(p_A=p_{azul}=\frac{1}{2}=p_{roja}=p_a\)</span>. Para que nuestro procedimento funcione claramente vamos a tener ahora dos jarras (una inicialmente con igual proporción de bolitas azules y rojas y la otra vacía) y una caja con al menos <span class="math inline">\(2N\)</span> bolitas de cada color, o sea que en nuestro ejemplo, al menos 10 bolitas azules y 10 bolitas rojas.</p>
<p>La jarra vacía va a representar una nueva generación de nuestra población. Para completarla procederemos extrayendo al azar de la <strong>jarra llena</strong> una bolita y de acuerdo al color de la misma sacamos <strong>de la caja</strong> una bolita del mismo color y la colocamos en la <strong>jarra vacía</strong>, devolviendo la bolita que sacamos a la jarra llena. Repetimos este procedimiento <span class="math inline">\(2N\)</span> veces, al cabo del cuál tendremos <span class="math inline">\(2N\)</span> bolitas en nuestra antigua <strong>jarra vacía</strong> (la nueva generación de la población). Para completar el procedimiento y estar prontos para una nueva generación, vacíamos el contenido de la anterior <strong>jarra llena</strong> en la caja.</p>
<p>En este punto, podemos analizar el contenido de la <strong>nueva jarra llena</strong> (la población “hija” de la inicial), contando cuantas bolitas de cada color obtuvimos. Ahora, ¿podemos predecir (de alguna manera) el comportamiento de este experimento en una generación? Si llamamos (arbitrariamente) un “éxito” al hecho de sacar una bolita de color azul, entonces la extracción de cada bolita será una variable aleatoria con distribución de Bernoulli<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> y probabilidad de éxito <span class="math inline">\(p_{azul}\)</span> (y por lo tanto, probabilidad de fracaso, bolita roja, <span class="math inline">\(p_{roja}=1-p\)</span>). Si consideramos el resultado de las <span class="math inline">\(2N\)</span> extracciones independientes y con la misma probabilidad (recordar que es un muestreo <strong>con reposición</strong>) como un conjunto, entonces la distribución del número de bolitas azules (éxitos) y rojas (fracasos) entre las <span class="math inline">\(2N\)</span> tenga una distribución binomial:</p>
<p><span class="math display" id="eq:binomi2">\[\begin{equation}
\begin{split}
P(i \text{ bolitas azules})={2N\choose i} p^i (1-p)^{2N-i},\\
{2N\choose i}=\frac{2N!}{i!(2N-i)!} 
\end{split}
\tag{3.1}
\end{equation}\]</span></p>
<p>Es decir, si bien el número de bolitas en la nueva jarra también es de <span class="math inline">\(2N=10\)</span>, ahora el número de bolitas azules (copias del alelo <strong>A</strong>) que llamamos <span class="math inline">\(i\)</span> (y por lo tanto el de bolitas rojas, o alelo <strong>a</strong> igual a <span class="math inline">\(2N-i\)</span>) es una variable aleatoria y por lo tanto con resultado incierto de experimento en experimento. En general, si una población tiene <span class="math inline">\(i\)</span> copias del alelo <span class="math inline">\(A\)</span> y <span class="math inline">\(2N-i\)</span> copias del alelo <span class="math inline">\(a\)</span>, la probabilidad de transición de pasar de <span class="math inline">\(i\)</span> copias a <span class="math inline">\(j\)</span> copias en el modelo de Wright-Fisher se encuentra dada por la siguiente ecuación:</p>
<p><span class="math display" id="eq:WrightFisher">\[\begin{equation}
T_{ij}={2N \choose j}\left(\frac{i}{2N}\right)^{j}\left(\frac{2N-i}{2N}\right)^{2N-j}=\frac{(2N)!}{j!(2N-j)!}p^jq^{2N-j}
\tag{3.2}
\end{equation}\]</span></p>
<p>Esta ecuación es bien sencilla de explicar. La probabilidad de éxito (alelo <strong>A</strong> o bolita azul) varía de generación en generación, y por lo tanto para la generación actual de gametos es igual a la proporción de alelos <strong>A</strong> (<span class="math inline">\(i\)</span>) en el total (<span class="math inline">\(2N\)</span>), por lo que para cada generación de gametos <span class="math inline">\(p=\frac{i}{2N}\)</span>. Concomitantemente, la probabilidad de fracaso (alelo <strong>a</strong> o bolita roja) es igual a la proporción de alelos <strong>a</strong> en el total, o sea <span class="math inline">\(\frac{2N-i}{2N}\)</span>. Ahora, el número de exitos <strong>en la siguiente generación</strong> le llamamos <span class="math inline">\(j\)</span> (la cantidad de alelos <strong>A</strong> que tienen la probabilidad <span class="math inline">\(T_{ij}\)</span>) y por lo tanto, la cantidad de alelos <strong>a</strong> será <span class="math inline">\(2N-j\)</span>.</p>
<p>Hasta ahora nos hemos referido a una población en particular y como vimos su evolución es completamente al azar. En la figura <a href="deriva.html#fig:figura3p4">3.4</a> podemos ver un ejemplo de la evolución del alelo <strong>A</strong> en una población de 5 individuos diploides. El punto de partida es de <span class="math inline">\(p_{A}=\frac{1}{2}\)</span> y el aspecto de “dientes de sierra” se debe a que lo más fino que puede ser el movimiento es de <span class="math inline">\(\frac{1}{2N}=\frac{1}{10}=0,1\)</span> en nuestro caso. Por otro lado, tanto <span class="math inline">\(p_A=0\)</span> como <span class="math inline">\(p_A=1\)</span> son <strong>barreras absorbentes</strong> ya que <span class="math inline">\(p_A=0\)</span> quiere decir que no quedan más alelos <strong>A</strong> (bolitas azules) en la población, mientras que <span class="math inline">\(p_A=1\)</span> quiere decir que todos los alelos que quedan en la población son <strong>A</strong>, es decir que este alelo se fijó en la población (y por lo tanto, en ambos casos la frecuencia no variará más en el tiempo; recordar que uno de los supuestos fue que no hay mutación).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p4"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p4-1.png" alt="Proporción de alelo A (bolitas azules) en una población de 5 individuos diploides. Notar de que se trata de una realización en particular de este experimento y que con seguridad si repetimos el experimento el resultado será diferente." width="672" />
<p class="caption">
Figure 3.4: Proporción de alelo A (bolitas azules) en una población de 5 individuos diploides. Notar de que se trata de una realización en particular de este experimento y que con seguridad si repetimos el experimento el resultado será diferente.
</p>
</div>
<p>Afortunadamente a partir de unas pocas líneas de código podemos explorar a nuestro antojo el comportamiento en varias poblaciones, conjunto que se llama <strong>ensemble</strong>, variando el número de individuos en ellas, así como la proporción inicial del alelo <strong>A</strong>. El resultado de probar el comportamiento para poblaciones de 5 y 50 individuos, con proporción inicial de alelo de <span class="math inline">\(p=\frac{1}{2}\)</span> y <span class="math inline">\(p=\frac{3}{4}\)</span> lo podemos ver en la figura <a href="deriva.html#fig:figura3p5">3.5</a>. Claramente podemos apreciar que la poblaciones con mayor número de individuos tienen un comportamiento menos errático. Por otro lado, en las poblaciones que arrancan más cerca de una de las <strong>barreras absorbentes</strong> la variación es menor en relación a las poblaciones con el mismo número de individuos per que arrancan desde la mitad (<span class="math inline">\(p=\frac{1}{2}\)</span>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p5"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p5-1.png" alt="Frecuencia del alelo A (bolitas azules) en 10 poblacionesde 5 individuos diploides (a la izquierda) y de 50 individuos diploides (derecha), para frecuencias iniciales de p=1/2 (arriba) y p=3/4 (abajo)." width="672" />
<p class="caption">
Figure 3.5: Frecuencia del alelo A (bolitas azules) en 10 poblacionesde 5 individuos diploides (a la izquierda) y de 50 individuos diploides (derecha), para frecuencias iniciales de p=1/2 (arriba) y p=3/4 (abajo).
</p>
</div>
<p>Este comportamiento no debería resultarnos extraño. Los muestreos que estamos realizando en cada población, a cada generación, provienen de distribuciones binomiales. Si recuerdas de tus cursos de matemáticas y estadística, para una variable <span class="math inline">\(i \sim Binom(2N,p)\)</span>, <span class="math inline">\(E(i)=2Np\)</span> y <span class="math inline">\(Var(i)=2Np(1-p)=2Np-2Np^2\)</span>, por lo que esperamos que mientras las poblaciones se encuentren segregando, la esperanza (la media) entre la distintas poblaciones sea de <span class="math inline">\(Np\)</span>, o lo que es lo mismo, la proporción del alelo <strong>A</strong> sea igual a <span class="math inline">\(p_A=\frac{E(i)}{2N}=\frac{2Np}{2N}=p\)</span> (es decir, en promedio las líneas de poblaciones oscilarán en torno a la frecuencia inicial). Más aún, como vimos antes (<a href="variación-y-equilibrio-de-hardy-weinberg.html#h-w-la-frecuencia-de-heterocigotas-en-función-de-la-frecuencia-alélica">H-W: la frecuencia de heterocigotas en función de la frecuencia alélica</a>), <span class="math inline">\(p(1-p)\)</span> tiene un máximo en <span class="math inline">\(p=\frac{1}{2}\)</span>, por lo que <span class="math inline">\(Var(i)=2Np(1-p)\)</span> también tendrá un máximo en <span class="math inline">\(p=\frac{1}{2}\)</span> (porque <span class="math inline">\(p(1-p)\)</span> está multiplicado por <span class="math inline">\(2N\)</span> que es necesariamente una constante positiva); en otras palabras, la varianza <strong>dentro de cada población</strong> será máxima cerca de la frecuencia <span class="math inline">\(p=\frac{1}{2}\)</span>.
¿Cómo se condice esto con el comportamiento más variable en poblaciones pequeñas? Si recuerdas de esos mismos cursos, la varianza en la frecuencia por <strong>generación</strong> en el <strong>ensemble</strong> viene dada por <span class="math inline">\(Var(i/(2N))=\frac{1}{(2N)^2}Var(i)=\frac{2Np(1-p)}{4N^2}=\frac{p(1-p)}{2N}\)</span>, es decir que al aumentar el tamaño de cada población (<span class="math inline">\(2N\)</span>) la variación <strong>entre poblaciones</strong> disminuye. Finalmente, la variación <strong>entre poblaciones</strong> para las poblaciones que aún se encuentran segregando (o sea, que no llegaron a las <strong>barreras absorbentes</strong>) se incrementa con el tiempo de manera aproximadamente lineal.</p>
<p>Una última observación es la que hace al número de individuos <span class="math inline">\(N\)</span> de las distintas poblaciones. Hasta ahora asumimos que cada uno de nuestros individuos era completamente independiente de los otros desde el punto de vista genético (es decir, condiciones ideales) y por lo tanto no tuvimos en cuenta el efecto de que no lo sean en nuestros cálculos. En realidad, en la práctica, bajo diferentes criterios (apareamientos dirigidos, diferencias en el número de progenie esperada por pareja, etc.), las poblaciones se suelen comportar como si el número de individuos fuese menor y a ese número se lo conoce como <strong>tamaño efectivo</strong> de la población y se lo representa con el símbolo <span class="math inline">\(N_e\)</span>. Esto lo veremos con más detalle en la sección <a href="deriva.html#tamaño-efectivo-poblacional">Tamaño efectivo poblacional</a> y de nuevo en el capítulo <a href="aparnoalazar.html#aparnoalazar">Apareamientos no-aleatorios</a>.</p>
<p>En resumen, a partir del modelo sencillo de Wright-Fisher pudimos entender que en ausencia de otras fuerzas evolutivas como la selección, migración o mutación, las frecuencias alélicas pueden variar en forma aleatoria y que con el transcurso del tiempo cada alelo puede fijarse en alguna población mientras que desaparece en otras. Este fenómeno es lo que se conoce como <strong>deriva genética</strong> o <strong>deriva aleatoria</strong>, este último término en razón de que el cambio en las frecuencias no tiene una dirección y que por lo tanto no es predecible el sentido para una población en particular.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<ul>
<li><p>El modelo de <strong>Wright-Fisher</strong> asume que de un <strong>pool infinito</strong> de gametos, con las frecuencias de los alelos proporcionales a lo muestreado para constituir la generación anterior, muestreamos nuevamente <span class="math inline">\(2N\)</span> alelos, que será mi nueva población.</p></li>
<li><p>La suposición de un <strong>pool infinito</strong> de gametos es equivalente, desde el punto de vista matemático a un muestreo con reposición.</p></li>
<li><p>Al generarse la nueva población a partir de <span class="math inline">\(2N\)</span> muestreos independientes de Bernoulli, la distribución de la nueva población será una Binomial con probabilidad <span class="math inline">\(p\)</span> y tamaño <span class="math inline">\(2N\)</span>.</p></li>
<li><p>La varianza de las frecuencias del alelo <strong>A</strong> (<span class="math inline">\(p\)</span>) entre poblaciones, <strong>por generación</strong>, debida al efecto de la deriva genética es:</p></li>
</ul>
<p><span class="math display" id="eq:varWFpergen">\[\begin{equation}
\sigma^2(p)=\frac{pq}{2N_e}=\frac{p-p^2}{2N_e}
\tag{3.3}
\end{equation}\]</span></p>
<p>con <span class="math inline">\(p\)</span> y <span class="math inline">\(q=1-p\)</span> las frecuencias de los alelos y <span class="math inline">\(N_e\)</span> el tamaño efectivo de las poblaciones que forman el <strong>ensemble</strong>. Como la varianza crece linealmente con el tiempo (en generaciones), tenemos también que para el tiempo <span class="math inline">\(t\)</span> para las líneas que continúan segregando:</p>
<p><span class="math display" id="eq:varWF">\[\begin{equation}
\sigma_t^2(p)=t\frac{pq}{2N_e}=t\frac{(p-p^2)}{2N_e}
\tag{3.4}
\end{equation}\]</span></p>
</div>
</div>
<div id="el-rol-de-la-subdivisión-poblacional-en-la-evolución-de-las-frecuencias-alélicas" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> El rol de la subdivisión poblacional en la evolución de las frecuencias alélicas</h2>
<p>La sección anterior marcó un cambio importante en nuestras perspectivas. Desde analizar el comportamiento de una o dos poblaciones, a partir de la sección anterior empezamos a apreciar que el azar puede jugar un rol muy importante en la evolución de las frecuencias alélicas en poblaciones relativamente pequeñas y nos empezamos a interesar en la visión en conjunto de las mismas.</p>
<p>El debate acerca del rol de la deriva genética versus la selección en los procesos de especiación (la aparición de nuevas especies) ha sido acalorado (ver, por ejemplo <span class="citation"><a href="#ref-CharlesworthLandeSlatkin1982" role="doc-biblioref">B. Charlesworth, Lande, and Slatkin</a> (<a href="#ref-CharlesworthLandeSlatkin1982" role="doc-biblioref">1982</a>)</span>). Aunque el debate continúa,pese a reconocer un rol no despreciable a la deriva genética, los actores principales de esta comedia que es la vida parecen ser la mutación (como generador de variabilidad) y la selección, a través de sus diversas formas de acción (algo que veremos en el capítulo de <a href="seleccion.html#seleccion">Selección Natural</a>).</p>
<p>Pero veamos cómo podría estar funcionando la deriva genética en los procesos que llevan a la especiación. En efecto, imaginemos un <em>locus</em> con dos alelos que sean neutros respecto a los ambientes (por lo tanto no hay selección). Asumamos también que la tasa mutacional es suficientemente baja como para que resulte improbable la aparición de los mismos alelos. Supongamos también que se trata de una especie con poca movilidad esperada, o sea la relación de su área potencial de apareamiento al rango geográfico de la especie (pueden ser especies animales, plantas, hongos, por ejemplo). Si la dispersión a largas distancias en esta especie suele ser algo relativamente raro, por ejemplo semillas llevadas por el viento, es posible imaginar que el <strong>ensemble</strong> de poblaciones está formado por pequeños <strong>parches</strong>, cada uno constituyendo una población diferente y que dada la baja movilidad de la especie no es probable que intercambien material genético con otros parches. Suponiendo además que el tamaño efectivo (<span class="math inline">\(N_e\)</span>) es relativamente pequeño, algo muy razonable teniendo en cuenta que los individuos deben reproducirse en su entorno cercano, estamos entonces en una situación como alguna de las representadas en la figura <a href="deriva.html#fig:figura3p5">3.5</a>. Es decir, mientras que en algunos parches la frecuencia del alelo <strong>A</strong> crecerá hacia la fijación del mismo, en otras poblaciones posiblemente se pierda (o lo que es lo mismo, quede fijado el alelo <strong>a</strong>). Pero la deriva genética es un fenómeno que ocurre simultáneamente en todo el genoma (obviamente que en sitios <strong>no ligados</strong> del genoma el fenómeno es independiente) y por lo tanto aún las poblaciones que terminen con el alelo <strong>A</strong> fijado serán diferentes en otros <em>loci</em>, donde la deriva ocurre en forma independiente. Todo este proceso, simplemente por la “reglas” de la reproducción, producirá un conjunto de poblaciones cada vez más disimiles entre ellas (y cada vez más parecidas dentro), lo que es un buen comienzo para la especiación.</p>
<p>Un fenómeno usual en muchas especies, que magnifica el rol de la deriva genética, es lo que se conoce como <strong>cuello de botella poblacional</strong> (o “genetic bottleneck”). En efecto, en muchas especies es frecuente encontrarse con eventos que llegan a la casi extinción de alguna población en particular, en un momento dado del tiempo, pero que luego de eso comienza a recuperarse e incrementar el número de individuos. Sin embargo, las huellas de esta reducción drástica en un momento son normalmente imborrables en el genoma. Como en el momento de máxima restricción solo unos pocos individuos sobreviven y por lo tanto son la base reproductiva de la población a futuro, al ser <span class="math inline">\(N_e\)</span> muy pequeño la varianza por generación será enorme, además de que la frecuencia inicial de las variantes será posiblemente <strong>sesgada</strong> respecto a la misma población antes del cuello de botella. Esto último nos lleva directamente a otro fenómeno estrechamente relacionado: el <strong>efecto fundador</strong>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:CandidoGodoi"></span>
<img src="figuras/candido_godoi.png" alt="Mellizos/Gemelos de Cândido Godoi (imagen sacada de la web, sin crédito de autor)." width="510" />
<p class="caption">
Figure 3.6: Mellizos/Gemelos de Cândido Godoi (imagen sacada de la web, sin crédito de autor).
</p>
</div>
<p>El <strong>efecto fundador</strong> se produce cuando un número relativamente pequeño de individuos <strong>funda una nueva población</strong> y por efecto de la frecuencia sesgada en esa pequeña muestra más el efecto de la endogamia (o “inbreeding,” el efecto del apareamiento entre parientes que veremos en otro capítulo más adelante) casi obligada por el número reducido de individuos, llevan a medida de que la población va creciendo a una fuerte desviación de las frecuencias alélicas respecto a la población original. Un ejemplo notable entre poblaciones humanas lo constituye el pueblo de <strong>Cândido Godói</strong>, un municipio de Río Grande do Sul (Brasil) de unos 6 mil habitantes. El sobrenombre del pueblo es “Terra dos gêmeos” (tierra de los gemelos), ya que 1 de cada 10 mujeres ha tenido mellizos/gemelos, una cifra muy superior al 1,8% de Río Grande do Sul (y en algún estudio, cerca de la mitad fueron monocigóticos), figura <a href="deriva.html#fig:CandidoGodoi">3.6</a>. Si bien se especuló que el origen de este fenómeno serían una serie de experimentos del doctor Nazi Josef Mengele, la causa más probable es el estrecho parentesco de sus habitantes, unido al efecto fundador como origen de la colonia <span class="citation"><a href="#ref-TaglianiRibeiro2011" role="doc-biblioref">Tagliani-Ribeiro et al.</a> (<a href="#ref-TaglianiRibeiro2011" role="doc-biblioref">2011</a>)</span>. En particular, en este estudio los autores encuentran una fuerte asociación entre la presencia del alelo P72 en el gen <em>TP53</em> y el “riesgo” de embarazo gemelar. También los autores reportan una significancia menor para la asociación entre el alelo T del gen <em>MDM4</em> y en conjunto proponen que ambos alelos (en dos genes distintos) estarían actuando mediante la reducción del mecanismo de apoptosis inducida por p53.</p>
<div id="homocigosidad-y-heterocigosidad" class="section level3 unnumbered">
<h3>Homocigosidad y Heterocigosidad</h3>
<p>En las secciones anteriores nos hemos manejado considerando exclusivamente la evolución en el tiempo de las frecuencias alélicas en las distintas poblaciones que conforman nuestro <strong>ensemble</strong> y dejamos de lado el análisis de lo que ocurriría dentro y entre ellas desde el punto de vista de los genotipos. Consideremos, como una suposición <em>a priori</em> razonable, que dentro de cada población se mantiene el apareamiento al azar y que más allá el número posiblemente pequeño de individuos dentro de ellas que hacen fluctuar las frecuencias alélicas, podemos esperar que las mismas vayan siguiendo <strong>aproximadamente</strong> el equilibrio de Hardy-Weinberg de generación en generación. Para graficar nuestra situación supongamos que tenemos una gran población, con una frecuencia del alelo <strong>A</strong> igual a <span class="math inline">\(p=\frac{1}{2}=0,5\)</span> que en el momento inicial de nuestra historia se divide en 4 poblaciones idénticas en tamaño (cada una de <span class="math inline">\(1/4\)</span> del tamaño de la grande), como lo representamos en la figura <a href="deriva.html#fig:subdivPob">3.7</a>. Cada una de estas poblaciones, a medida de que pase el tiempo, por efecto exclusivo de la deriva genética se irá apartando de la frecuencia original <span class="math inline">\(p=0,5\)</span> y la varianza de frecuencias entre ellas irá creciendo en el tiempo, como vimos más arriba. Es de destacar que nuestra representación en la figura <a href="deriva.html#fig:subdivPob">3.7</a> es apenas una configuración posible de infinitas, ya que la evolución de las 4 poblaciones será aleatoria, pero esta configuración en particular, sin pérdida de generalidad nos ayudará a ilustrar el fenómeno general.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:subdivPob"></span>
<img src="figuras/subdivisionPoblacional2.png" alt="Evolución por deriva genética de las frecuencias alélicas en 4 subpoblaciones que parten de la misma frecuencia (el tiempo no está a escala). Las líneas superior e inferior representan las **barreras absorbentes** de fijación y pérdida del alelo. A medida que corre el tiempo las poblaciones se apartan de la frecuencia alélica inicial, aunque se mantiene la frecuencia promedio como el valor inicial." width="556" />
<p class="caption">
Figure 3.7: Evolución por deriva genética de las frecuencias alélicas en 4 subpoblaciones que parten de la misma frecuencia (el tiempo no está a escala). Las líneas superior e inferior representan las <strong>barreras absorbentes</strong> de fijación y pérdida del alelo. A medida que corre el tiempo las poblaciones se apartan de la frecuencia alélica inicial, aunque se mantiene la frecuencia promedio como el valor inicial.
</p>
</div>
<p>Si pensamos en la población original, antes de la subdivisión y asumimos que se encontraba en equilibrio de Hardy-Weinberg, ya que <span class="math inline">\(q=1-p=1-\frac{1}{2}=\frac{1}{2}\)</span>, tenemos que la composición de los tres genotipos era la siguiente:</p>
<p><span class="math display">\[\begin{equation}
AA=p^2=\left(\frac{1}{2}\right)^2=\frac{1}{4}\\
Aa=2pq=2 \cdot \frac{1}{2} \frac{1}{2}=2 \cdot \frac{1}{4}=\frac{1}{2}\\
aa=q^2=\left(\frac{1}{2}\right)^2=\frac{1}{4}
\end{equation}\]</span></p>
<p>Luego, con el paso del tiempo llegamos a un determinado momento <span class="math inline">\(t_1\)</span> en que las frecuencias alélicas ya han divergido algo. En la tabla <a href="deriva.html#tab:subdivtx1">3.2</a> podemos ver lo que ocurre a nivel de los genotipos en cada una de las 4 poblaciones, así como la media de las 4 poblaciones (que como son todas iguales en tamaño es directamente igual al promedio de los valores). En la última columna tenemos también la frecuencia de los genotipos homocigotos, es decir <strong>AA</strong> y <strong>aa</strong>. Claramente, la frecuencia alélica promedio no ha cambiado, era de <span class="math inline">\(\frac{1}{2}\)</span> en <span class="math inline">\(t_0=0\)</span> y sigue siendo <span class="math inline">\(\frac{1}{2}\)</span> en <span class="math inline">\(t_1\)</span>. Sin embargo, dentro de las poblaciones el cambio de frecuencia, sumado al equilibrio Hardy-Weinberg para cada una de ellas se refleja en diferencias importantes entre poblaciones en la proporción de homocigotos. Más aún, el promedio de los homocigotos (el promedio de la suma <strong>AA</strong> y <strong>aa</strong> en cada población) se vio incrementado, desde <span class="math inline">\(fr(AA)+fr(aa)=\frac{1}{4}+\frac{1}{4}=\frac{1}{2}=0,5\)</span> a <span class="math inline">\(0,5725\)</span>. Esto no es menor, sin cambiar el promedio de las frecuencias alélicas y manteniendo el equilibrio de Hardy-Weinberg dentro de las poblaciones, si las volviésemos a agrupar a el solo efecto de contar los genotipos, el <strong>ensemble</strong> (el conjunto de todos los individuos de todas las poblaciones) ya no están más en equilibrio de Hardy-Weinberg (porque el equilibrio para <span class="math inline">\(p=0,5\)</span> es de <span class="math inline">\(G=\frac{1}{2}=0,5\)</span>, notar que usamos el símbolo <span class="math inline">\(G\)</span> para homocigotos, como en la sección <a href="variación-y-equilibrio-de-hardy-weinberg.html#tres-o-más-alelos">Tres o más alelos</a> del capítulo anterior).</p>
<table>
<caption><span id="tab:subdivtx1">Table 3.2: </span>Frecuencias de los genotipos en las 4 poblaciones, manteniendo el equilibrio de Hardy-Weinberg en cada una de ellas, en el primer punto en el tiempo luego del inicio (<span class="math inline">\(t_1\)</span>).</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">p</th>
<th align="left">AA</th>
<th align="left">Aa</th>
<th align="left">aa</th>
<th align="left">Homocigotos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Población 1</td>
<td align="left">0.7500</td>
<td align="left">0.5625</td>
<td align="left">0.3750</td>
<td align="left">0.0625</td>
<td align="left">0.6250</td>
</tr>
<tr class="even">
<td align="left">Población 2</td>
<td align="left">0.6000</td>
<td align="left">0.3600</td>
<td align="left">0.4800</td>
<td align="left">0.1600</td>
<td align="left">0.5200</td>
</tr>
<tr class="odd">
<td align="left">Población 3</td>
<td align="left">0.4000</td>
<td align="left">0.1600</td>
<td align="left">0.4800</td>
<td align="left">0.3600</td>
<td align="left">0.5200</td>
</tr>
<tr class="even">
<td align="left">Población 4</td>
<td align="left">0.2500</td>
<td align="left">0.0625</td>
<td align="left">0.3750</td>
<td align="left">0.5625</td>
<td align="left">0.6250</td>
</tr>
<tr class="odd">
<td align="left">media</td>
<td align="left"><strong>0.5000</strong></td>
<td align="left"><strong>0.2862</strong></td>
<td align="left"><strong>0.4275</strong></td>
<td align="left"><strong>0.2862</strong></td>
<td align="left"><strong>0.5725</strong></td>
</tr>
</tbody>
</table>
<p>Veamos que ocurre entonces a medida de que nos alejamos del punto inicial en el tiempo. Cuando llegamos al punto <span class="math inline">\(t_2\)</span>, las frecuencias en las poblaciones divergen un poco más, aunque ninguna población a llegado aún a fijar alguno de los dos alelos. La distribución de los genotipos en las mismas, de acuerdo a las nuevas frecuencias alélicas, se puede apreciar en la tabla <a href="deriva.html#tab:subdivtx2">3.3</a>. Claramente volvemos a ver un incremento en en promedio de homocigotos en la población, que ahora subió hasta <span class="math inline">\(0,6450\)</span>.</p>
<table>
<caption><span id="tab:subdivtx2">Table 3.3: </span>Frecuencias de los genotipos en las 4 poblaciones, manteniendo el equilibrio de Hardy-Weinberg en cada una de ellas, en el segundo punto en el tiempo luego del inicio (<span class="math inline">\(t_2\)</span>).</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">p</th>
<th align="left">AA</th>
<th align="left">Aa</th>
<th align="left">aa</th>
<th align="left">Homocigotos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Población 1</td>
<td align="left">0.8500</td>
<td align="left">0.7225</td>
<td align="left">0.2550</td>
<td align="left">0.0225</td>
<td align="left">0.7450</td>
</tr>
<tr class="even">
<td align="left">Población 2</td>
<td align="left">0.6500</td>
<td align="left">0.4225</td>
<td align="left">0.4550</td>
<td align="left">0.1225</td>
<td align="left">0.5450</td>
</tr>
<tr class="odd">
<td align="left">Población 3</td>
<td align="left">0.3500</td>
<td align="left">0.1225</td>
<td align="left">0.4550</td>
<td align="left">0.4225</td>
<td align="left">0.5450</td>
</tr>
<tr class="even">
<td align="left">Población 4</td>
<td align="left">0.1500</td>
<td align="left">0.0225</td>
<td align="left">0.2550</td>
<td align="left">0.7225</td>
<td align="left">0.7450</td>
</tr>
<tr class="odd">
<td align="left">media</td>
<td align="left"><strong>0.5000</strong></td>
<td align="left"><strong>0.3225</strong></td>
<td align="left"><strong>0.3550</strong></td>
<td align="left"><strong>0.3225</strong></td>
<td align="left"><strong>0.6450</strong></td>
</tr>
</tbody>
</table>
<p>Para hacer la historia corta y confirmar la tendencia, además de comenzar a imaginar hacia dónde vamos, veamos que ocurre en el instante <span class="math inline">\(t_3\)</span>, momento para el cual en la <em>Población 1</em> se ha fijado el alelo <strong>A</strong> (<span class="math inline">\(p=1\)</span>), mientras que en la <em>Población 4</em> se ha fijado el alelo <strong>a</strong> (o lo que es equivalente, se ha perdido el <strong>A</strong>, <span class="math inline">\(p=0\)</span>). La distribución de genotipos se observa en la tabla <a href="deriva.html#tab:subdivtx3">3.4</a>.</p>
<table>
<caption><span id="tab:subdivtx3">Table 3.4: </span>Frecuencias de los genotipos en las 4 poblaciones, manteniendo el equilibrio de Hardy-Weinberg en cada una de ellas, en el tercer punto en el tiempo luego del inicio (<span class="math inline">\(t_3\)</span>).</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">p</th>
<th align="left">AA</th>
<th align="left">Aa</th>
<th align="left">aa</th>
<th align="left">Homocigotos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Población 1</td>
<td align="left">1.0000</td>
<td align="left">1.0000</td>
<td align="left">0.0000</td>
<td align="left">0.0000</td>
<td align="left">1.0000</td>
</tr>
<tr class="even">
<td align="left">Población 2</td>
<td align="left">0.7000</td>
<td align="left">0.4900</td>
<td align="left">0.4200</td>
<td align="left">0.0900</td>
<td align="left">0.5800</td>
</tr>
<tr class="odd">
<td align="left">Población 3</td>
<td align="left">0.3000</td>
<td align="left">0.0900</td>
<td align="left">0.4200</td>
<td align="left">0.4900</td>
<td align="left">0.5800</td>
</tr>
<tr class="even">
<td align="left">Población 4</td>
<td align="left">0.0000</td>
<td align="left">0.0000</td>
<td align="left">0.0000</td>
<td align="left">1.0000</td>
<td align="left">1.0000</td>
</tr>
<tr class="odd">
<td align="left">media</td>
<td align="left"><strong>0.5000</strong></td>
<td align="left"><strong>0.3950</strong></td>
<td align="left"><strong>0.2100</strong></td>
<td align="left"><strong>0.3950</strong></td>
<td align="left"><strong>0.7900</strong></td>
</tr>
</tbody>
</table>
<p>Ahora, además de haber nuevamente aumentado la proporción de homocigotos respecto al punto anterior en el tiempo, también tenemos un fenómeno nuevo: dos poblaciones solo tienen (y tendrán a futuro) genotipos homocigotos ya que se ha fijado uno de los dos alelos. Todo esto ocurre sin cambiar la frecuencia alélica media del <strong>ensemble</strong>. Más aún, si recordamos el comportamiento de las frecuencias alélicas en el tiempo, y como lo veremos en detalle más adelante, tarde o temprano las poblaciones terminan cayendo en alguna de las dos “trampas” que son las <strong>barreras absorbentes</strong>, los estados de fijación o pérdida (fijación del otro alelo), por lo que este comportamiento de la <em>Población 1</em> y <em>Población 4</em> es también esperable para las otras dos poblaciones. En ese momento ya no quedarán heterocigotos en el <strong>ensemble</strong>, pese a que la frecuencia alélica se mantiene como al inicio.</p>
<p>Para entender mejor y poder cuantificar este fenómeno de la reducción del número de heterocigotos debemos pasar a entender primero unos conceptos sobre los que abundaremos más adelante en el capítulo <a href="aparnoalazar.html#aparnoalazar">Apareamientos no-aleatorios</a>. Como vimos previamente, el concepto de alelo ha ido variando en el tiempo a medida de que nuestro conocimiento sobre la biología molecular y la genética han llevado a entender las bases de la variación genética. Sin embargo, hay un aspecto en que las cosas no han cambiado mucho: el origen de la similaridad o diferencia entre alelos. En ausencia de mutación, cuando un alelo es diferente de otro en la presente generación, nos resulta obvio de dónde viene la diferencia: dos alelos son diferentes en esta generación porque provienen de diferentes alelos en la generación previa y hay poca distinción más que agregar. Sin embargo, cuando dos alelos son “iguales” (decimos que es el mismo alelo) en la presente generación, podemos ser más precisos sobre el origen de esta similitud: los dos alelos “iguales” en la presente generación pueden provenir de dos alelos “iguales” en la generación previa, pero que no sean copias del mismo ADN que los generó, o pueden ser copias del mismo ADN (gametos del mismo individuo y del mismo cromosoma), en cuyo caso los llamamos <strong>idénticos por ascendencia</strong>. Este concepto es fundamental, así que asegúrate de haberlo entendido. En ambos casos, cuando los dos alelos son “iguales” independientemente del origen, decimos que son <strong>idénticos en estado</strong>. Claramente, excepto por mutaciones recurrentes en el tiempo, si nos retrotraemos en el pasado lo suficiente, todos los alelos <strong>idénticos en estado</strong> deberían venir del mismo alelo original, y por lo tanto serían de alguna manera <strong>idénticos por ascendencia</strong>, por lo que el marco de referencia es fundamental para decidir a partir de cuando vamos a empezar a contar.</p>
<p>La probabilidad de que <strong>los dos alelos en un individuo</strong> sean <strong>idénticos por ascendencia</strong> se simboliza comúnmente con la letra <span class="math inline">\(F\)</span>, a partir de <span class="citation"><a href="#ref-wright1922" role="doc-biblioref">Sewall Wright</a> (<a href="#ref-wright1922" role="doc-biblioref">1922</a>)</span> que lo llamó coeficiente de fijación. Nosotros vamos a utilizar un subíndice para denotar el tiempo desde la generación <span class="math inline">\(0\)</span>, que consideramos la generación inicial. Supongamos que queremos calcular la probabilidad de que dos alelos sean <strong>idénticos por ascendencia</strong> en la generación <span class="math inline">\(t\)</span>, es decir <span class="math inline">\(F_t\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:recursionFt"></span>
<img src="figuras/recursionFt2.png" alt="Ilustración del razonamiento atrás de la recursión para F en una población de tamaño finito. Existen dos alternativas disjuntas (de ahí la suma) para que un alelo sea idéntico por ascendencia en la generación t: que los alelos provengan del mismo alelo en la generación t-1, cuya probabilidad es \(\frac{1}{2N}\) (y en ese caso F=1) o que los alelos provengan de distintas copias en la generación t-1 y en ese caso la probabilidad de que sean idénticos por ascendencia es por definición \(F_{t-1}\). El resultado de esto es la recursión para la probabilidad de que dos alelos sean idénticos por ascendencia en la generación \(t\), es decir \(F_t=\frac{1}{2N}+\left(1-\frac{1}{2N}\right) F_{t-1}\)." width="543" />
<p class="caption">
Figure 3.8: Ilustración del razonamiento atrás de la recursión para <em>F</em> en una población de tamaño finito. Existen dos alternativas disjuntas (de ahí la suma) para que un alelo sea idéntico por ascendencia en la generación <em>t</em>: que los alelos provengan del mismo alelo en la generación <em>t-1</em>, cuya probabilidad es <span class="math inline">\(\frac{1}{2N}\)</span> (y en ese caso <em>F</em>=1) o que los alelos provengan de distintas copias en la generación <em>t-1</em> y en ese caso la probabilidad de que sean idénticos por ascendencia es por definición <span class="math inline">\(F_{t-1}\)</span>. El resultado de esto es la recursión para la probabilidad de que dos alelos sean idénticos por ascendencia en la generación <span class="math inline">\(t\)</span>, es decir <span class="math inline">\(F_t=\frac{1}{2N}+\left(1-\frac{1}{2N}\right) F_{t-1}\)</span>.
</p>
</div>
<p>Como se ilustra en la figura <a href="deriva.html#fig:recursionFt">3.8</a>, existen dos posibilidades mutuamente excluyentes para que dos alelos sean <strong>idéntico por ascendencia</strong> en la generación <span class="math inline">\(t\)</span>: a) que los dos alelos provengan del mismo alelo en la generación <span class="math inline">\(t-1\)</span>, un evento cuya probabilidad es <span class="math inline">\(\frac{1}{2N}\)</span> (ya que hay <span class="math inline">\(2N\)</span> alelos en la población y por lo tanto la probabilidad de volver a muestrear el mismo es <span class="math inline">\(\frac{1}{2N}\)</span>) y en ese caso <span class="math inline">\(F=1\)</span> ya que al venir del mismo alelo este es <strong>idéntico por ascendencia</strong> a sí mismo con probabilidad de 1 y b) que los alelos provengan de distintas copias en la generación <span class="math inline">\(t-1\)</span> y en ese caso la probabilidad de que sean <strong>idénticos por ascendencia</strong> es por definición <span class="math inline">\(F_{t-1}\)</span>. Como se trata de dos eventos disjuntos (puede pasar uno u otro, pero no los dos a la vez), puedo sumar sus probabilidades para tener</p>
<p><span class="math display" id="eq:recursionF1">\[\begin{equation}
F_t=\frac{1}{2N}+\left(1-\frac{1}{2N}\right) F_{t-1}
\tag{3.5}
\end{equation}\]</span></p>
<p>Es decir, tengo la forma de calcular la probabilidad de dos alelos sean <strong>idénticos por ascendencia</strong> en una generación basado en que conozco dicha probabilidad para la generación anterior. Veamos ahora si podemos llegar a una expresión general para la probabilidad de dos alelos sean <strong>idénticos por ascendencia</strong> en una generación basado en el número de generaciones transcurridas y la probabilidad inicial <span class="math inline">\(F_0\)</span>. Si a ambos lados de la ecuación <a href="deriva.html#eq:recursionF1">(3.5)</a> lo multiplicamos por <span class="math inline">\(-1\)</span> y le sumamos <span class="math inline">\(1\)</span> tenemos</p>
<p><span class="math display" id="eq:recursionF2">\[\begin{equation}
1-F_t=1-\frac{1}{2N}-\left(1-\frac{1}{2N}\right) F_{t-1}=\left(1-\frac{1}{2N}\right)(1-F_{t-1})
\tag{3.6}
\end{equation}\]</span></p>
<p>Pero con la misma lógica,</p>
<p><span class="math display" id="eq:recursionF3">\[\begin{equation}
1-F_{t-1}=\left(1-\frac{1}{2N}\right)(1-F_{t-2})
\tag{3.7}
\end{equation}\]</span></p>
<p>y sustituyendo <a href="deriva.html#eq:recursionF3">(3.7)</a> en <a href="deriva.html#eq:recursionF2">(3.6)</a>, tenemos</p>
<p><span class="math display" id="eq:recursionF4">\[\begin{equation}
1-F_t=\left(1-\frac{1}{2N}\right)\left(1-\frac{1}{2N}\right)(1-F_{t-2})=\left(1-\frac{1}{2N}\right)^2(1-F_{t-2})
\tag{3.8}
\end{equation}\]</span></p>
<p>Prosiguiendo con la recursión hasta llegar a la generación <span class="math inline">\(0\)</span>, la generación inicial, como transcurren <span class="math inline">\(t\)</span> generaciones entre la <span class="math inline">\(0\)</span> y la actual, entonces tenemos que <a href="deriva.html#eq:recursionF4">(3.8)</a> se generaliza a</p>
<p><span class="math display" id="eq:recursionF5">\[\begin{equation}
1-F_t=\left(1-\frac{1}{2N}\right)^t(1-F_{0})
\tag{3.9}
\end{equation}\]</span></p>
<p>Más aún, si suponemos que en la generación inicial, por falta de conocimiento acerca de la probabilidad de que dos alelos sean idénticos por ascendencia asignamos arbitrariamente <span class="math inline">\(F_0=0\)</span>, entonces <a href="deriva.html#eq:recursionF5">(3.9)</a> se transforma en</p>
<p><span class="math display" id="eq:recursionF6">\[\begin{equation}
1-F_t=\left(1-\frac{1}{2N}\right)^t\\
F_t=1-\left(1-\frac{1}{2N}\right)^t
\tag{3.10}
\end{equation}\]</span></p>
<p>Veamos ahora como se relaciona todo esto con el problema de la subdivisión poblacional planteado en la figura <a href="deriva.html#fig:subdivPob">3.7</a>. Por definición, <span class="math inline">\(F\)</span> es también la reducción en heterocigosis o el incremento en homocigosis respecto al equilibrio de Hardy-Weinberg (y sus frecuencias genotípicas) en poblaciones finitas (porque es la probabilidad de que dos alelos sean idénticos por ascendencia en un individuo, por lo tanto homocigoto). Entonces, el paralelismo de <span class="math inline">\(1-F\)</span> es respecto a los heterocigotos conservados y el apareamiento aleatorio. Si consideramos que la frecuencia esperada de heterocigotas en una población de tamaño finito es una función de <span class="math inline">\(p\)</span> y <span class="math inline">\(q\)</span>, pero también de esa probabilidad de que los alelos no sean idénticos por ascendencia, entonces si llamamos <span class="math inline">\(H_t\)</span> a esa frecuencia, tenemos,</p>
<p><span class="math display">\[\begin{equation}
H_t=2pq(1-F_{t-1})\\
\therefore 1-F_{t-1}=\frac{H_t}{2pq}
\end{equation}\]</span></p>
<p>El <span class="math inline">\(t-1\)</span> en el término <span class="math inline">\((1-F_{t-1})\)</span> se corresponde con el hecho de que el efecto de la reducción de los pares de alelos <strong>NO idénticos por ascendencia</strong> se ve en la generación anterior a la presente. Sustituyendo en <a href="deriva.html#eq:recursionF5">(3.9)</a></p>
<p><span class="math display" id="eq:recursionF7">\[\begin{equation}
1-F_t=\frac{H_t}{2pq}=\left(1-\frac{1}{2N}\right)^t(1-F_{0}) \\
\therefore H_t=\left(1-\frac{1}{2N}\right)^t [2pq(1-F_{0})]
\tag{3.11}
\end{equation}\]</span></p>
<p>Pero <span class="math inline">\([2pq(1-F_{0})]\)</span> en la ecuación <a href="deriva.html#eq:recursionF7">(3.11)</a> es la cantidad inicial de heterocigotas, teniendo en cuenta la posibilidad de que ya en esa generación inicial existiese una reducción de la frecuencia esperada respecto a Hardy-Weinberg (o sea, <span class="math inline">\(F_0 \ne 0\)</span>), por lo que podemos escribir esta última ecuación como</p>
<p><span class="math display" id="eq:recursionF8">\[\begin{equation}
H_t=\left(1-\frac{1}{2N}\right)^t H_0 \approx H_0 e^{\frac{-t}{2N}}
\tag{3.12}
\end{equation}\]</span></p>
<p>Es decir, pese a que en cada una de las poblaciones se mantiene el equilibrio de Hardy-Weinberg, como se puede apreciar en la figura <a href="deriva.html#fig:figura3p9">3.9</a>, la proporción de individuos heterocigotos en el conjunto de ellas, o mejor dicho el promedio en el <strong>ensemble</strong>, decaerá en forma geométrica respecto al valor inicial a lo largo del tiempo ya que la proporción en cada generación es multiplicada por el factor <span class="math inline">\(\left(1-\frac{1}{2N}\right)\)</span> para pasar a la siguiente (la aproximación exponencial funciona en general razonablemente bien y me permite resolver algunos problemas en forma más sencilla). El efecto de la reducción en la proporción de heterocigotos es realmente drástico cuando los tamaños poblacionales son extremadamente pequeños, por ejemplo <span class="math inline">\(N=5\)</span> o <span class="math inline">\(N=10\)</span> individuos en la figura <a href="deriva.html#fig:figura3p9">3.9</a>, pero son apenas notables cuando el número de individuos es 50 o más (notar que para 100 el individuos el punto de reducción a <span class="math inline">\(50\%\)</span> de la heterocigosis inicial ni siquiera aparece en la gráfica ya que llevaría más de 138 generaciones para alcanzarlo).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p9"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p9-1.png" alt="Reducción esperada en el número inicial de heterocigotas $H_0$ de acuerdo al tamaño **N** de las poblaciones y al número de generaciones transcurridas. La línea negra horizontal marca la reducción a la mitad del valor inicial y los puntos sobre las curvas resaltan el número de generaciones requeridas para esa reducción a la mitad." width="672" />
<p class="caption">
Figure 3.9: Reducción esperada en el número inicial de heterocigotas <span class="math inline">\(H_0\)</span> de acuerdo al tamaño <strong>N</strong> de las poblaciones y al número de generaciones transcurridas. La línea negra horizontal marca la reducción a la mitad del valor inicial y los puntos sobre las curvas resaltan el número de generaciones requeridas para esa reducción a la mitad.
</p>
</div>
<hr />
<div id="ejemplo-3.1" class="section level4 unnumbered">
<h4>Ejemplo 3.1</h4>
<p>La ecuación <a href="deriva.html#eq:recursionF8">(3.12)</a>, en particular la aproximación exponencial, nos permite estimar facilmente los tiempos hasta determinado nivel de reducción de la frecuencia inicial de heterocigotos. Por ejemplo, para alcanzar la mitad del valor inicial (<span class="math inline">\(H_0\)</span>), con poblaciones de <span class="math inline">\(N\)</span> individuos puedo hacer <span class="math inline">\(H_t=\frac{H_0}{2}\)</span>. Luego, de acuerdo a la ecuación <a href="deriva.html#eq:recursionF8">(3.12)</a> tenemos que</p>
<p><span class="math display">\[\begin{equation*}
H_t=\frac{H_0}{2}=H_0e^{\frac{-t}{2N}}\\
\therefore \frac{1}{2}=e^{\frac{-t}{2N}}
\end{equation*}\]</span></p>
<p>Aplicando el logaritmo a ambos lados de la ecuación, tenemos</p>
<p><span class="math display">\[\begin{equation*}
\ln\left(\frac{1}{2}\right)=\ln\left(e^{\frac{-t}{2N}}\right)=\frac{-t}{2N}
\end{equation*}\]</span></p>
<p>y finalmente</p>
<p><span class="math display">\[\begin{equation*}
t=-2N \ln\left(\frac{1}{2}\right) \approx 1,39N
\end{equation*}\]</span></p>
<p>Es decir, en <span class="math inline">\(1,39N\)</span> generaciones. Si lo hubiésemos hecho sin la aproximación, el procedimiento es análogo y llegaríamos a</p>
<p><span class="math display">\[\begin{equation*}
\frac{H_0}{2}=\left(1-\frac{1}{2N}\right)^t H_0 \therefore t=\frac{\ln{\left(\frac{1}{2}\right)}}{\ln{\left(1-\frac{1}{2N}\right)}}
\end{equation*}\]</span></p>
<p>que si bien es la solución exacta, no es lineal en el número de individuos en cada población.</p>
<hr />
<p>Resumiendo, en esta sección vimos como la subdivision poblacional produce el efecto de disminuir el número de heterocigotas respecto a los esperado para las poblaciones del <strong>ensemble</strong> agregadas en un solo grupo y bajo condiciones de <strong>panmixia</strong> (es decir, con libertad de aparearse con cualquier otro individuo de la población, sin restricciones genéticas, conductuales o ambientales). Esa disminución de la proporción de heterocigotos esperados ocurre a una tasa constante por generación (en nuestro modelo) y la misma es de <span class="math inline">\(\left(1-\frac{1}{2N}\right)\)</span>, por lo que la reducción total a lo largo de <span class="math inline">\(t\)</span> generaciones será del orden de <span class="math inline">\(\left(1-\frac{1}{2N}\right)^t\)</span>. Mientras que en la sección <a href="deriva.html#el-modelo-de-wright-fisher">El modelo de Wright-Fisher</a> construimos un modelo de evolución de las frecuencias alélicas sin preocuparnos de los genotipos, en esta sección vimos las implicancias para la evolución de los genotipos tiene dicho modelo. En la sección <a href="deriva.html#cadenas-de-markov">Cadenas de Markov</a> veremos de otra forma una conexión entre los dos fenómenos utilizando una aproximación fundamental para comprender los procesos estocásticos en general.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<ul>
<li><p>La recursión para el <strong>coeficiente de fijación</strong> <span class="math inline">\(F\)</span> en la generación <span class="math inline">\(t\)</span>, <span class="math inline">\(F_t\)</span> es igual a:
<span class="math display">\[\begin{equation*}
1-F_t=\left(1-\frac{1}{2N}\right)^t(1-F_0)
\end{equation*}\]</span></p></li>
<li><p>Cuando <span class="math inline">\(F_0=0\)</span>, es decir que asumimos que en la <strong>generación inicial</strong> la probabilidad de que dos alelos en un locus de un individuo diploide es cero, entonces la recursión anterior se simplifica a:</p></li>
</ul>
<p><span class="math display">\[\begin{equation*}
F_t=1-\left(1-\frac{1}{2N}\right)^t
\end{equation*}\]</span></p>
<ul>
<li>El número de heterocigotos en un <strong>ensemble</strong> de poblaciones de tamaño finito <span class="math inline">\(N\)</span> se ve reducido de generación en generación respecto a lo esperado para el equilibrio de Hardy-Weinberg. Esa reducción es a la tasa de <span class="math inline">\(\left(1-\frac{1}{2N}\right)\)</span> por generación, por lo que la frecuencia de heterocigotos en la generación <span class="math inline">\(t\)</span> se calcula de acuerdo a la siguiente ecuación:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
H_t=\left(1-\frac{1}{2N}\right)^t H_0 \approx H_0 e^{\frac{-t}{2N}}
\end{equation*}\]</span></p>
</div>
<!-- \begin{equation} -->
<!-- \mathcal{H}_t=\mathcal{H}_0 (1-\frac{1}{2N})^t -->
<!-- \end{equation} -->
<!-- \begin{equation} -->
<!-- \mathcal{G}'=\frac{1}{2N}+(1-\frac{1}{2N})\mathcal{G} -->
<!-- \end{equation} -->
<!-- \begin{equation} -->
<!-- \mathcal{H}'=1-\mathcal{G}'=1-(1-\frac{1}{2N})\mathcal{H} -->
<!-- \end{equation} -->
</div>
</div>
</div>
<div id="cadenas-de-markov" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Cadenas de Markov</h2>
<p>Si recuerdas la ecuación <a href="deriva.html#eq:WrightFisher">(3.2)</a> de más arriba, establecía la probabilidad de transición de un número <span class="math inline">\(i\)</span> de copias a un número <span class="math inline">\(j\)</span> (en un total de <span class="math inline">\(2N\)</span> alelos), en una generación y la misma era igual a:</p>
<p><span class="math display" id="eq:WrightFisher2">\[\begin{equation}
T_{ij}={2N \choose j}\left(\frac{i}{2N}\right)^{j}\left(\frac{2N-i}{2N}\right)^{2N-j}=\frac{(2N)!}{j!(2N-j)!}p^jq^{2N-j}
\tag{3.13}
\end{equation}\]</span></p>
<p>Visto de otra forma, como <span class="math inline">\(i\)</span> puede ir desde <span class="math inline">\(0\)</span> hasta <span class="math inline">\(2N\)</span> y lo mismo para <span class="math inline">\(j\)</span>, podemos poner estas probabilidad de transición en una matriz cuadrada con <span class="math inline">\(2N+1\)</span> filas y <span class="math inline">\(2N+1\)</span> columnas (el <span class="math inline">\(+1\)</span> es debido a que <span class="math inline">\(0\)</span> alelo es posible). Por ejemplo, calculemos la matriz para una población con 2 individuos diploides. Para ello vamos a calcular en forma explícita las probabilidades de transición de unas pocas celdas de la matriz y el resto sigue la misma lógica. En particular, vamos a calcular algunas celdas de la fila correspondientes a 2 alelos <strong>A</strong> en la generación actual (o sea <span class="math inline">\(p=\frac{2}{4}=\frac{1}{2}=0,5\)</span>), es decir la probabilidad de pasar <span class="math inline">\(i=2\)</span> a un número <span class="math inline">\(j\)</span> determinado en la próxima generación.</p>
<p>De acuerdo a la ecuación <a href="deriva.html#eq:WrightFisher2">(3.13)</a>, la probabilidad de transición de 2 copias del alelo <strong>A</strong> (<span class="math inline">\(i=2\)</span>) a 1 copia del mismo (<span class="math inline">\(j=1\)</span>) es de:</p>
<p><span class="math display">\[\begin{equation}
T_{2,1}={4 \choose 1}\left(\frac{2}{4}\right)^{1}\left(\frac{4-2}{4}\right)^{4-1}={4 \choose 1}\left(\frac{1}{2}\right)^{1}\left(\frac{1}{2}\right)^{3}=4 \left(\frac{1}{2}\right)^4=0,25
\end{equation}\]</span></p>
<p>Asimismo, la probabilidad de transición de 2 copias del alelo <strong>A</strong> (<span class="math inline">\(i=2\)</span>) a 3 copias del mismo (<span class="math inline">\(j=3\)</span>) es de:</p>
<p><span class="math display">\[\begin{equation}
T_{2,3}={4 \choose 3}\left(\frac{2}{4}\right)^{3}\left(\frac{4-2}{4}\right)^{4-3}={4 \choose 3}\left(\frac{1}{2}\right)^{3}\left(\frac{1}{2}\right)^{1}=4 \left(\frac{1}{2}\right)^4=0,25
\end{equation}\]</span></p>
<p>De la misma manera, la probabilidad de transición de 2 copias del alelo <strong>A</strong> (<span class="math inline">\(i=2\)</span>) a 4 copias del mismo (<span class="math inline">\(j=4\)</span>) es de:</p>
<p><span class="math display">\[\begin{equation}
T_{2,4}={4 \choose 4}\left(\frac{2}{4}\right)^{4}\left(\frac{4-2}{4}\right)^{4-4}={4 \choose 4}\left(\frac{1}{2}\right)^{4}\left(\frac{1}{2}\right)^{0}=1 \left(\frac{1}{2}\right)^4=0,0625
\end{equation}\]</span></p>
<p>En la tabla <a href="deriva.html#tab:matrizMarkov">3.5</a> puedes ver el resultado de calcular las probabilidades de transición para todos los pares de estados posibles (pares entrada-salida, o generación actual-próxima generación, <span class="math inline">\(0 \leq i \leq 2N\)</span>, <span class="math inline">\(0 \leq j \leq 2N\)</span>). Llamaremos a esta matriz <span class="math inline">\(T\)</span>, por ser la matriz de probabilidad de <strong>transiciones</strong> de estado. En las filas tenemos los posibles estados en la generación actual, definidos como el número de alelos <strong>A</strong> en la generación actual, mientras que en las columnas tenemos el número de alelos <strong>A</strong> en la generación próxima. Se trata de probabilidades, ya que lo visto hasta ahora es que el apareamiento de acuerdo al modelo de Wright-Fisher generará poblaciones descendientes en forma aleatoria, con una probabilidad dada por esta matriz de transición. Es de notar que los estados actuales de <strong>0</strong> y <strong>4</strong> alelos <strong>A</strong> se corresponden a lo que definimos como <strong>barreras absorbentes</strong> de nuestro sistema, pues una vez alcanzado alguno de estos dos estados será imposible abandonarlos (estamos asumiendo la ausencia de mutación). Dicho de otra forma, una vez que se pierde el alelo <strong>A</strong> en una población (<span class="math inline">\(0\)</span> copias del mismo), o que el mismo queda fijado en la población (<span class="math inline">\(2N\)</span> copias, en nuestro ejemplo <span class="math inline">\(2N=4\)</span> copias), en las próximas generaciones esto no va a cambiar.</p>
<table>
<caption><span id="tab:matrizMarkov">Table 3.5: </span>Matriz de transición para un locus con dos alelos y dos individuos diploides.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">a 0 alelos A</th>
<th align="right">a 1 alelos A</th>
<th align="right">a 2 alelos A</th>
<th align="right">a 3 alelos A</th>
<th align="right">a 4 alelos A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">de 0 alelos A</td>
<td align="right">1.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
</tr>
<tr class="even">
<td align="left">de 1 alelos A</td>
<td align="right">0.3164</td>
<td align="right">0.4219</td>
<td align="right">0.2109</td>
<td align="right">0.0469</td>
<td align="right">0.0039</td>
</tr>
<tr class="odd">
<td align="left">de 2 alelos A</td>
<td align="right">0.0625</td>
<td align="right">0.2500</td>
<td align="right">0.3750</td>
<td align="right">0.2500</td>
<td align="right">0.0625</td>
</tr>
<tr class="even">
<td align="left">de 3 alelos A</td>
<td align="right">0.0039</td>
<td align="right">0.0469</td>
<td align="right">0.2109</td>
<td align="right">0.4219</td>
<td align="right">0.3164</td>
</tr>
<tr class="odd">
<td align="left">de 4 alelos A</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">1.0000</td>
</tr>
</tbody>
</table>
<p>Excelente! Tenemos computada nuestra matriz de transiciones. Si observas con cuidado verás que la suma de cada fila es igual a 1, es decir <span class="math inline">\(\sum_{j=0}^{2N} p_{i,j}=1\)</span>. Esto quiere decir que las poblaciones que parten de <span class="math inline">\(i\)</span> alelos en la generación padre deben distribuirse entre todas las posibilidades <span class="math inline">\(j\)</span>, pero que en última instancia al tratarse de un probabilidad la suma de todas las posibilidades disjuntas debe ser igual a 1. Veamos ahora como la podemos usar para calcular la evolución de las frecuencias alélicas en un <strong>ensemble</strong> de poblaciones, todas del mismo tamaño y que parten de la misma frecuencia alélica. Supongamos que todas estas poblaciones parten en tiempo <span class="math inline">\(t=0\)</span> de <span class="math inline">\(i=2\)</span> alelos <strong>A</strong>. Entonces, si representamos las frecuencia de poblaciones en las que hay <span class="math inline">\(i\)</span> alelos con un vector de largo <span class="math inline">\(2N+1\)</span>, la primera posición representando la frecuencia de poblaciones con 0 alelos <strong>A</strong>, la segunda la frecuencia de poblaciones con 1 alelo <strong>A</strong>, la tercera con 2 alelos <strong>AA</strong> y así hasta la posición <span class="math inline">\(2n+1=5\)</span> en nuestro caso, como todas las poblaciones arrancan desde <span class="math inline">\(i=2\)</span>, nuestro vector de frecuencias será <span class="math inline">\(\mathbf{I}_0=(0;0;1;0;0)\)</span>. Ahora, si multplicamos este <strong>vector fila</strong> <span class="math inline">\(\mathbf{I}_0\)</span> por nuestra matríz <span class="math inline">\(\mathbf{T}\)</span> de transiciones (si precisas recordar como se multiplican matrices y vectores, recurre al <a href="apendice-a-conceptos-matemáticos-básicos.html#apendice-a-conceptos-matemáticos-básicos">APENDICE A: Conceptos Matemáticos Básicos</a>), obtendremos un nuevo vector de probabilidad de que las distintas poblaciones del <strong>ensemble</strong> posean un número determinado de alelos <strong>A</strong> (<a href="deriva.html#tab:vectorProbabilidades1">3.6</a>), <span class="math inline">\(\mathbf{I}_1=\mathbf{I}_0 * \mathbf{T}\)</span>.</p>
<table>
<caption><span id="tab:vectorProbabilidades1">Table 3.6: </span>Vector de probabilidades de que una población en nuestro ensemble se encuentre en un estado alélico determinado luego de la primera generación (<span class="math inline">\(I_1\)</span>).</caption>
<thead>
<tr class="header">
<th align="right">0 alelos A</th>
<th align="right">1 alelos A</th>
<th align="right">2 alelos A</th>
<th align="right">3 alelos A</th>
<th align="right">4 alelos A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0625</td>
<td align="right">0.25</td>
<td align="right">0.375</td>
<td align="right">0.25</td>
<td align="right">0.0625</td>
</tr>
</tbody>
</table>
<p>Es decir, si bien partimos de que todas las poblaciones poseían 2 alelos <strong>A</strong>, por efecto del azar (<strong>deriva genética</strong> le llamamos a este efecto), ahora un <span class="math inline">\(6,25\%\)</span> de ellas poseerán 0 alelos <strong>A</strong> (se habrá perdido el mismo), un <span class="math inline">\(25\%\)</span> 1 alelo <strong>A</strong>, un <span class="math inline">\(37,5\%\)</span> 2 alelos <strong>A</strong>, otro <span class="math inline">\(25\%\)</span> 3 alelos <strong>A</strong> y finalmente, <span class="math inline">\(6,25\%\)</span> de ellas tendrán todos los 4 alelos <strong>A</strong> (habrán fijado ese alelo). Ahora, la misma matriz de transición que aplicamos para pasar de la generación <span class="math inline">\(t=0 \to t=1\)</span> la podemos aplicar al vector de probabilidades (frecuencias relativas) de poblaciones en la generación <span class="math inline">\(t=1\)</span> para pasar a la <span class="math inline">\(t=2\)</span> (las probabilidades de transición entre estados no cambian con el paso del tiempo, es decir se trata de una cadena de markov homogénea o estacionaria en el tiempo). Es decir que ahora tenemos <span class="math inline">\(\mathbf{I}_2=\mathbf{I}_1 * \mathbf{T}\)</span>, cuyo resultado podemos apreciar en <a href="deriva.html#tab:vectorProbabilidades2">3.7</a>.</p>
<table>
<caption><span id="tab:vectorProbabilidades2">Table 3.7: </span>Vector de probabilidades de que una población en nuestro ensemble se encuentre en un estado alélico determinado luego de la segunda generación (<span class="math inline">\(I_2\)</span>).</caption>
<thead>
<tr class="header">
<th align="right">0 alelos A</th>
<th align="right">1 alelos A</th>
<th align="right">2 alelos A</th>
<th align="right">3 alelos A</th>
<th align="right">4 alelos A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.166</td>
<td align="right">0.2109</td>
<td align="right">0.2461</td>
<td align="right">0.2109</td>
<td align="right">0.166</td>
</tr>
</tbody>
</table>
<p>Este procedimiento podemos repetirlo de generación en generación. Cuando un proceso estocástico depende solamente del estado inmediantamente anterior en el tiempo, como en nuestro caso, decimos que se trata de un proceso Markoviano. Una cadena de Márkov<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> es una secuencia de eventos (usualmente en el tiempo) en la que cada resultado depende exclusivamente del resultado precedente. Dicho de otra manera, para predecir el siguiente resultado del proceso (futuro) solo la información del presente estado es relevante y el pasado (los estados anteriores del sistema) no tienen relevancia. A esto último se le conoce como <strong>propiedad markoviana</strong> (o de <strong>falta de memoria</strong>). En nuestro caso, como la distribución de probabilidades de cada nueva generación <span class="math inline">\(t=k\)</span> es determinada multiplicando el resultado de la anterior (<span class="math inline">\(\mathbf{I}_{t=(k-1)}\)</span>) por la matriz de transición (<span class="math inline">\(\mathbf{T}\)</span>), claramente podemos ver por qué se trata de una <strong>cadena</strong> (de Márkov). Si comparamos la evolución de nuestro sistema, tenemos ahora que desde la generación <span class="math inline">\(t=0\)</span> hasta la generación <span class="math inline">\(t=5\)</span>, la frecuencias han ido cambiando de la manera que se aprecia en la tabla <a href="deriva.html#tab:evolProbabilidades1">3.8</a>.</p>
<table>
<caption><span id="tab:evolProbabilidades1">Table 3.8: </span>Evolución del vector de probabilidades de que una población en nuestro ensemble se encuentre en un estado alélico determinado desde la generación 0 a la quinta generación.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">0 alelos A</th>
<th align="right">1 alelos A</th>
<th align="right">2 alelos A</th>
<th align="right">3 alelos A</th>
<th align="right">4 alelos A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">t=0</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
<td align="right">1.0000</td>
<td align="right">0.0000</td>
<td align="right">0.0000</td>
</tr>
<tr class="even">
<td align="left">t=1</td>
<td align="right">0.0625</td>
<td align="right">0.2500</td>
<td align="right">0.3750</td>
<td align="right">0.2500</td>
<td align="right">0.0625</td>
</tr>
<tr class="odd">
<td align="left">t=2</td>
<td align="right">0.1660</td>
<td align="right">0.2109</td>
<td align="right">0.2461</td>
<td align="right">0.2109</td>
<td align="right">0.1660</td>
</tr>
<tr class="even">
<td align="left">t=3</td>
<td align="right">0.2490</td>
<td align="right">0.1604</td>
<td align="right">0.1813</td>
<td align="right">0.1604</td>
<td align="right">0.2490</td>
</tr>
<tr class="odd">
<td align="left">t=4</td>
<td align="right">0.3117</td>
<td align="right">0.1205</td>
<td align="right">0.1356</td>
<td align="right">0.1205</td>
<td align="right">0.3117</td>
</tr>
<tr class="even">
<td align="left">t=5</td>
<td align="right">0.3587</td>
<td align="right">0.0904</td>
<td align="right">0.1017</td>
<td align="right">0.0904</td>
<td align="right">0.3587</td>
</tr>
</tbody>
</table>
<p>Otra forma de verlo, más gráfica aparece en la figura <a href="deriva.html#fig:figura3p6">3.10</a>. Claramente se aprecia que mientras que las probabilidades de encontrarse en los estados intermedios (<span class="math inline">\(i=1\)</span> a <span class="math inline">\(i=3\)</span>, en gris) decrece, la de los estados correspondientes a las <strong>barreras absorbentes</strong> (rojo=pérdida, azul=fijación) crece en la misma medida. La pregunta sería ¿hacia donde va este movimiento?, o dicho de otra forma que ocurre si seguimos de generación en generación.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p6"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p6-1.png" alt="Evolución de la probabilidad de encontrar a las poblaciones en un estado alélico determinado desde la generación $t=0$ a $t=5$ (de izquierda arriba a derecha abajo). En rojo el etado de 0 alelos **A** (pérdida del mismo), en azul 4 alelos **A** (fijación del mismo) y en gris oscuro 2 alelos (nuestro punto de partida en todas las poblaciones). Notar la diferente escala de la generación $t=0$ al resto." width="672" />
<p class="caption">
Figure 3.10: Evolución de la probabilidad de encontrar a las poblaciones en un estado alélico determinado desde la generación <span class="math inline">\(t=0\)</span> a <span class="math inline">\(t=5\)</span> (de izquierda arriba a derecha abajo). En rojo el etado de 0 alelos <strong>A</strong> (pérdida del mismo), en azul 4 alelos <strong>A</strong> (fijación del mismo) y en gris oscuro 2 alelos (nuestro punto de partida en todas las poblaciones). Notar la diferente escala de la generación <span class="math inline">\(t=0\)</span> al resto.
</p>
</div>
<p>Antes que eso, es interesante notar que <span class="math inline">\(\mathbf{I}_2=\mathbf{I}_1 * \mathbf{T} = (\mathbf{I}_0 * \mathbf{T}) * \mathbf{T} = \mathbf{I}_0 * (\mathbf{T} * \mathbf{T})=\mathbf{I}_0 * \mathbf{T}^2\)</span> (el producto de matrices es asociativo y la potenciación de matrices es el producto <span class="math inline">\(n\)</span> veces de la matriz con si misma, distinto de elevar a la <span class="math inline">\(n\)</span> cada celda de la misma). Claramente lo anterior se puede generalizar a <span class="math inline">\(\mathbf{I}_{t=k}=\mathbf{I}_0 * \mathbf{T}^{(k-1)}\)</span>. En palabras, para calcular la distribución de probabilidades de los estados (número de alelos <strong>A</strong> en nuestro <strong>ensemble</strong> de poblaciones) en cualquier generación (por ejemplo <span class="math inline">\(t=k\)</span>, <span class="math inline">\(k&gt;0\)</span>) basta con multplicar la distribución en la generación inicial (o sea en <span class="math inline">\(t=0\)</span>, que llamamos <span class="math inline">\(\mathbf{I}_0\)</span>) por la matriz de transición de probabilidades elevada a la potencia <span class="math inline">\(k-1\)</span>.</p>
<p>Volvamos entonces a la pregunta anterior. ¿Hacia dónde va el movimiento de las frecuencias en las distintas poblaciones a largo plazo? Para eso, teniendo en cuenta el razonamiento de que <span class="math inline">\(\mathbf{I}_{t=k}=\mathbf{I}_0 * \mathbf{T}^{(k-1)}\)</span>, resulta interesante ver cómo se comporta <span class="math inline">\(\mathbf{T}^{(k-1)}\)</span> cuando <span class="math inline">\(k \to \infty\)</span>, es decir cuando el número de generaciones va a infinito. Una aproximación numérica sencilla consiste en elevar <span class="math inline">\(\mathbf{T}\)</span> a un número suficientemente grande, por ejemplo 50 generaciones y ver la forma que adquiere la matriz, como aparece en la tabla <a href="deriva.html#tab:matrizMarkov50">3.9</a>.</p>
<table>
<caption><span id="tab:matrizMarkov50">Table 3.9: </span>Matriz de transición para un locus con dos alelos y dos individuos diploides luego de 50 generaciones.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">a 0 alelos A</th>
<th align="right">a 1 alelos A</th>
<th align="right">a 2 alelos A</th>
<th align="right">a 3 alelos A</th>
<th align="right">a 4 alelos A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">de 0 alelos A</td>
<td align="right">1.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">de 1 alelos A</td>
<td align="right">0.75</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.25</td>
</tr>
<tr class="odd">
<td align="left">de 2 alelos A</td>
<td align="right">0.50</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.50</td>
</tr>
<tr class="even">
<td align="left">de 3 alelos A</td>
<td align="right">0.25</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.75</td>
</tr>
<tr class="odd">
<td align="left">de 4 alelos A</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.00</td>
</tr>
</tbody>
</table>
<p>Si miramos las columnas de la matriz <a href="deriva.html#tab:matrizMarkov50">3.9</a> podemos apreciar dos situaciones claramente distintas; en las columnas 2, 3 y 4 (que corresponden a pasar de una generación a la siguiente a los estados de 1, 2 y 3 alelos <strong>A</strong> respectivamente), todas las celdas son 0, es decir más allá del punto de arranque (el vector de frecuencias o probabilidades <span class="math inline">\(\mathbf{I}_0\)</span>), cuando el tiempo tiende a infinito (en principio lo estaríamos viendo con solo 50 generaciones) estos estados alélicos estarán vacíos (ninguna población tendrá 1, 2 o 3 alelos <strong>A</strong>), en nuestro modelo de dos individuos diploides). En cambio, las columnas 1 y 5, que se corresponden a la fijación del alelo <strong>a</strong> (pérdida del <strong>A</strong>) y la fijación del <strong>A</strong> respectivamente plantean una distribución que parece en espejo una de otra; claramente estas columnas se corresponden a las dos <strong>barreras absorbentes</strong>. Si nos fijamos en la columna 1, el único 0 se corresponde a la probabilidad de pasar de 4 alelos <strong>A</strong> a 0 alelo <strong>A</strong>, lo que es trivial ya que si el alelo <strong>A</strong> se encuentra fijado, al no existir mutación es imposible que las poblaciones evolucionen a otro estado alélico. Inversamente, en la columna 5 el único 0 se corresponde a la probabilidad de pasar de 0 a 4 alelos <strong>A</strong>, lo que es también trivial ya que no existe posibilidad de pasar del <strong>a</strong> fijado a otro estado. El resto de las celdas es fácil de explicar. Para terminar fijando en alelo <strong>a</strong>, cuando se parte de 1 solo <strong>A</strong>, es decir 3 <strong>a</strong>, la probabilidad de fijarse el <strong>a</strong> es <span class="math inline">\(\frac{3}{4}\)</span>; cuando se parte de 2 alelos <strong>A</strong>, es de <span class="math inline">\(\frac{2}{4}=\frac{1}{2}\)</span> y cuando se parte de 3 alelos <strong>A</strong>, es decir solo 1 <strong>a</strong>, la probabilidad de terminar fijando <strong>a</strong> es <span class="math inline">\(\frac{1}{4}\)</span>. De forma inversa para la columna 5.</p>
<p>La conclusión de todo lo anterior no es menor: con la matriz de probabilidad de transiciones <span class="math inline">\(\mathbf{T}\)</span> (<a href="deriva.html#tab:matrizMarkov">3.5</a>) el estado estacionario (cuando <span class="math inline">\(t \to \infty\)</span>) implica que <strong>solo los estados de fijación de alguno de los alelos tienen probabilidad mayor a cero</strong>. El punto de partida solo influirá en la distribución entre ellos, pero no en que solo ellos pueden tener probabilidad positiva. Pongamos un ejemplo: todas las poblaciones inicialmente tienen 1 alelo <strong>A</strong> de los 4 posibles (recordar que son dos individuos diploides, <span class="math inline">\(2N=4\)</span>), es decir, <span class="math inline">\(\mathbf{I}_0=(0;1;0;0;0)\)</span>. Si multiplicamos este vector inicial de probabilidades (probabilidades de encontrar poblaciones del <strong>ensemble</strong> en ese estado), tenemos que <span class="math inline">\(\mathbf{I}_0*\mathbf{T}^\infty\)</span> (llamamos <span class="math inline">\(\mathbf{T}^\infty\)</span> a la potencia infinita, aunque en este contexto <span class="math inline">\(\mathbf{T}^{50} \sim \mathbf{T}^\infty\)</span>), el resultado es <span class="math inline">\(\mathbf{I}_0*\mathbf{T}^\infty=(0,75;0;0;0;0,25)\)</span>, claramente en línea con lo que esperábamos: ninguna población aún segregando (1, 2 o 3 alelos <strong>A</strong>), <span class="math inline">\(75\%\)</span> de la poblaciones con el alelo <strong>a</strong> fijado y <span class="math inline">\(25\%\)</span> de las poblaciones con el alelo <strong>A</strong> fijado.</p>
<p>Si en lugar de haber arrancado con todas las poblaciones con 1 solo alelo <strong>A</strong>, hubiésemos arrancado con <span class="math inline">\(25\%\)</span> de las poblaciones con 1 alelo <strong>A</strong>, <span class="math inline">\(25\%\)</span> con dos alelos y <span class="math inline">\(50\%\)</span> con 3 alelos <strong>A</strong>, entonces <span class="math inline">\(\mathbf{I}_0=(0;0,25;0,25;0,50;0)\)</span>. Por lo tanto <span class="math inline">\(\mathbf{I}_0*\mathbf{T}^\infty=(0,4375;0;0;0;0,5625)\)</span>, es decir que el <span class="math inline">\(43,75\%\)</span> de las poblaciones de nuestro <strong>ensemble</strong> tendrían fijado el alelo <strong>a</strong> y el restante <span class="math inline">\(56,25\%\)</span> tendría fijado el alelo <strong>A</strong>.</p>
<p>En general, si la deriva genética es la única fuerza evolutiva actuante (sin selección, sin mutación, sin migración), el equilibrio se alcanza cuando más tarde o más temprano todas las poblaciones se encuentran fijadas para uno de los dos alelos.</p>
<p>Un último punto que cabe mencionar acá. Si observamos la forma en la que crece la suma de los estados correspondientes a las <strong>barreras absorbentes</strong>, es posible demostrar que a partir de determinado punto la tasa de aproximación al estado de equilibrio es igual a <span class="math inline">\((1-\frac{1}{2N})\)</span>. Dicho de otra forma, a partir de determinado momento, a cada generación la proporción de poblaciones aún segregantes se reduce en <span class="math inline">\(\frac{1}{2N_e}\)</span>, proporción que va a parar a los estados correspondientes a las <strong>barreras absorbentes</strong>.</p>
<!-- ```{r evolFijados, echo = FALSE, cache=TRUE, warning=FALSE} -->
<!-- I0=c(0,0,1,0,0) -->
<!-- I1<-I0%*%(mimat%^%1) -->
<!-- I2<-I0%*%(mimat%^%2) -->
<!-- I3<-I0%*%(mimat%^%3) -->
<!-- I4<-I0%*%(mimat%^%4) -->
<!-- I5<-I0%*%(mimat%^%5) -->
<!-- J<-rbind(I0,I1,I2,I3,I4,I5) -->
<!-- midf<-data.frame("fija a"=J[,1],"fija A"=J[,5],"total fijados"=J[,1]+J[,5],"total segregando"=1-(J[,1]+J[,5])) -->
<!-- knitr::kable(midf,digits=4,caption='Evolución de la proporción de poblaciones fijadas para uno de los dos alelos.',col.names = gsub("[.]", " ", colnames(midf))) -->
<!-- ``` -->
</div>
<div id="tamaño-efectivo-poblacional" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Tamaño efectivo poblacional</h2>
<p>Un punto que mencionamos antes pero no abundamos fue la diferencia entre el tamaño censal de una población, es decir el número <span class="math inline">\(N\)</span> de individuos que la conforman y el tamaño efectivo de la misma, que llamamos <span class="math inline">\(N_e\)</span>. A veces resulta claro cuando en determinadas estructuras poblacionales particulares no tienen ningún sentido el número <span class="math inline">\(N\)</span> como un indicador del comportamiento genético de la población, por ejemplo cuando un solo macho es responsable de todas las crías, pero otras veces no resulta tan claro. En todo caso, dada la dependencia de varias de nuestras ecuaciones de algún número que represente el tamaño poblacional, es necesario definir que significa ese número a la luz de las cosas que hemos asumido en nuestros modelos.</p>
<p>Un ejemplo claro lo representa el supuesto de tamaña poblacional constante que hemos usado en el modelo de Wright-Fisher. Desafortunadamente, este supuesto es difícil de constatar en la realidad ya que las poblaciones fluctuan de tamaño, algunas en forma de tendencia (al crecimiento o decrecimiento) y otras a través de ciclos (por ejemplo, tamaños poblacionales de presa y predador, que se están íntimamente relacionados). En este sentido, podríamos pensar en obtener un número poblacional en una población <strong>perfecta</strong> (para nuestro modelo) en la que de alguna manera el efecto genético de la deriva fuese equivalente al de nuestra población real. Si el tamaño poblacional fluctua en el tiempo, podríamos por ejemplo pensar en que la media aritmética (el clásico promedio, que conoces muy bien) del tamaño censal sería un buen resumen del impacto genético de la deriva en la población. Desafortunadamente, el impacto genético de los tamaños poblacionales pequeños es desproporcionadamente alto, como puede verse en la figura <a href="deriva.html#fig:figura3p8">3.11</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p8"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p8-1.png" alt="Efecto de un cuello de botella poblacional en la frecuencia alélica. La población de 100 alelos, 50 rojos y 50 azules, se ve drásticamente reducida en una generación a 4 alelos (entre las dos líneas verdes), que por muestreo aleatorio son ahora 3 azules y 1 rojo. Luego de ese cuello de botella la población vuelve a expandirse al nivel inicial, pero la frecuencia ya quedó alterada en forma importante (figura propia sobre idea de @Hamilton2009)." width="672" />
<p class="caption">
Figure 3.11: Efecto de un cuello de botella poblacional en la frecuencia alélica. La población de 100 alelos, 50 rojos y 50 azules, se ve drásticamente reducida en una generación a 4 alelos (entre las dos líneas verdes), que por muestreo aleatorio son ahora 3 azules y 1 rojo. Luego de ese cuello de botella la población vuelve a expandirse al nivel inicial, pero la frecuencia ya quedó alterada en forma importante (figura propia sobre idea de <span class="citation"><a href="#ref-Hamilton2009" role="doc-biblioref">Hamilton</a> (<a href="#ref-Hamilton2009" role="doc-biblioref">2009</a>)</span>).
</p>
</div>
<p>En efecto, pese a que la población inicial era de 50 individuos diploides, o sea 100 alelos, 50 rojos y 50 azules, al sufrir un cuello de botella poblacional (sobreviven 2 individuos diploides, marcado por las dos líneas verdes en la figura <a href="deriva.html#fig:figura3p8">3.11</a>) se muestrean 3 alelos azules y 1 rojo (un evento que tiene una probabilidad de <span class="math inline">\(\frac{1}{4}=25\%\)</span>). Al expandirse nuevamente la población a 50 individuos, es decir 100 alelos, lo hará desde la frecuencia del cuello de botella. Resulta clara la influencia desproporcionada (respecto a un promedio simple) que tiene el muestreo durante el cuello de botella poblacional.</p>
<p>Veamos entonces una forma más razonable de estimar el tamaño de una población que fluctua en número. Para hacer nuestro razonamiento supongamos que la población va de la generación 0 hasta la 2. De acuerdo a lo que vimos en la sección de <a href="deriva.html#homocigosidad-y-heterocigosidad">Homocigosidad y Heterocigosidad</a>,</p>
<p><span class="math display" id="eq:F1">\[\begin{equation}
1-F_2=\left(1-\frac{1}{2N_1}\right)(1-F_1) 
\tag{3.14}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:F2">\[\begin{equation}
1-F_1=\left(1-\frac{1}{2N_0}\right)(1-F_0) 
\tag{3.15}
\end{equation}\]</span></p>
<p>Sustituyendo <a href="deriva.html#eq:F2">(3.15)</a> en <a href="deriva.html#eq:F1">(3.14)</a>, tenemos:</p>
<p><span class="math display" id="eq:F3">\[\begin{equation}
1-F_2=\left(1-\frac{1}{2N_1}\right)\left(1-\frac{1}{2N_0}\right)(1-F_0) 
\tag{3.16}
\end{equation}\]</span></p>
<p>Si el tamaño <span class="math inline">\(N\)</span> fuese constante, obtendríamos el <span class="math inline">\(N_e\)</span> generalizando esta expresión para un tiempo <span class="math inline">\(t\)</span>:</p>
<p><span class="math display" id="eq:F4">\[\begin{equation}
1-F_t=\left(1-\frac{1}{2N_e}\right)^t(1-F_0) 
\tag{3.17}
\end{equation}\]</span></p>
<p>Por ejemplo, en el caso en que <span class="math inline">\(t=2\)</span>, la ecuación <a href="deriva.html#eq:F4">(3.17)</a> se transforma en:</p>
<p><span class="math display" id="eq:F5">\[\begin{equation}
1-F_2=\left(1-\frac{1}{2N_e}\right)^2(1-F_0) 
\tag{3.18}
\end{equation}\]</span></p>
<p>Ahora, si igualamos el resultado “real” (ecuación <a href="deriva.html#eq:F3">(3.16)</a>) a la “ideal” (ecuación <a href="deriva.html#eq:F5">(3.18)</a>), tenemos:</p>
<p><span class="math display" id="eq:F6">\[\begin{equation}
1-F_2=\left(1-\frac{1}{2N_e}\right)^2(1-F_0)=\left(1-\frac{1}{2N_1}\right)\left(1-\frac{1}{2N_0}\right)(1-F_0)=1-F_2\\
\left(1-\frac{1}{2N_e}\right)^2=\left(1-\frac{1}{2N_1}\right)\left(1-\frac{1}{2N_0}\right)
\tag{3.19}
\end{equation}\]</span></p>
<p>Desarrollando la ecuación <a href="deriva.html#eq:F6">(3.19)</a>, tenemos que:</p>
<p><span class="math display" id="eq:F7">\[\begin{equation}
1-2\frac{1}{2N_e}+\frac{1}{4N_e^2}=1-\frac{1}{2N_0}-\frac{1}{2N_1}+\frac{1}{4N_0N_1}\\
\frac{1}{N_e}-\frac{1}{4N_e^2}=\frac{1}{2}\left(\frac{1}{N_0}+\frac{1}{N_1}\right)-\frac{1}{4N_0N_1}
\tag{3.20}
\end{equation}\]</span></p>
<p>y considerando que los términos en <span class="math inline">\(\frac{1}{4N_e^2}\)</span> y <span class="math inline">\(\frac{1}{4N_0N_1}\)</span> no afectan casi el resultado, porque su orden es casi similar, llegamos a que:</p>
<p><span class="math display" id="eq:F7">\[\begin{equation}
\frac{1}{N_e}=\frac{1}{2}\left(\frac{1}{N_0}+\frac{1}{N_1}\right)
\tag{3.20}
\end{equation}\]</span></p>
<p>es una muy buena aproximación. De hecho, esto significa que <span class="math inline">\(N_e\)</span> es la <strong>media armónica</strong> entre <span class="math inline">\(N_0\)</span> y <span class="math inline">\(N_1\)</span>. En general, para <span class="math inline">\(t \ge 2\)</span> la media armónica (el recíproco de la media de recíprocos) es un buen indicador del <strong>tamaño efectivo poblacional</strong>:</p>
<p><span class="math display" id="eq:Ne1">\[\begin{equation}
\frac{1}{N_e}=\frac{1}{t}\left(\frac{1}{N_0}+\frac{1}{N_1}+\frac{1}{N_2}+...+\frac{1}{N_{t-1}} \right)\\
N_e=\frac{t}{\left(\frac{1}{N_0}+\frac{1}{N_1}+\frac{1}{N_2}+...+\frac{1}{N_{t-1}} \right)}
\tag{3.21}
\end{equation}\]</span></p>
<hr />
<div id="ejemplo-3.3" class="section level4 unnumbered">
<h4>Ejemplo 3.3</h4>
<p>Un productor rural y exportardor de la raza “Scottish Blackface” (figura <a href="deriva.html#fig:ScottishBlackface">3.12</a>) posee un rebaño de <span class="math inline">\(N=1000\)</span> animales (mitad machos, mitad hembras), cuando por razón de la crisis debe vender 900 de ellos (suponemos que 450 machos y 450 hembras). Una generación después ya cuenta con <span class="math inline">\(N=200\)</span> animales. Calcular el tamaño efectivo poblacional en esta última generación, asumiendo que la generación inicial era la de <span class="math inline">\(N=1000\)</span> animales.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ScottishBlackface"></span>
<img src="figuras/ScottishBlackface.png" alt="Scottish Blackface en la isla de Lewis, Hébridas Exteriores (a partir de imagen en wikipedia, autores Iain and Sarah from London, UK)." width="416" />
<p class="caption">
Figure 3.12: Scottish Blackface en la isla de Lewis, Hébridas Exteriores (a partir de imagen en wikipedia, autores Iain and Sarah from London, UK).
</p>
</div>
<p>De acuerdo a la ecuación <a href="deriva.html#eq:Ne1">(3.21)</a>, debemos calcular la media armónica entre el <span class="math inline">\(N\)</span> de las <span class="math inline">\(t=3\)</span> generaciones, es decir</p>
<p><span class="math display">\[\begin{equation}
N_e=\frac{3}{\left(\frac{1}{N_0}+\frac{1}{N_1}+\frac{1}{N_2}\right)}\\
N_e=\frac{3}{\left(\frac{1}{1000}+\frac{1}{100}+\frac{1}{200}\right)}=187,5 \sim 188 \text{ animales}\\
\end{equation}\]</span></p>
<hr />
<p>Otra fuente importante de diferencias entre el tamaño censal y el tamaño efectivo de una población es el desequilibrio entre el número de machos y el número de hembras, como veremos en detalle en otros capítulos. En general, si una población está constituida por <span class="math inline">\(N_m\)</span> machos y <span class="math inline">\(N_h\)</span> hembras, el número total de animales (individuos) es <span class="math inline">\(N_a=N_m+N_h\)</span>, mientras que (como deduciremos en otro capítulo), para una generación determinada</p>
<p><span class="math display" id="eq:Ne2">\[\begin{equation}
N_e=\frac{4N_mNh}{N_m+N_h}
\tag{3.22}
\end{equation}\]</span></p>
<p>Cuando el número de hembras es igual al número de machos (<span class="math inline">\(N_h=N_m=\frac{N}{2}\)</span>), algo bastante raro en las poblaciones comerciales (al menos de mamíferos), tenemos que para la misma generación la ecuación <a href="deriva.html#eq:Ne2">(3.22)</a> se transforma en</p>
<p><span class="math display" id="eq:Ne3">\[\begin{equation}
N_e=\frac{4N_mNh}{N_m+N_h}=\frac{4\frac{N}{2}\frac{N}{2}}{\frac{N}{2}+\frac{N}{2}}=\frac{N^2}{N}=N\\
\tag{3.23}
\end{equation}\]</span></p>
<p>Es decir, <span class="math inline">\(N_e=N\)</span>, el tamaño efectivo poblacional es igual al tamaño censal.</p>
<hr />
</div>
<div id="ejemplo-3.4" class="section level4 unnumbered">
<h4>Ejemplo 3.4</h4>
<p>El productor anterior decidió fundar otro núcleo cerrado, con 1020 animales en total, 1000 ovejas y 20 carneros de la raza Scottish Blackface. Calcula el tamaño poblacional de la misma.</p>
<p>De acuerdo a la ecuación <a href="deriva.html#eq:Ne2">(3.22)</a>, el tamaño efectivo de esta población es</p>
<p><span class="math display">\[\begin{equation}
N_e=\frac{4N_mN_h}{N_m+N_h}=\frac{4 \cdot 20 \cdot 1000}{20+1000}=\frac{80000}{1020}=78,43 \sim 78 \text{ animales}\\
\end{equation}\]</span></p>
<hr />
<p>Finalmente, otra versión del tamaño efectivo poblacional es la que sale de nuestra definición del modelo ideal y de cuanto esperamos que sea su varianza. Si llamamos <span class="math inline">\(\Delta p=p_t-p_{t-1}\)</span>, es decir a la diferencia entre la frecuencia promedio en la generación <span class="math inline">\(t\)</span> y la generación anterior (<span class="math inline">\(t-1\)</span>), entonces la varianza de <span class="math inline">\(\Delta p\)</span> estará dada por</p>
<p><span class="math display">\[\begin{equation}
Var(\Delta p)=\frac{p_{t-1}q_{t-1}}{2N}
\end{equation}\]</span></p>
<p>cuando el proceso cumple con todos los requerimientos del modelo de Wright-Fisher. Pero esto mismo podemos usarlo para estimar cuál sería el tamaño efectivo poblacional que generaría la misma varianza empírica que tenemos en <span class="math inline">\(\Delta p\)</span>, <span class="math inline">\(N_e^v\)</span>. Es decir, despejando <span class="math inline">\(N\)</span>, que ahora llamaremos <span class="math inline">\(N_e^v\)</span>, que es nuestra incógnita asumiendo que proviene de un proceso perfecto Wright-Fisher, tenemos</p>
<p><span class="math display">\[\begin{equation}
N_e^v=\frac{pq}{2 Var(\Delta p)}
\end{equation}\]</span></p>
<p>En resumen, en esta última forma de calcular el tamaño efectivo poblacional hemos asumido que la varianza entre generaciones en la media de frecuencias alélicas proviene de un proceso de Wright-Fisher y esto nos permite estimar cuál sería el tamaño de las poblaciones que se corresponden con esa varianza.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<ul>
<li><p>El tamaño efectivo de una población (<span class="math inline">\(N_e\)</span>) raramente coincide con el tamaño censal de la misma (<span class="math inline">\(N\)</span>), siendo las razones para esto diversas (variación del tamaño en el tiempo, diferente número de macho que de hembras, diferencias muy importantes en el número de descendientes entre reproductores candidatos, etc.).</p></li>
<li><p>El efecto conocido como <strong>cuello de botella</strong> (<strong>bottleneck</strong>) poblacional se refiere a la <strong>reducción drástica</strong> del número de reproductores en algún momento de la vida de una población determinada y aunque luego la misma experimente una nueva expansión, el cuello de botella dejará huellas indelebles a nivel de la variabilidad genómica.</p></li>
<li><p>El tamaño efectivo poblacional cuando varía el tamaño de la población en el tiempo se puede calcular como la media armónica entre los tamaños a cada generación:</p></li>
</ul>
<p><span class="math display">\[\begin{equation}
N_e=\frac{t}{\left(\frac{1}{N_0}+\frac{1}{N_1}+\frac{1}{N_2}+...+\frac{1}{N_{t-1}} \right)}
\end{equation}\]</span></p>
<ul>
<li>Cuando el número de reproductores machos es diferente del número de reproductores hembras, el tamaño efectivo de la población es inferior a la suma de individuos y lo podemos calcular como</li>
</ul>
<p><span class="math display">\[\begin{equation}
N_e=\frac{4N_mNh}{N_m+N_h}
\end{equation}\]</span></p>
<ul>
<li>Si asumimos que se trata de un proceso de Wright-Fisher perfecto, podemos obtener un estimado del tamaño efectivo poblacional que se corresponde con la varianza en la media de frecuencias alélicas entre generaciones a partir de la dicha varianza <strong>observada</strong> mediante</li>
</ul>
<p><span class="math display">\[\begin{equation}
N_e^v=\frac{pq}{2 Var(\Delta p)}
\end{equation}\]</span></p>
</div>
</div>
</div>
<div id="aproximación-de-difusión" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Aproximación de difusión</h2>
<hr />
<p>NOTA: Gran parte de los desarrollos de esta sección siguen directamente el libro <span class="citation"><a href="#ref-HartlClark2007" role="doc-biblioref">Hartl and Clark</a> (<a href="#ref-HartlClark2007" role="doc-biblioref">2007</a>)</span>, que entendemos es de los más claros al nivel del presente curso, mientras que otros siguen el libro de <span class="citation"><a href="#ref-WalshLynch2018" role="doc-biblioref">Walsh and Lynch</a> (<a href="#ref-WalshLynch2018" role="doc-biblioref">2018</a>)</span> que posee un apéndice dedicado al tema. Otras fuentes importantes son el libro de <span class="citation"><a href="#ref-DennyGaines2000" role="doc-biblioref">Denny and Gaines</a> (<a href="#ref-DennyGaines2000" role="doc-biblioref">2000</a>)</span> para los procesos de difusión en biología y el libro de <span class="citation"><a href="#ref-Hamilton2009" role="doc-biblioref">Hamilton</a> (<a href="#ref-Hamilton2009" role="doc-biblioref">2009</a>)</span>, que seguimos directamente también (más allá de modificaciones mínimas) y que trata con cierto detalle pero a un nivel muy razonable la aproximación por difusión en genética (que a su vez sigue el de <span class="citation"><a href="#ref-DennyGaines2000" role="doc-biblioref">Denny and Gaines</a> (<a href="#ref-DennyGaines2000" role="doc-biblioref">2000</a>)</span>).</p>
<p>Inevitablemente, esta sección es bastante técnica y usaremos cálculo diferencial e integral en múltiples variables, así como algunos conceptos básicos de ecuaciones diferenciales en derivadas parciales. Si te sientes un poco oxidado en estos temas, en el <a href="apendice-b-cálculo-diferencial-e-integral-ecuaciones-diferenciales.html#apendice-b-cálculo-diferencial-e-integral-ecuaciones-diferenciales">APENDICE B: Cálculo Diferencial e Integral, ecuaciones diferenciales</a> podrás repasar los principales conceptos.</p>
<p>Dada la complejidad de esta sección, no pretendemos que seas capaz de reproducir o aún entender cada paso o derivación (aunque nos pondría muy contentos si así fuese). Si te resulta imposible entender no te desanimés ya que podrás seguir el resto del curso en forma independiente de las derivaciones de esta sección. La idea es que puedas entender de dónde surgen algunos resultados muy importantes que veremos en este y otros capítulos. Es muy importante para la mente científica conocer y entender el origen de resultados y fórmulas que utilizarás a lo largo de tu carrera, tanto como estudiante como profesional. <strong><em>¡Ánimo!</em></strong></p>
<hr />
<p>Como vimos más arriba (<a href="deriva.html#cadenas-de-markov">Cadenas de Markov</a>), la evolución del número de copias de un alelo en poblaciones idénticas es un proceso estocástico discreto y la evolución de los estados puede seguirse a través de la multiplicación de la matriz de probabilidades de transición (cadenas de Markov). Sin embargo, esta aproximación suele ser dificultosa o imposible en la práctica para manejar modelos más complejos y una buena aproximación para comprender el comportamiento a largo plazo viene por el lado de los procesos de difusión. En efecto, si consideramos el tiempo como una variable continua, re-escalando el tiempo en generaciones que habíamos utilizado hasta ahora mediante la transformación <span class="math inline">\(\tau=\frac{t}{N}\)</span> y escalando el número de copias del alelo <strong>A</strong> (<span class="math inline">\(i\)</span>) de tal forma que <span class="math inline">\(x=\frac{i}{2N}\)</span>, cuando <span class="math inline">\(N \to \infty\)</span> ambas variables pasan a ser continuas.</p>
<div id="caminatas-al-azar-y-procesos-de-difusión" class="section level3 unnumbered">
<h3>Caminatas al azar y procesos de difusión</h3>
<p>En la sección <a href="deriva.html#el-modelo-de-wright-fisher">El modelo de Wright-Fisher</a> vimos el comportamiento de la frecuencia alélica guiada solo por el proceso de deriva genética. Si observamos nuevamente el trazo dejado por cualquiera de las poblaciones no resulta difícil imaginarse el recorrido de alguien que (posiblemente borracho) a cada instante en el tiempo, decide a través del resultado de tirar una moneda si el siguiente paso es a la derecha o a la izquierda. Más aún, podemos pensar que esta persona se encuentra sobre una línea trazada en el piso y que arranca desde una determinada posición inicial decidiendo con la moneda hacia dónde dar el siguiente paso. Lo que nos interesa entonces es estudiar el comportamiento de este tipo de procesos y ver si podemos hacer algunas predicciones al respecto. Más divertido aún y más cercano a lo que vamos a describir ahora sería un experimento donde a la salida de un bar (en un lugar medio desierto) reclutamos a todos los borrachos disponibles, los ponemos en “fila india” y les explicamos que al sonido de la campana (que tañeremos en forma regular) deben tirar una moneda y en función del resultado dar un paso a la derecha (si sale cara) o a la izquierda (si sale cruz); o aún quedarse quietos si no sintieron la campana o estaban distraídos. Bueno, también se podría hacer sin borrachos, pero intuimos que será mucho más divertido en el primer caso.</p>
<p>En realidad, existe una motivación física mucho más potente y que usaremos como analogía para luego pasar a ver como esa analogía nos puede ayudar a entender los procesos estocásticos en las frecuencias alélicas de nuestras poblaciones. La motivación es muy sencilla: imaginemos que en el instante <span class="math inline">\(t=0\)</span> dejamos caer una gota de tinta en la posición central de un canal horizontal abierto conteniendo agua (el canal se extiende a derecha, signo positivo, e izquierda, signo negativo, de <span class="math inline">\(x=0\)</span>). En ambos extremos del canal tenemos un medio que absorbe las partículas de tinta a medida de que van arribando (es decir, son <strong>barreras absorbentes</strong> para las partículas de tinta). El papel de nuestros “borrachos” lo representarán ahora las pequeñas partículas de tinta que formaban la gota y que ahora, a partir del instante <span class="math inline">\(t=0\)</span> comenzarán a dispersarse en ambas direcciones. Para que nuestra analogía tenga cierto sentido físico y poder estudiar su comportamiento vamos a definir una serie de reglas que se aplican al movimiento individual de cada partícula.</p>
<p><strong>Reglas</strong></p>
<p>1- La partícula comienza en la posición <span class="math inline">\(x=0\)</span> en el instante inicial, <span class="math inline">\(t=0\)</span>.</p>
<p>2- La partícula se mueve <strong>una distancia fija</strong> <span class="math inline">\(\delta\)</span> en cada intervalo de tiempo <span class="math inline">\(\tau\)</span>.</p>
<p>3- La partícula se puede mover solo en el eje permitido, con probabilidad <span class="math inline">\(p=\frac{1}{2}\)</span> hacia la derecha (arbitrariamente, puede ser cualquier dirección) y por lo tanto con probabilidad <span class="math inline">\(q=1-p=1-\frac{1}{2}=\frac{1}{2}\)</span> hacia la izquierda (o en sentido opuesto al anterior).</p>
<p>4- El sentido en el que se mueve es independiente del sentido en la movida anterior, o lo que es lo mismo, se trata de un proceso <strong>sin memoria</strong> (recordar lo visto en la sección <a href="deriva.html#cadenas-de-markov">Cadenas de Markov</a>).</p>
<p>5- Pueden existir tantas particulas como se quiera en la misma posición del eje sin interferir unas con otras (es como si cada una “corriese” por su propio carril, todos los carriles paralelos unos a otros).</p>
<p>En la figura <a href="deriva.html#fig:difusion">3.13</a> podemos ver una representación esquemática de nuestro diseño. En el instante <span class="math inline">\(t=0\)</span> consideramos que cae la gota de tinta (roja) al agua <strong>al mismo tiempo</strong> que las <strong>partículas</strong> que la constituyen comienzan a difundir hacia izquierda y derecha de acuerdo a las reglas que establecimos más arriba.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:difusion"></span>
<img src="figuras/difusion2.png" alt="Diagrama que representa el escenario para el movimiento de nuestras partículas de tinta. En el instante inicial la gota de tinta cae  al mismo tiempo sus partículas constituyentes comienzan a difundir a izquierda y derecha (elaboración propia sobre idea de @Hamilton2009)." width="613" />
<p class="caption">
Figure 3.13: Diagrama que representa el escenario para el movimiento de nuestras partículas de tinta. En el instante inicial la gota de tinta cae al mismo tiempo sus partículas constituyentes comienzan a difundir a izquierda y derecha (elaboración propia sobre idea de <span class="citation"><a href="#ref-Hamilton2009" role="doc-biblioref">Hamilton</a> (<a href="#ref-Hamilton2009" role="doc-biblioref">2009</a>)</span>).
</p>
</div>
<p>Primero, podríamos analizar que ocurre con la posición promedio de las partículas a medida de que avanza el tiempo, por ejemplo en una unidad (<span class="math inline">\(\tau\)</span>). La posición media está dada por</p>
<p><span class="math display">\[\begin{equation}
\bar{x}=p(\delta)+q(-\delta)
\end{equation}\]</span></p>
<p>Como las partículas se mueven a derecha e izquierda con la misma probabilidad, <span class="math inline">\(\delta\)</span> y <span class="math inline">\(-\delta\)</span> unidades de posición, entonces tenemos que luego de una unidad de tiempo <span class="math inline">\(\tau\)</span> la posición media será en nuestro caso</p>
<p><span class="math display" id="eq:difu1">\[\begin{equation}
\bar{x}=\frac{1}{2}(\delta)-\frac{1}{2}(\delta)=0
\tag{3.24}
\end{equation}\]</span></p>
<p>Es decir, que la posición media de las partículas será la misma que al comienzo. Esto no debería extrañarnos dado de que por simetría del problema tantas partículas se moverán hacia un lado como otras en el sentido opuesto, lo que da un balance neto de cero respecto al desplazamiento del punto medio. Entonces, ¿nada ha cambiado? Si recuerdas el comportamiento de las distintas poblaciones en la figura <a href="deriva.html#fig:figura3p5">3.5</a>, posiblemente te habrás imaginado que si bien la media del proceso no cambia, la varianza si lo hace. Si además recuerdas la fórmula para la varianza</p>
<p><span class="math display">\[\begin{equation}
Var(x)=E(x^2)-E^2(x)
\end{equation}\]</span></p>
<p>y que además en nuestro caso <span class="math inline">\(E^2(x)=E(x)E(x)=\bar{x}\bar{x}=0 \cdot 0\)</span>, llegaremos enseguida a la conclusión de que la varianza en posición de las partículas es igual a <span class="math inline">\(E(x^2)\)</span>, o lo que es lo mismo el promedio de las posiciones al cuadrado. Como además, en cada intervalo arbitrariamente pequeño de tiempo la partícula solo puede moverse <span class="math inline">\(\delta\)</span> en uno de los sentidos, la ubicación de la partícula <span class="math inline">\(i\)</span> en el tiempo 1 será igual a</p>
<p><span class="math display">\[\begin{equation}
x_{i,(t=1)}=x_{i,(t=0)}+\delta
\end{equation}\]</span></p>
<p>con <span class="math inline">\(\delta\)</span> positivo o negativo. O sea, para obtener una expresión de la varianza en las posiciones de las partículas, luego de un intervalo arbitrariamente pequeño (de <span class="math inline">\(t=0\)</span> a <span class="math inline">\(t=1\)</span>) debemos comenzar por elevar al cuadrado esta expresión y luego promediar</p>
<p><span class="math display">\[\begin{equation}
x_{i,(t=1)}^2=(x_{i,(t=0)}+\delta)^2\\
x_{i,(t=1)}^2=x_{i,(t=0)}^2+2x_{i,(t=0)}\delta+\delta^2
\end{equation}\]</span></p>
<p>Por lo tanto, promediando el resultado anterior para las N partículas obtenemos</p>
<p><span class="math display">\[\begin{equation}
\sigma^2(x_{i,(t=1)})=\frac{1}{N} \sum_{i=1}^{N} (x_{i,(t=0)}^2+2x_{i,(t=0)}\delta+\delta^2)
\end{equation}\]</span></p>
<p>La expresión anterior se puede simplificar bastante. En primer lugar, por una razón de simetría, habrá tantas partículas que se muevan a la derecha como a la izquierda (recordar <span class="math inline">\(\bar{x}=0\)</span>, ecuación <a href="deriva.html#eq:difu1">(3.24)</a>), por lo que el término del medio es igual a cero. Luego</p>
<p><span class="math display">\[\begin{equation}
\sigma^2(x_{i,(t=1)})=\frac{1}{N}\sum_{i=1}^{N} x_{i,(t=0)}^2 + \frac{1}{N}N\delta^2\\
\sigma^2(x_{i,(t=1)})=\overline{x^2}_{i,(t=0)}+\delta^2
\end{equation}\]</span></p>
<p>Ahora, suponiendo que a <span class="math inline">\(t=0\)</span> todas las partículas salen de la posición cero, entonces el promedio del cuadrado de sus distancias será 0 también (<span class="math inline">\(\overline{x^2}_{i,(t=0)}=0\)</span>), por lo que nos quedamos con <span class="math inline">\(\delta^2\)</span>, es decir el cuadrado del cambio en posición en un intervalo de tiempo, como el incremento en la varianza en un avance arbitrariamente pequeño del tiempo (de <span class="math inline">\(t=0\)</span> a <span class="math inline">\(t=1\)</span>). En un intervalo de tiempo de <span class="math inline">\(t\)</span> unidades, por lo tanto, la varianza de la posición de las partículas será de <span class="math inline">\(t\delta^2\)</span>, o dicho de otra manera, la varianza en la posición de las partículas se incrementa en forma lineal con el tiempo. En el primer instante la varianza será <span class="math inline">\(1 \cdot\delta^2=\delta^2\)</span>, en el segundo instante será <span class="math inline">\(2\delta^2\)</span>, luego <span class="math inline">\(3\delta^2\)</span>, etc. La anterior es una observación más que razonable para describir el fenómeno de cómo una gota de tinta se dispersa en el agua a medida de que pasa el tiempo.</p>
<p>Si definimos el <strong>coeficiente de difusión</strong> de las partículas (<span class="math inline">\(D\)</span>) como la velocidad con que la tinta se difunde en el agua, tenemos que</p>
<p><span class="math display" id="eq:difu2">\[\begin{equation}
D=\frac{1}{2}\frac{d\sigma^2}{dt}
\tag{3.25}
\end{equation}\]</span></p>
<p>La ecuación anterior es fácil de entender, la varianza representa la dispersión de las partículas en un momento dado y por lo tanto su derivada primera respecto del tiempo es su velocidad. Pero la varianza representa dispersión a ambos lados del punto de inicio, por lo que solo la mitad de la misma corresponderá a la magnitud de la velocidad en un sentido (de lo contrario, la velocidad neta siempre sería cero). Como <span class="math inline">\(\sigma^2=t\delta^2\)</span>, entonces</p>
<p><span class="math display" id="eq:difu2p1">\[\begin{equation}
D=\frac{1}{2}\frac{d\sigma^2}{dt}=\frac{1}{2}\frac{d(t\delta^2)}{dt}=\frac{\delta^2}{2}
\tag{3.26}
\end{equation}\]</span></p>
<p>Es decir, <span class="math inline">\(D=\frac{\delta^2}{2}\)</span> es la velocidad de difusión de las partículas, o lo que es lo mismo, un medio del incremento en la varianza en una unidad de tiempo arbitrariamente pequeño.</p>
<p>Volvamos ahora a la genética. ¿Cómo se relaciona esto del proceso de difusión con nuestro tratamiento de la evolución estocástica de las frecuencias alélicas en las poblaciones? En principio es muy sencillo: si consideramos que cada población del <strong>ensemble</strong> es como una partícula en nuestro modelo de difusión, los “movimientos” que puede realizar nuestras poblaciones son en lugar del movimiento físico de las partículas, los cambios en frecuencia alélica en la población. O sea, si por ejemplo, partimos de <span class="math inline">\(p_A=0,5\)</span>, es equivalente como partir del punto medio en el modelo de difusión. Ahora las <strong>barreras absorbentes</strong> estarán en <span class="math inline">\(p_A=0\)</span> y <span class="math inline">\(p_A=1\)</span>. Por otra parte, si recuerdas lo tratado en la sección <a href="deriva.html#el-modelo-de-wright-fisher">El modelo de Wright-Fisher</a>, la <strong>varianza por generación</strong> (o lo que sería un intervalo arbitrariamente pequeño en la difusión) era <span class="math inline">\(\sigma^2(p)=\frac{pq}{2N}\)</span> y la varianza a lo largo del tiempo, en la generación <span class="math inline">\(t\)</span>, por ejemplo igual a <span class="math inline">\(\sigma^2_t(p)=t\frac{pq}{2N}\)</span> (ecuación <a href="deriva.html#eq:varWF">(3.4)</a>, para simplificar la notación llamaremos <span class="math inline">\(\sigma^2\)</span> a <span class="math inline">\(\sigma^2_t(p)\)</span>), por lo que podemos hacer:</p>
<p><span class="math display" id="eq:difu3">\[\begin{equation}
\frac{d\sigma^2}{dt}=\frac{d(t\frac{pq}{2N})}{dt}=\frac{pq}{2N}
\tag{3.27}
\end{equation}\]</span></p>
<p>Si recordamos de la ecuación <a href="deriva.html#eq:difu2">(3.25)</a> que <span class="math inline">\(D=\frac{1}{2}\frac{d\sigma^2}{dt}\)</span> y substituimos en ella el resultado de la ecuación <a href="deriva.html#eq:difu3">(3.27)</a>, tenemos que el coeficiente de difusión <span class="math inline">\(D\)</span> es ahora</p>
<p><span class="math display" id="eq:difu4">\[\begin{equation}
D=\frac{1}{2}\frac{d\sigma^2}{dt}=\frac{1}{2}\frac{pq}{2N}=\frac{pq}{4N}=\frac{p-p^2}{4N}
\tag{3.28}
\end{equation}\]</span></p>
<p>Es decir, el coeficiente de difusión para las frecuencias alélicas de nuestras poblaciones es una función de la frecuencia de los alelos (<span class="math inline">\(p\)</span> y <span class="math inline">\(q\)</span>). El denominador de la ecuación <a href="deriva.html#eq:difu4">(3.28)</a> no depende de las frecuencias ya que se trata de un número <span class="math inline">\(N\)</span> positivo, multiplicado por una constante positiva (4). En cambio, el numerador depende de la frecuencia del alelo <strong>A</strong> (<span class="math inline">\(p\)</span>): si recuerdas de la sección <a href="variación-y-equilibrio-de-hardy-weinberg.html#h-w-la-frecuencia-de-heterocigotas-en-función-de-la-frecuencia-alélica">H-W: la frecuencia de heterocigotas en función de la frecuencia alélica</a>, el producto <span class="math inline">\(p \cdot q\)</span> tiene un máximo cuando <span class="math inline">\(p=q=\frac{1}{2}\)</span>. Es decir la velocidad de difusión (cambio de frecuencias alélicas) será máxima cerca de <span class="math inline">\(p=\frac{1}{2}\)</span> y tenderá a cero a medida que <span class="math inline">\(p\)</span> se acerque a las barreras absorbentes de <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span>. Dicho de otra manera, la velocidad de cambio en la frecuencia en cada población será máximo en el entorno de <span class="math inline">\(p=\frac{1}{2}\)</span>, llevando a las poblaciones hacia las regiones donde el coeficiente de difusión es menor, cerca de las barreras absorbentes, donde al ser menor el coeficiente de difusión permanecerá más tiempo. Por otra parte, el coeficiente de difusión también depende del tamaño poblacional efectivo: a mayor número de individuos en cada una de las poblaciones que constituyen el <strong>ensemble</strong>, menor será el coeficiente de difusión, o lo que es lo mismo menor la velocidad con que cambian las frecuencias de los alelos en cada población.</p>
<p>Procuraremos ahora calcular la probabilidad de que una población se encuentre en una región en particular en el intervalo de frecuencias, o en nuestra analogía de difusión la probabilidad de encontrar una partícula en una posición en particular del eje en que se mueven. Para eso necesitaremos calcular el flujo de partículas en la región de interés, o dicho de otra forma el número neto de partículas que atraviesan un área definida por intervalo de tiempo. Si consideramos un área <span class="math inline">\(A\)</span> el flujo neto de partículas que atraviesa la misma hacia la derecha (arbitrariamente) es igual a la mitad del número de partículas que están a una distancia <span class="math inline">\(\delta\)</span> a la izquierda de la misma (recuerda que en cada posición la mitad de las partículas tenderá a moverse a la izquierda y la otra mitad a la derecha), menos la mitad de la partículas que a una distancia <span class="math inline">\(\delta\)</span> a la derecha del área de referencia (<span class="math inline">\(\delta\)</span> porque es la distancia a la que se mueven en una unidad de tiempo). Es decir:</p>
<p><span class="math display">\[\begin{equation}
N_{neto}(Der)=\frac{1}{2}N(Izq)-\frac{1}{2}N(Der)=-\frac{1}{2}[N(Der)-N(Izq)]
\end{equation}\]</span></p>
<p>Pero el flujo es la cantidad de partículas que atraviesan un área en determinado tiempo, por lo que para obtener una expresión de este en el punto <span class="math inline">\(x\)</span>, que llamaremos <span class="math inline">\(J_x\)</span> debemos dividir por área y por tiempo:</p>
<p><span class="math display">\[\begin{equation}
J_x=-\frac{1}{2}\frac{[N(Der)-N(Izq)]}{At}
\end{equation}\]</span></p>
<p>Si multplicamos esta última expresión por 1, bajo la forma de <span class="math inline">\(\frac{\delta^2}{\delta^2}\)</span>, para luego rearreglar los términos, la misma quedará:</p>
<p><span class="math display" id="eq:difu5">\[\begin{equation}
J_x=-\frac{\delta^2}{2t}\frac{1}{\delta}\frac{[N(Der)-N(Izq)]}{A\delta}=-\frac{\delta^2}{2t}\frac{1}{\delta}\left[\frac{N(Der)}{A\delta}-\frac{N(Izq)}{A\delta}\right]
\tag{3.29}
\end{equation}\]</span></p>
<p>Si observamos los dos términos entre paréntesis rectos de la ecuación anterior, en ambos casos (<span class="math inline">\(\frac{N(Der)}{A\delta}\)</span> y <span class="math inline">\(\frac{N(Izq)}{A\delta}\)</span>) se trata de un número de partículas dividido entre el producto de un área (<span class="math inline">\(A\)</span>) por una distancia (<span class="math inline">\(\delta\)</span>), es decir dividido entre un volumen (recuerda de la escuela cómo calculábamos los volúmenes). Pero el número de partículas divido entre el volumen que ocupan las mismas es la concentración, por lo que podemos llamar <span class="math inline">\(C(Der)\)</span> y <span class="math inline">\(C(Izq)\)</span> a la concentración de partículas a derecha e izquierda de nuestra área. Además, previamente habíamos visto (ecuación <a href="deriva.html#eq:difu2p1">(3.26)</a>) que <span class="math inline">\(\frac{\delta^2}{2}=D\)</span>, por lo que en una unidad de tiempo (<span class="math inline">\(t=1\)</span>), substituyendo en <a href="deriva.html#eq:difu5">(3.29)</a> tenemos:</p>
<p><span class="math display" id="eq:difu6">\[\begin{equation}
J_x=-D\frac{C(Der)-C(Izq)}{\delta}
\tag{3.30}
\end{equation}\]</span></p>
<p>Si asumimos que las partículas se encuentran uniformemente distribuidas en el intervalo entre <span class="math inline">\(x\)</span> y <span class="math inline">\(x+\delta\)</span> su posición promedio será <span class="math inline">\(\frac{\delta}{2}\)</span> (lo mismo para el otro lado, pero ahora será <span class="math inline">\(-\frac{\delta}{2}\)</span>), que tomaremos como posición característica. Entonces <span class="math inline">\(C(Der)=C(x+\frac{\delta}{2})\)</span> y <span class="math inline">\(C(Izq)=C(x-\frac{\delta}{2})\)</span>, por lo que la ecuación <a href="deriva.html#eq:difu6">(3.30)</a> la podemos escribir como:</p>
<p><span class="math display" id="eq:difu7">\[\begin{equation}
J_x=-D\frac{C(x+\frac{\delta}{2})-C(x-\frac{\delta}{2})}{\delta}
\tag{3.31}
\end{equation}\]</span></p>
<p>Si en esta última expresión hacemos el paso al límite cuando las distancias en <span class="math inline">\(x\)</span> son infinitamente pequeñas), es decir cuando <span class="math inline">\(\delta \to 0\)</span>, tenemos que:</p>
<p><span class="math display" id="eq:difu7">\[\begin{equation}
J_x=-D\frac{dC}{dx}
\tag{3.31}
\end{equation}\]</span></p>
<p>que se conoce como la <strong>primer ecuación de difusión de Fick</strong>. Nuevamente, esta ecuación parece sencilla de interpretar. El coeficiente de difusión es un número positivo que indica la velocidad de movimiento de las partículas en el medio. Por otro lado, <span class="math inline">\(\frac{dC}{dx}\)</span> representa el gradiente de la concentración de partículas (en nuestro caso de poblaciones) y cuando su signo es positivo indica la dirección hacia la mayor concentración de partículas. Como acá el producto tiene un signo negativo, la ecuación nos indica que las partículas (poblaciones) se moverán en dirección a donde hay una menor concentración (recordar la analogía con la gota de tinta en agua; la tinta se moverá hacia donde hay menor concentración). Obviamente, en el equilibrio, para cada posición en el eje de movimiento (nuestras frecuencias alélicas) tantas partículas se moverán hacia un lado como hacia el otro.</p>
<p>Pasemos ahora a intentar entender como esto nos puede aportar a entender el comportamiento de las frecuencias alélicas en nuestro <strong>ensemble</strong>. Para esto, debemos recordar que estamos tratando con una aproximación continua (las frecuencias alélicas ya no las expresamos como el número de copias de un alelo sino como este número divido entre <span class="math inline">\(2N\)</span>) y por lo tanto la probabilidad la vamos a sustituir por una <strong>densidad de probabilidad</strong>, que llamaremos <span class="math inline">\(\phi(p,x,t)\)</span> (notar la dependencia del punto inicial de partida <span class="math inline">\(p\)</span>, o sea la frecuencia inicial del alelo <strong>A</strong>). Esta densidad de probabilidad es equivalente a la concentración de partículas. <span class="math inline">\(\phi(p,x,t)\)</span> representa el balance neto entre las poblaciones que arriban a esa frecuencia alélica <span class="math inline">\(x\)</span> y aquellas que se alejan de la misma; pero esto, en nuestro razonamiento previo es el <strong>flujo neto</strong> en el punto <span class="math inline">\(x\)</span>, es decir <span class="math inline">\(J_x\)</span>. De acuerdo a la <strong>ecuación de continuidad</strong>, ya que el material no se crea o destruye,</p>
<p><span class="math display" id="eq:difu8">\[\begin{equation}
\frac{d\phi(p,x,t)}{dt}+\frac{dJ_{x,t}}{dx}=0\\
\frac{d\phi(p,x,t)}{dt}=-\frac{dJ_{x,t}}{dx}
\tag{3.32}
\end{equation}\]</span></p>
<p>Hasta ahora nos hemos manejado asumiendo que el movimiento de las frecuencias alélicas en las distintas poblaciones se debe exclusivamente al azar (por eso <strong>random drift</strong>), pero para hacer más general nuestra ecuación debemos entender que las frecuencias alélicas también pueden variar de forma sistemática, por ejemplo a través de la mutación (fuera del equilibrio mutacional) y selección. La analogía con las partículas de tinta sería a través de suponer que las mismas tienen determinada carga eléctrica y que entre las dos barreras absorbentes existe una diferencia de potencial que hará que las partículas se muevan sistemáticamente en una dirección (efecto superpuesto al aleatorio). Ahora, si llamamos <span class="math inline">\(M(x)\)</span> a ese efecto sistemático, tenemos entonces</p>
<p><span class="math display">\[\begin{equation}
J_{x,t}=M(x)\phi(p,x,t)-D\frac{d\phi(p,x,t)}{dx}
\end{equation}\]</span></p>
<p>por lo que sustituyendo en la ecuación <a href="deriva.html#eq:difu8">(3.32)</a> tenemos</p>
<p><span class="math display" id="eq:difu9">\[\begin{equation}
\frac{d\phi(p,x,t)}{dt}=-\frac{dJ_{x,t}}{dx}=-\frac{d}{dx}\left[M(x)\phi(p,x,t)-D\frac{d\phi(p,x,t)}{dx}\right]
\tag{3.33}
\end{equation}\]</span></p>
<p>Pero la derivación en forma más general de estas ecuaciones, directamente en nuestro dominio, así como las soluciones para casos particulares las veremos en más detalles en las sub-secciones que siguen.</p>
</div>
<div id="kolmogorov-forward-equation" class="section level3 unnumbered">
<h3>Kolmogorov Forward Equation</h3>
<p>Asumiendo que las poblaciones de nuestro <strong>ensemble</strong> son suficientemente grandes, la frecuencia de los alelos se transforma razonablemente en una variable continua que avanza suvamente en el tiempo, sin grandes saltos. En este sentido, la “Kolmogorov Forward Equation” (<strong>KFE</strong>) nos permite analizar el comportamiento en el tiempo de la función continua de probabilidad <span class="math inline">\(\phi(p,x,t)\)</span>, es decir de la densidad de probabilidad de encontrar la frecuencia alélica en <span class="math inline">\(0&lt;x&lt;1\)</span> (notar que es válida solo entre las <strong>barreras absorbentes</strong>, pero no para ellas, es decir en las poblaciones aún segregantes) en determinado tiempo <span class="math inline">\(t\)</span>, partiendo de una frecuencia inicial <span class="math inline">\(p\)</span>.</p>
<p>Para nuestro desarrollo, análogo a lo que hicimos en <a href="deriva.html#caminatas-al-azar-y-procesos-de-difusión">Caminatas al azar y procesos de difusión</a> vamos a permitir pequeños desplazamientos de nuestras variables <span class="math inline">\(x\)</span> y <span class="math inline">\(t\)</span>, es decir <span class="math inline">\(\Delta x\)</span> y <span class="math inline">\(\Delta t\)</span>. Nuevamente, como vimos más arriba, hay dos fuerzas que pueden hacer que <span class="math inline">\(x\)</span> cambie en un intervalo <span class="math inline">\(\Delta t\)</span>: una fuerza sistemática que desplace las frecuencias alélicas siempre en una dirección (nuestro análogo era el campo eléctrico para las partículas de tinta) y que llamaremos <span class="math inline">\(M(x)\)</span> y una fuerza aleatoria, la deriva genética (que en nuestra analogía previa era la difusión por movimiento “Browniano” de las partículas de tinta) que llamaremos <span class="math inline">\(V(x)\)</span>. Sin pérdida de generalidad, vamos a asumir que nuestro alelos favorecido es el <strong>A</strong>, cuya densidad de probabilidad (frecuencia) está dada por <span class="math inline">\(x\)</span> (y la inicial del mismo por <span class="math inline">\(p\)</span>) y que la fuerza sistemática es en el sentido creciente de <span class="math inline">\(x\)</span> (o sea, en sentido de la fijación del <strong>A</strong>). En el cuadro que sigue tenemos detallados los posibles movimientos hacia la “posición” <span class="math inline">\(x\)</span> en un intervalo <span class="math inline">\(\Delta t\)</span> a partir del momento <span class="math inline">\(t\)</span> en que estamos (recordar que en un intervalo <span class="math inline">\(\Delta t\)</span> <span class="math inline">\(x\)</span> solo puede moverse hacia abajo o hacia arriba, pérdida o fijación, una cantidad <span class="math inline">\(\Delta x\)</span>), así como las probabilidades asociadas y la causa del movimiento.</p>
<table>
<colgroup>
<col width="15%" />
<col width="14%" />
<col width="25%" />
<col width="31%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Posición después de <span class="math inline">\(t\)</span> generaciones</th>
<th align="left">Probabilidad de esa frecuencia</th>
<th align="left">Posibilidades de cambiar a <span class="math inline">\(x\)</span> en <span class="math inline">\(\Delta t\)</span></th>
<th align="left">Probabilidad del cambio en <span class="math inline">\(\Delta t\)</span></th>
<th align="left">Fuerza</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x-\Delta x\)</span></td>
<td align="left"><span class="math inline">\(\phi(p,x-\Delta x,t)\)</span></td>
<td align="left"><span class="math inline">\(x-\Delta x \to x\)</span></td>
<td align="left"><span class="math inline">\(M(x-\Delta x)\)</span></td>
<td align="left">Sistemática</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x-\Delta x\)</span></td>
<td align="left"><span class="math inline">\(\phi(p,x-\Delta x,t)\)</span></td>
<td align="left"><span class="math inline">\(x-\Delta x \to x\)</span></td>
<td align="left"><span class="math inline">\(\frac{V(x-\Delta x)}{2}\)</span></td>
<td align="left">Deriva</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(x+\Delta x\)</span></td>
<td align="left"><span class="math inline">\(\phi(p,x+\Delta x,t)\)</span></td>
<td align="left"><span class="math inline">\(x+\Delta x \to x\)</span></td>
<td align="left"><span class="math inline">\(\frac{V(x+\Delta x)}{2}\)</span></td>
<td align="left">Deriva</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x\)</span></td>
<td align="left"><span class="math inline">\(\phi(p,x,t)\)</span></td>
<td align="left"><span class="math inline">\(x \to x\)</span></td>
<td align="left"><span class="math inline">\(1-M(x)-V(x)\)</span></td>
<td align="left">Permanece</td>
</tr>
</tbody>
</table>
<p>Para llegar a <span class="math inline">\(x\)</span> en el próximo intervalo (<span class="math inline">\(t+\Delta t\)</span>), como el máximo recorrido posible en <span class="math inline">\(x\)</span> es <span class="math inline">\(\Delta x\)</span> debo estar a la distancia <span class="math inline">\(\|\Delta x\|\)</span> de <span class="math inline">\(x\)</span>, es decir en <span class="math inline">\(x-\Delta x\)</span> o en <span class="math inline">\(x+\Delta x\)</span>, o una tercera alternativa que es estar ya en <span class="math inline">\(x\)</span> y quedarme en esa posición. Las probabilidades de estar en esas posiciones en el tiempo <span class="math inline">\(t\)</span> son las que aparecen en la segunda columna del cuadro anterior. A cada una de ellas le corresponde una probabilidad de movimiento de <span class="math inline">\(x\)</span> determinada, como aparece en la columna 4 del cuadro. Como asumimos que <span class="math inline">\(M(x)\)</span> va hacia la fijación, solo participaría en la probabilidad de movernos de <span class="math inline">\(x-\Delta x\)</span> a <span class="math inline">\(x\)</span> (y no en el sentido contrario); esa es la razón porque <span class="math inline">\(x-\Delta x\)</span> aparece en dos filas del cuadro. La razón de por qué el efecto de la deriva es <span class="math inline">\(\frac{V(x)}{2}\)</span> es que se trata de una fuerza simétrica y por lo tanto la posibilidad de aumentar <span class="math inline">\(x\)</span> es igual a la de disminuirla y entonces debemos partir a la mitad su efecto para cada lado. Por último, la probabilidad de que <span class="math inline">\(x\)</span> se quede en donde está es el complemento de las otras probabilidades (<span class="math inline">\(M(x)\)</span> y <span class="math inline">\(V(x)\)</span>), ya que al ser probabilidades el conjunto de todos los eventos excluyentes deben sumar <span class="math inline">\(1\)</span>.</p>
<p>Ahora, para analizar el cambio ocurrido entre <span class="math inline">\(\phi(p,x,t+\Delta t)\)</span> y <span class="math inline">\(\phi(p,x,t)\)</span>, si multiplicamos la columna 2 por la 4, sumamos y reordenamos los términos tenemos:</p>
<p><span class="math display">\[\begin{equation}
\phi(p,x,t+\Delta t)-\phi(p,x,t)=\\
-\left[M(x)\phi(p,x,t)-M(x-\Delta x)\phi(p,x-\Delta x,t)\right]\\
+\frac{1}{2}\left\{\left[ V(x+\Delta x)\phi(p,x+\Delta x,t) - V(x)\phi(p,x,t) \right]\\
-\left[ V(x)\phi(p,x,t) - V(x-\Delta x)\phi(p,x-\Delta x,t) \right]\right\}
\end{equation}\]</span></p>
<p>Pero el lado izquierdo de la ecuación anterior representa el cambio en <span class="math inline">\(\phi\)</span> (que podemos representar como <span class="math inline">\(\Delta \phi\)</span>) a partir de un cambio en <span class="math inline">\(t\)</span> (por lo tanto <span class="math inline">\(\Delta t\)</span>). De la misma manera, el primer término del lado derecho de la ecuación representa el cambio en <span class="math inline">\(M\phi\)</span> para un determinado cambio en <span class="math inline">\(x\)</span> (<span class="math inline">\(\Delta x\)</span>). Finalmente, el segundo término es el cambio del cambio en <span class="math inline">\(V\phi\)</span>, notar las dos diferencias en ese término (que representamos como <span class="math inline">\(\Delta\Delta V\phi\)</span>) para un cambio en dos pasos de <span class="math inline">\(x\)</span> (por lo tanto <span class="math inline">\(\Delta\Delta x\)</span>). Poniendo todo junto:</p>
<p><span class="math display">\[\begin{equation}
\frac{\Delta \phi(p,x,t)}{\Delta t}=-\frac{\Delta [M(x)\phi(p,x,t)]}{\Delta x}+\frac{1}{2}\frac{\Delta \{\Delta[V(x)\phi(p,x,t)]\}}{\Delta(\Delta x)}
\end{equation}\]</span></p>
<p>Pasando al límite, cuando <span class="math inline">\(\Delta t \to 0\)</span> y <span class="math inline">\(\Delta x \to 0\)</span>, la ecuación en diferencias converge a una ecuación diferencial parcial, que se conoce como <strong>Kolmogorov Forward Equation</strong> (o <strong>KFE</strong>)<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>:</p>
<p><span class="math display" id="eq:KFE">\[\begin{equation}
\frac{\partial \phi(p,x,t)}{\partial t}=-\frac{\partial [M(x)\phi(p,x,t)]}{\partial x}+\frac{1}{2}\frac{\partial \{\partial[V(x)\phi(p,x,t)]\}}{\partial(\partial x)}\\
\frac{\partial \phi(p,x,t)}{\partial t}=-\frac{\partial [M(x)\phi(p,x,t)]}{\partial x}+\frac{1}{2}\frac{\partial^2[V(x)\phi(p,x,t)]}{\partial x^2}
\tag{3.34}
\end{equation}\]</span></p>
<p>Retomando la biología del problema, arriba mencionamos que <span class="math inline">\(M(x)\)</span> era una fuerza sistemática que llevaba la frecuencia del alelo <strong>A</strong> en una dirección pero no especificamos mucho más. Esta fuerza podría representar sin problemas la selección, la mutación (o el balance mutacional) y la migración, alguna de ellas las veremos más adelante. Por otro lado, la fuerza aleatoria es igual (en nuestro modelo) a la varianza en las frecuencias alélicas luego de una generación de muestreo al azar en poblaciones de tamaño <span class="math inline">\(2N\)</span> y por lo tanto <span class="math inline">\(V(x)=\frac{x(1-x)}{2N_e}\)</span>, con <span class="math inline">\(N_e\)</span> tamaño efectivo según la varianza.</p>
</div>
<div id="kolmogorov-backward-equation" class="section level3 unnumbered">
<h3>Kolmogorov Backward Equation</h3>
<p>Una segunda posibilidad que se nos brinda de analizar lo que ocurre con la ecuación <span class="math inline">\(\phi(p,x,t)\)</span> es <strong>mirar hacia atrás en el tiempo</strong> (de ahí el <strong>Backward</strong>) y ver lo que podría haber ocurrido con <span class="math inline">\(p\)</span>, la frecuencia inicial (en lugar de <span class="math inline">\(x\)</span>) en el primer instante en el tiempo. Ahora, como todas las poblaciones del <strong>ensemble</strong> parten del mismo <span class="math inline">\(p\)</span>, en ese pequeño incremento de tiempo <span class="math inline">\(\Delta t\)</span>, los movimientos posibles serían <span class="math inline">\(p-\Delta p\)</span>, <span class="math inline">\(p+\Delta p\)</span> o quedarse en <span class="math inline">\(p\)</span>. Las probabilidades correspondientes a esos eventos las vemos en el siguiente cuadro.</p>
<table>
<colgroup>
<col width="25%" />
<col width="24%" />
<col width="37%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Cambio en la 1era generación</th>
<th align="left">Probabilidad de ese cambio</th>
<th align="left">Probabilidad de cambiar a <span class="math inline">\(x\)</span> en <span class="math inline">\(t-\Delta t\)</span></th>
<th align="left">Fuerza</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(p \to p+\Delta p\)</span></td>
<td align="left"><span class="math inline">\(M(p)\)</span></td>
<td align="left"><span class="math inline">\(\phi(p+\Delta p,x,t-\Delta t)\)</span></td>
<td align="left">Sistemática</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(p \to p+\Delta p\)</span></td>
<td align="left"><span class="math inline">\(\frac{V(p)}{2}\)</span></td>
<td align="left"><span class="math inline">\(\phi(p+\Delta p,x,t-\Delta t)\)</span></td>
<td align="left">Deriva</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(p \to p-\Delta p\)</span></td>
<td align="left"><span class="math inline">\(\frac{V(p)}{2}\)</span></td>
<td align="left"><span class="math inline">\(\phi(p-\Delta p,x,t-\Delta t)\)</span></td>
<td align="left">Deriva</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(p \to p\)</span></td>
<td align="left"><span class="math inline">\(1-M(p)-V(p)\)</span></td>
<td align="left"><span class="math inline">\(\phi(p,x,t-\Delta t)\)</span></td>
<td align="left">Permanece</td>
</tr>
</tbody>
</table>
<p>Para la movida <span class="math inline">\(p \to p+\Delta p\)</span> hay dos posibilidades, el efecto de la fuerza sistemática y de la aleatoria, por lo que su efecto combinado será <span class="math inline">\(M(p)+\frac{V(p)}{2}\)</span>. Para la movida <span class="math inline">\(p \to p-\Delta p\)</span> solamente <span class="math inline">\(\frac{V(p)}{2}\)</span> y para quedarse en <span class="math inline">\(p\)</span> por lo tanto <span class="math inline">\(1-M(p)-V(p)\)</span>. Ahora, como ya recorrimos un intervalo de tiempo <span class="math inline">\(\Delta t\)</span>, el tiempo remanente para llegar al estado <span class="math inline">\(x\)</span> en el presente será <span class="math inline">\(t-\Delta t\)</span> y por lo tanto las probabilidades asociadas a cada evento serán las que aparecen en la columna 3 del cuadro. Por ejemplo, para <span class="math inline">\(p \to p+\Delta p\)</span>, entonces para llegar a <span class="math inline">\(x\)</span> en el tiempo <span class="math inline">\(t-\Delta t\)</span> restante, la probabilidad es de <span class="math inline">\(\phi(p+\Delta p,x,t-\Delta t)\)</span>. De la misma manera, para <span class="math inline">\(p \to p-\Delta p\)</span> la probabilidad es de <span class="math inline">\(\phi(p-\Delta p,x,t-\Delta t)\)</span> y finalmente para permanecer en <span class="math inline">\(p\)</span> la probabilidad será de <span class="math inline">\(\phi(p,x,t-\Delta t)\)</span>. Ahora, la diferencia entre <span class="math inline">\(\phi(p,x,t)\)</span> y <span class="math inline">\(\phi(p,x,t-\Delta t)\)</span> saldrá de la multiplicación de las columnas 2 y 3 del cuadro, para luego sumarlas, que luego de reordenar los términos nos permite llegar a:</p>
<p><span class="math display">\[\begin{equation}
\phi(p,x,t)-\phi(p,x,t-\Delta t)=\\
M(p)\left[\phi(p+\Delta p,x,t-\Delta t)-\phi(p,x,t-\Delta t)\right]\\
+\frac{V(p)}{2}\left\{\left[\phi(p+\Delta p,x,t-\Delta t) - \phi(p,x,t-\Delta t) \right]\\
-\left[\phi(p,x,t-\Delta t) - \phi(p-\Delta p,x,t-\Delta t) \right]\right\}
\end{equation}\]</span></p>
<p>Nuevamente, el lado izquierdo de la ecuación anterior representa el cambio en <span class="math inline">\(\phi\)</span> (que podemos representar como <span class="math inline">\(\Delta \phi\)</span>) a parti de un cambio en <span class="math inline">\(t\)</span> (por lo tanto <span class="math inline">\(\Delta t\)</span>). Ahora, sin embargo, el primer término del lado derecho de la ecuación es <span class="math inline">\(M(p)\)</span> (que queda afuera del <span class="math inline">\(\Delta\)</span>) multiplicado por el cambio en <span class="math inline">\(\phi\)</span> (<span class="math inline">\(M\Delta\phi\)</span>) para un determinado cambio en <span class="math inline">\(p\)</span> (<span class="math inline">\(\Delta p\)</span>). Notar que ahora, en lugar de <span class="math inline">\(x\)</span> es en <span class="math inline">\(p\)</span>. Finalmente, el segundo término es ahora <span class="math inline">\(V(p)\)</span> multiplicado el cambio del cambio en <span class="math inline">\(\phi\)</span>, notar las dos diferencias en ese término (que representamos como <span class="math inline">\(\Delta\Delta \phi\)</span>) para un cambio en dos pasos de <span class="math inline">\(p\)</span> (por lo tanto <span class="math inline">\(\Delta\Delta p\)</span>). Poniendo todo junto:</p>
<p><span class="math display">\[\begin{equation}
\frac{\Delta \phi(p,x,t)}{\Delta t}=M(p)\frac{\Delta \phi(p,x,t)}{\Delta p}+\frac{V(p)}{2}\frac{\Delta \{\Delta\phi(p,x,t)\}}{\Delta(\Delta p)}
\end{equation}\]</span></p>
<p>Pasando al límite, cuando <span class="math inline">\(\Delta t \to 0\)</span> y <span class="math inline">\(\Delta p \to 0\)</span>, la ecuación en diferencias converge a una ecuación diferencial parcial, que se conoce como <strong>Kolmogorov Backward Equation</strong> (o <strong>KBE</strong>):</p>
<p><span class="math display" id="eq:KBE">\[\begin{equation}
\frac{\partial \phi(p,x,t)}{\partial t}=M(p)\frac{\partial \phi(p,x,t)}{\partial p}+\frac{V(p)}{2}\frac{\partial \{\partial \phi(p,x,t)\}}{\partial(\partial p)}\\
\frac{\partial \phi(p,x,t)}{\partial t}=M(p)\frac{\partial \phi(p,x,t)}{\partial p}+\frac{V(p)}{2}\frac{\partial^2 \phi(p,x,t)}{\partial p^2}
\tag{3.35}
\end{equation}\]</span></p>
</div>
<div id="solución-de-las-ecuaciones" class="section level3 unnumbered">
<h3>Solución de las ecuaciones</h3>
<p>En el equilibrio, la distribución de probabilidades no cambia con el tiempo, por lo que</p>
<p><span class="math display" id="eq:solKE1">\[\begin{equation}
\frac{\partial \phi(p,x,t)}{\partial t}=0
\tag{3.36}
\end{equation}\]</span></p>
<p>Cuando una función de este tipo existe la llamamos <strong>distribución estacionaria</strong> ya que no cambiará con el tiempo y como la misma no depende del punto de partida tampoco (dentro del intervalo abierto de la difusión), la denotamos como <span class="math inline">\(\phi(x)\)</span> solamente. Cuando se cumple la ecuación <a href="deriva.html#eq:solKE1">(3.36)</a>, aplicándolo en la ecuación <a href="deriva.html#eq:KFE">(3.34)</a>, tenemos</p>
<p><span class="math display" id="eq:solKE2">\[\begin{equation}
\frac{\Delta \phi(x)}{\partial t}=-\frac{\partial [M(x)\phi(x)]}{\partial x}+\frac{1}{2}\frac{\partial^2[V(x)\phi(x)]}{\partial x^2}=0 \therefore \\
\frac{\partial [M(x)\phi(x)]}{\partial x}=\frac{1}{2}\frac{\partial^2[V(x)\phi(x)]}{\partial x^2}
\tag{3.37}
\end{equation}\]</span></p>
<p>Si ahora integramos (en <span class="math inline">\(x\)</span>) ambos lados de esta ecuación, tenemos</p>
<p><span class="math display" id="eq:solKE3">\[\begin{equation}
2 M(x)\phi(x)=\frac{\partial [V(x)\phi(x)]}{\partial x}
\tag{3.38}
\end{equation}\]</span></p>
<p>que se trata de una ecuación diferencial simple, tratable con técnicas de ecuaciones diferenciales ordinarias, que tiene como solución</p>
<p><span class="math display" id="eq:solKE4">\[\begin{equation}
\phi(x)=\frac{C}{V(x)G(x)}
\tag{3.39}
\end{equation}\]</span></p>
<p>con <span class="math inline">\(C\)</span> una constante normalizadora tal que <span class="math inline">\(\int_0^1 \phi(p,x,t) dx=1\)</span>, de forma que la ecuación <a href="deriva.html#eq:solKE4">(3.39)</a> pueda considerarse una función de densidad de probabilidad y <span class="math inline">\(G\)</span> la integral indefinida (conocida como <strong>función de escala</strong>):</p>
<p><span class="math display" id="eq:solKE5">\[\begin{equation}
G(x)=exp[-2 \int^x \frac{M(y)}{V(y)}dy]
\tag{3.40}
\end{equation}\]</span></p>
<p>Ahora, la pregunta que nos hacemos es ¿cómo se relaciona todo esto con nuestros problemas de genética de poblaciones? Veamos por ejemplo la determinación de la probabilidad de fijación de un alelo baja deriva genética. Cuando al menos existe una <strong>barrera absorbente</strong> y la misma es accesible, entonces no existe la distribución estacionaria (ya que en algún momento del tiempo todas las poblaciones terminarán en alguna de esas <strong>barreras absorbentes</strong>). Sin embargo, cuando existe más de una, conocer la probabilidad de terminar en una de ellas en particular suele ser importante y en nuestro caso, conocer la probabilidad de terminar en la <strong>barrera absorbente</strong> <span class="math inline">\(x=1\)</span>, es decir la fijación, dado que partimos de una frecuencia <span class="math inline">\(p\)</span> inicial es algo muy importante. Llamaremos <span class="math inline">\(u(p,t)\)</span> a la probabilidad de fijación en el tiempo <span class="math inline">\(t\)</span> del alelo de interés (por ejemplo <strong>A</strong>), cuando partimos de una frecuencia inicial <span class="math inline">\(p\)</span>. Es posible demostrar que <span class="math inline">\(u(p,t)\)</span> es una función que cumple con la <strong>KBE</strong> . En particular, nos interesa conocer esa probabilidad cuando el tiempo <span class="math inline">\(t \to \infty\)</span>, es decir cuando todas las poblaciones hayan fijado algún alelo y llamaremos <span class="math inline">\(u(p)=\lim_{t \to \infty}u(p,t)\)</span>. En esas condiciones <span class="math inline">\(u(p)\)</span> no variará con el tiempo y por lo tanto su derivada respecto al tiempo será igual a cero, por lo que la ecuación <a href="deriva.html#eq:KBE">(3.35)</a> quedará:</p>
<p><span class="math display" id="eq:tf1">\[\begin{equation}
\frac{\partial u(p)}{\partial t}=0=M(p)\frac{\partial u(p)}{\partial p}+\frac{V(p)}{2}\frac{\partial^2 u(p)}{\partial p^2}
\tag{3.41}
\end{equation}\]</span></p>
<p>A veces es posible encontrar esta misma ecuación escrita de la siguiente forma, que reduce un poco el aspecto intimidante de esta última ecuación</p>
<p><span class="math display" id="eq:tf2">\[\begin{equation}
0=M(p)\frac{d u(p)}{d p}+\frac{V(p)}{2}\frac{d^2 u(p)}{d p^2}
\tag{3.42}
\end{equation}\]</span></p>
<p>al pasar la notación desde <span class="math inline">\(\partial\)</span> a <span class="math inline">\(d\)</span> lo que es posible ya que a esta altura nuestra <span class="math inline">\(u(p,t)\)</span> ya no depende más del tiempo (no cambiará en el tiempo) y entonces se trata de una función de una sola variable. Tenemos dos formas de ver <span class="math inline">\(u(p)\)</span>, primero como la probabilidad última de fijación de alelo <strong>A</strong> siendo que partimos desde una frecuencia inicial <span class="math inline">\(p\)</span>; segundo, como la proporción de poblaciones en nuestro <strong>ensemble</strong> en los que finalmente el alelo <strong>A</strong> será fijado.</p>
<p>Volviendo a la ecuación <a href="deriva.html#eq:tf1">(3.41)</a>, de acuerdo a <span class="citation"><a href="#ref-Kimura1962" role="doc-biblioref">Kimura</a> (<a href="#ref-Kimura1962" role="doc-biblioref">1962</a>)</span> la misma tiene la siguiente solución</p>
<p><span class="math display" id="eq:tf3">\[\begin{equation}
u(p)=\frac{\int_0^p G(x) dx}{\int_0^1 G(x) dx}
\tag{3.43}
\end{equation}\]</span></p>
<p>con <span class="math inline">\(G(x)\)</span> como fue definido previamente en la ecuación <a href="deriva.html#eq:solKE5">(3.40)</a> y con las condiciones de frontera <span class="math inline">\(u(0)=0\)</span> y <span class="math inline">\(u(1)=1\)</span>, que en términos llanos quiere decir que un alelo que no existe jamás será fijado y que un alelo fijado ya está fijado.</p>
<p>Finalmente, casi llegamos a donde queríamos. Vamos a determinar la probabilidad de fijación de un alelo que solo experimenta la fuerza de la deriva y por lo tanto <span class="math inline">\(M(x)=0\)</span> y <span class="math inline">\(V(x)=x(1-x)/(2N_e)\)</span>. Sustituyendo estos valores en la ecuación <a href="deriva.html#eq:solKE5">(3.40)</a> tenemos que</p>
<p><span class="math display" id="eq:tf4">\[\begin{equation}
G(x)=exp[-2 \int^x \frac{M(y)}{V(y)}dy]=exp[-4N_e \int^x \frac{0}{x(1-x)}dy]=e^{-4N_e0}=1
\tag{3.44}
\end{equation}\]</span></p>
<p>es decir, que bajo estas condiciones <span class="math inline">\(G(x)=1\)</span>. Por lo tanto, sustituyendo este valor en la ecuación <a href="deriva.html#eq:tf3">(3.43)</a>, tenemos ahora</p>
<p><span class="math display" id="eq:tf5">\[\begin{equation}
u(p)=\frac{\int_0^p G(x) dx}{\int_0^1 G(x) dx}=\frac{\int_0^p 1 dx}{\int_0^1 1 dx}=\frac{p-0}{1-0}=p
\tag{3.45}
\end{equation}\]</span></p>
<p>La ecuación <a href="deriva.html#eq:tf5">(3.45)</a> nos brinda un resultado así de simple como de importante: la probabilidad de fijación de un alelo que solo experimenta deriva genética es igual a su frecuencia inicial en la población (o en el <strong>ensemble</strong> de poblaciones) de referencia, algo que usaremos en la próxima sección. Si lo pensamos un poco este resultado tiene bastante sentido intuitivo a partir del comportamiento de las gráficas que vimos en la sección <a href="deriva.html#el-modelo-de-wright-fisher">El modelo de Wright-Fisher</a>, en particular la figura <a href="deriva.html#fig:figura3p5">3.5</a>: como se trata de un proceso aleatorio con la misma probabilidad de ir hacia arriba o hacia abajo en la figura, cuanto más cerca arrancamos del borde superior (la fijación del alelo), mayor será la probabilidad de que las poblaciones caigan en la <strong>barrera absorbente</strong> de fijación, o dicho de otra forma, una mayor proporción de poblaciones irán a terminar en el estado de fijación. ¿Cuánto o cuántas? Bueno, en principio uno podría pensar que es proporcional al punto de arranque, <span class="math inline">\(p\)</span>, lo que afortunadamente se ve confirmado por los cálculos (algo más complejos) precedentes.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<p>Bajo la condición de que la deriva sea la única fuerza evolutiva actuando, en una población de <span class="math inline">\(N\)</span> individuos diploides, en un <em>locus</em> con dos alelos:</p>
<ul>
<li><p>La <strong>probabilidad de fijación</strong> de un alelo es igual a su frecuencia <span class="math inline">\(p\)</span></p></li>
<li><p>La ecuación hacia adelante de Kolmogorov (<strong>KFE</strong>) analiza el comportamiento de la función de densidad de probabilidad <span class="math inline">\(\phi(p,x,t)\)</span>, es decir la distribución de las frecuencias alélicas <span class="math inline">\(x\)</span>, a medida de que avanza el tiempo y tiene la siguiente forma</p></li>
</ul>
<p><span class="math display">\[\begin{equation}
\frac{\partial \phi(p,x,t)}{\partial t}=-\frac{\partial [M(x)\phi(p,x,t)]}{\partial x}+\frac{1}{2}\frac{\partial^2[V(x)\phi(p,x,t)]}{\partial x^2}
\end{equation}\]</span></p>
<ul>
<li>La ecuación hacia atrás de Kolmogorov (<strong>KBE</strong>) es la generalmente más útil en genética de poblaciones. Analiza el comportamiento de la función de densidad de probabilidad <span class="math inline">\(\phi(p,x,t)\)</span> respecto a la frecuencia inicial <span class="math inline">\(p\)</span>, a medida de que voy hacia atrás en el tiempo y tiene la siguiente forma</li>
</ul>
<p><span class="math display">\[\begin{equation}
\frac{\partial \phi(p,x,t)}{\partial t}=M(p)\frac{\partial \phi(p,x,t)}{\partial p}+\frac{V(p)}{2}\frac{\partial^2 \phi(p,x,t)}{\partial p^2}
\end{equation}\]</span></p>
</div>
</div>
</div>
<div id="probabilidad-de-fijación-y-tiempos-de-fijación" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Probabilidad de fijación y tiempos de fijación</h2>
<p>Como vimos antes, la probabilidad última de fijación de un alelo neutro es igual a la frecuencia inicial de dicho alelo, por ejemplo <span class="math inline">\(p\)</span> para el alelo <strong>A</strong>. Inicial, en este contexto, se refiere a cualquier punto en el tiempo que tomemos como referencia, lo que claramente irá variando a medida que avance el tiempo. Más aún, como también vimos antes, cuando la única acción evolutiva es la correspondiente a la deriva genética el estado de equilibrio se corresponderá a cuando no existan poblaciones segregando, por lo que la probabilidad para cualquier punto entre las dos <strong>barreras absorbentes</strong> (fijación, <span class="math inline">\(p=1\)</span>, pérdida, <span class="math inline">\(p=0\)</span>) será cero. Pese a esto, hay varios resultados interesantes que surgen a partir de la <strong>KBE</strong> y que fueron derivados por <span class="citation"><a href="#ref-KimuraOhta1969" role="doc-biblioref">Kimura and Ohta</a> (<a href="#ref-KimuraOhta1969" role="doc-biblioref">1969</a>)</span>. En particular, si bien existían resultados previos para el tiempo de segregación de un alelo (obtenidos a partir de un método diferente), es decir el tiempo hasta que uno de los dos estados absorbentes es alcanzado, no existía una solución para cada uno de los dos tiempos en forma independiente. En particular, asumiendo que el punto de partida es cuando la frecuencia del alelo <strong>A</strong> es <span class="math inline">\(p\)</span>, el tiempo medio transcurrido hasta la fijación del alelo <strong>A</strong> (<span class="math inline">\(\bar{t_1}(p)\)</span>, notar la dependencia en <span class="math inline">\(p\)</span>) viene dado por</p>
<p><span class="math display" id="eq:Tfix">\[\begin{equation}
\bar{t_1}(p)=-4N \frac{(1-p) \ln(1-p)}{p}
\tag{3.46}
\end{equation}\]</span></p>
<p>mientras que el tiempo medio hasta la pérdida del alelo <strong>A</strong> (<span class="math inline">\(\bar{t_0}(p)\)</span>) es</p>
<p><span class="math display" id="eq:Tloss">\[\begin{equation}
\bar{t_0}(p)=-4N \frac{(p) \ln(p)}{(1-p)}
\tag{3.47}
\end{equation}\]</span></p>
<p>Por las dudas, los subíndices <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span> se refieren en esta sección a pérdida (<span class="math inline">\(p=0\)</span>) y fijación (<span class="math inline">\(p=1\)</span>), respectivamente. La derivación de estas ecuaciones es un poco más compleja y excede el alcance de este capítulo (y seguramente tu paciencia), pero para los que estén interesados en cómo se llega hasta eso (a partir de los resultados de la sección previa) una excelente explicación se encuentra en el <strong>Apendix 1</strong> del libro de <span class="citation"><a href="#ref-WalshLynch2018" role="doc-biblioref">Walsh and Lynch</a> (<a href="#ref-WalshLynch2018" role="doc-biblioref">2018</a>)</span>, ecuaciones A1.21-A1.28. Volviendo a lo nuestro, los anteriores son los tiempos a la fijación y a la pérdida del alelo. Para calcular el tiempo medio hasta que ocurra alguno de los dos eventos (<span class="math inline">\(\bar{t}(p)\)</span>), debemos ponderar cada uno de estos dos tiempos por la probabilidad de que ocurra, la fijación con probabilidad <span class="math inline">\(p\)</span> y la pérdida con probabilidad <span class="math inline">\(1-p\)</span>, por lo que el promedio ponderado de ellos estará dado por <span class="math inline">\(\bar{t}=p \bar{t_1}(p)+ (1-p) \bar{t_0}(p)\)</span>. Sustituyendo los valores correspondientes a <span class="math inline">\(\bar{t_1}(p)\)</span> (ecuación <a href="deriva.html#eq:Tfix">(3.46)</a>) y <span class="math inline">\(\bar{t_0}(p)\)</span> (ecuación <a href="deriva.html#eq:Tloss">(3.47)</a>), tenemos:</p>
<p><span class="math display" id="eq:Tseg">\[\begin{equation}
\bar{t}(p)=p \bar{t_1}(p)+ (1-p) \bar{t_0}(p)=\\
= p \left[-4N \frac{(1-p) \ln(1-p)}{p}\right] + (1-p) \left[-4N \frac{(p) \ln(p)}{(1-p)}\right]\\
\bar{t}(p)=-4N [p \ln(p) + (1-p) \ln(1-p)]
\tag{3.48}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p7"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p7-1.png" alt="Tiempo medio a la fijación (verde), pérdida (roja) y de segregación (azul) en función de la frecuencia del alelo **A**. Cuando la frecuencia de **A** es 1/2 el tiempo medio de segregación es máximo y su valor esperado es de aproximadamente 2,77N generaciones." width="672" />
<p class="caption">
Figure 3.14: Tiempo medio a la fijación (verde), pérdida (roja) y de segregación (azul) en función de la frecuencia del alelo <strong>A</strong>. Cuando la frecuencia de <strong>A</strong> es 1/2 el tiempo medio de segregación es máximo y su valor esperado es de aproximadamente 2,77N generaciones.
</p>
</div>
<p>Las curvas correspondientes a los tres tiempos (<span class="math inline">\(\bar{t},\bar{t_0}, \bar{t_1}\)</span>) se pueden ver en la figura <a href="deriva.html#fig:figura3p7">3.14</a>, como función de la frecuencia inicial del alelo <strong>A</strong> (<span class="math inline">\(p\)</span>). Mientras que en <span class="math inline">\(\bar{t_0}\)</span> y <span class="math inline">\(\bar{t_1}\)</span> los máximos tiempos se corresponden a la <strong>proximidad inmediata</strong> a barreras absorbentes (ahora discutiremos cuán cerca), en el caso de <span class="math inline">\(\bar{t}\)</span> el tiempo máximo ocurre cuando la frecuencia del alelo <strong>A</strong> es exactamente intermedia entre las barreras (<span class="math inline">\(p=\frac{1}{2}=0,5\)</span>). En particular, a esta frecuencia <span class="math inline">\(p=\frac{1}{2}\)</span>, la ecuación <a href="deriva.html#eq:Tseg">(3.48)</a> se transforma en</p>
<p><span class="math display" id="eq:TsegMax">\[\begin{equation}
\bar{t}(p=\frac{1}{2})=-4N [\frac{1}{2} \ln(\frac{1}{2}) + \frac{1}{2} \ln(\frac{1}{2})]=-4N [2 \frac{1}{2} \ln(\frac{1}{2})]=-4N \ln(\frac{1}{2})=4N \ln(2)\\
\bar{t}_{max}=\sim 2,77N
\tag{3.49}
\end{equation}\]</span></p>
<p>Es decir, si partimos de una frecuencia del alelo <strong>A</strong> de <span class="math inline">\(p=0,5\)</span> el tiempo medio que llevará hasta la eventual fijación o pérdida del mismo es de <span class="math inline">\(2,77N\)</span> generaciones. Por otro lado, cuando aparece un nuevo alelo en la población su frecuencia es <span class="math inline">\(\frac{1}{(2N)}\)</span> ya que en la población hay <span class="math inline">\(N\)</span> individuos diploides (y por lo tanto un total de <span class="math inline">\(2N\)</span> alelos). En este caso, <strong>lo más cerca que podemos estar de su pérdida</strong> antes de que ocurra, el tiempo que le llevará a la fijación será</p>
<p><span class="math display" id="eq:TfixMax">\[\begin{equation}
\bar{t_1}(p=\frac{1}{2N})=-4N \frac{(1-\frac{1}{2N}) \ln(1-\frac{1}{2N})}{\frac{1}{2N}} \sim 4N
\tag{3.50}
\end{equation}\]</span></p>
<p>La última aproximación basada en que <span class="math inline">\(\frac{\ln(1-x)}{x} \to 1\)</span> cuando <span class="math inline">\(x \to 0\)</span> y que <span class="math inline">\(1-\frac{1}{2N}=\frac{2N-1}{2N} \to 1\)</span> cuando <span class="math inline">\(N \to \infty\)</span>, en conjunto una buena aproximación aún para valores tan pequeños como <span class="math inline">\(N=10\)</span>. Es decir, al surgir un nuevo alelo en la población su probabilidad de fijación es <span class="math inline">\(\frac{1}{2N}\)</span> y en la eventualidad de que lo consiga el tiempo requerido será en promedio de <span class="math inline">\(4N\)</span> generaciones.</p>
<p>Finalmente, la probabilidad de perder ese mismo alelo nuevo es <span class="math inline">\(1-\frac{1}{2N}\)</span> y el tiempo promedio a la pérdida será de</p>
<p><span class="math display" id="eq:TlossMin">\[\begin{equation}
\bar{t_0}(\frac{1}{2N})=-4N \frac{(\frac{1}{2N}) \ln(\frac{1}{2N})}{(1-\frac{1}{2N})}=2 \frac{\ln(\frac{1}{2N})}{(1-\frac{1}{2N})} \sim 2 \ln(2N) 
\tag{3.51}
\end{equation}\]</span></p>
<p>lo que es claramente menor que el tiempo medio a la eventual fijación ya que para <span class="math inline">\(N&gt;0\)</span>, <span class="math inline">\(2N \gg \ln(2N)\)</span>.</p>
<hr />
<div id="ejemplo-3.5" class="section level4 unnumbered">
<h4>Ejemplo 3.5</h4>
<p>En un rebaño aislado de 1000 ovejas Scottish Blackface que existe en una isla remota de las Hébridas exteriores surge un nuevo alelo en un gen de la pigmentación de la lana que bajo la luz del crepúsculo las hace ver <strong>verdes</strong>. Suponiendo que este alelo es neutro (es decir, no confiere ninguna ventaja ni demérito para la reproducción) y que la deriva genética es la única fuerza evolutiva en cuestión, ¿cuál es la probabilidad de que este alelo se fije en la población? ¿Cuánto tiempo tardaría en ocurrir eso (promedio), en la eventualidad de que ocurra teniendo en cuenta que el intervalo generacional para estas ovejas (tiempo promedio en el que nacen los hijos) es de 3 años, sin generaciones solapantes? ¿Cuál es la probabilidad de que se pierda el alelo y cuánto tardaría en promedio en ocurrir eso (en la eventualidad de que se pierda)? ¿Cuál sería el tiempo medio segregando este alelo?</p>
<p>La probabilidad de que el nuevo alelo sobreviva es su frecuencia inicial, en este caso <span class="math inline">\(p=\frac{1}{2N}=\frac{1}{2 \cdot 1000}=0,0005=0,05\%\)</span>. El tiempo hasta la fijación esta dado por la ecuación <a href="deriva.html#eq:TfixMax">(3.50)</a> y es aproximadamente <span class="math inline">\(4N\)</span> generaciones, es decir <span class="math inline">\(4 \cdot 1000=4000\)</span> generaciones. Considerando que cada generación lleva unos 3 años, se precisarían unos <span class="math inline">\(4000 \cdot 3=12000\)</span> años para que este alelo se fijase.</p>
<p>La probabilidad de que el nuevo alelo se pierda es <span class="math inline">\(1-\frac{1}{2N}=1-\frac{1}{2000}=0,9995=99,95\%\)</span>. En la eventualidad de que esto ocurra (recordar que se trata del azar trabajando y no podemos determinar si ocurrirá o no), el tiempo medio a la pérdida esta dado por la ecuación <a href="deriva.html#eq:TlossMin">(3.51)</a> y es aproximadamente de <span class="math inline">\(2\ln(2N)=2 \cdot \ln(2000) \sim 15,2\)</span> generaciones. Teniendo en cuenta el tiempo de 3 años por generación, eso sería <span class="math inline">\(3 \cdot 15,2=45,6\)</span> años.</p>
<p>Por último, el tiempo medio segregando el alelo viene dado por la ecuación <a href="deriva.html#eq:Tseg">(3.48)</a> y es <span class="math inline">\(\bar{t}(p)=-4N [p \ln(p) + (1-p) \ln(1-p)]=-4 \cdot 1000 [0,0005 \cdot \ln(0,0005) + 0,9995 \cdot \ln(0,9995)] \sim 17,2\)</span> generaciones, lo que teniendo en cuenta el intervalo de 3 años entre generaciones nos daría <span class="math inline">\(3 \cdot 17,2=51,6\)</span> años. También hubiésemos arribado a este resultado como promedio ponderado entre fijación y pérdida, es decir <span class="math inline">\(12000 \cdot 0,0005+45.6 \cdot 0,9995=51,5772 \sim 57,6\)</span> años.</p>
<hr />
<p>Para terminar con este tema, un hecho a primera vista curioso. Si ya has tenido un curso de ecología, sin duda te estarás preguntando por la conexión entre la ecuación <a href="deriva.html#eq:Tseg">(3.48)</a> que predice el tiempo medio que un locus con dos alelos se encuentra segregando en un <strong>ensemble</strong> de poblaciones con el índice de diversidad de Shannon-Weaver (a veces conocido como de Shannon o incluso Shannon-Wiener). Si recuerdas este índice, que nos indicaba la diversidad de especies en un sistema ecológico, el mismo era <span class="math inline">\(- \sum_{i=1}^{n} p_i \ln{p_i}\)</span>, para un conjunto de <span class="math inline">\(n\)</span> especies diferentes, donde <span class="math inline">\(p_i\)</span> es la frecuencia de la especie <span class="math inline">\(i\)</span> en el conjunto (<span class="math inline">\(\sum_i p_i=1\)</span>). Si consideramos que <span class="math inline">\(q=1-p\)</span> y <span class="math inline">\(p+q=1\)</span>, podemos llamar <span class="math inline">\(p_1=p\)</span> y <span class="math inline">\(p_2=q\)</span>, que cumplen <span class="math inline">\(\sum_i p_i=1\)</span>. Más aún, con este cambio de notación podemos reescribir la ecuación <a href="deriva.html#eq:Tseg">(3.48)</a> como:</p>
<p><span class="math display">\[\begin{equation}
\bar{t}(p)=-4N [p \ln(p) + (1-p) \ln(1-p)]=-4N [p_1 \ln(p_1)+p_1 \ln(p_2)]=-4N \sum_i p_i \ln(p_i)
\end{equation}\]</span></p>
<p>Excepto por el factor de escala <span class="math inline">\(4N\)</span>, el índice de Shannon-Weaver para <span class="math inline">\(n=2\)</span> especies es idéntico al tiempo medio de segregación, lo que llama inmediatamente a pensar, como paralelismo, en las distintas poblaciones segregando como la probabilidad de mantener la diversidad genética dentro de las mismas en el tiempo.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<p>Bajo la condición de que la deriva sea la única fuerza evolutiva actuando, en una población de <span class="math inline">\(N\)</span> individuos diploides, en un <em>locus</em> con dos alelos:</p>
<ul>
<li><p>La <strong>probabilidad de fijación</strong> de un alelo es igual a su frecuencia <span class="math inline">\(p\)</span></p></li>
<li><p>El <strong>tiempo a la eventual fijación</strong> de ese alelo es <span class="math inline">\(\bar{t_1}(p)=-4N \frac{(1-p) \ln(1-p)}{p}\)</span></p></li>
<li><p>La <strong>probabilidad de perder un alelo</strong> es igual a <span class="math inline">\(1-p\)</span></p></li>
<li><p>El <strong>tiempo a la eventual pérdida</strong> de ese alelo es <span class="math inline">\(\bar{t_0}(p)=-4N \frac{(p) \ln(p)}{(1-p)}\)</span></p></li>
<li><p>El <strong>tiempo segregando</strong> en ese locus, es decir el tiempo a eventual fijación o pérdida es <span class="math inline">\(\bar{t}(p)=-4N [p \ln(p) + (1-p) \ln(1-p)]\)</span></p></li>
<li><p>El <strong>tiempo máximo segregando</strong> se alcanza cuando el punto de partida es <span class="math inline">\(p=\frac{1}{2}\)</span> y es igual a <span class="math inline">\(\sim 2,77N\)</span> generaciones.</p></li>
</ul>
</div>
</div>
</div>
<div id="el-modelo-coalescente" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> El modelo coalescente</h2>
<p>En general, el modelo de Wright-Fisher es una buena aproximación inicial para modelar la evolución de una población, pero las poblaciones reales se suelen apartar de varios de los supuestos, como ya vimos. Un tema del que nos hemos abstenido de tocar hasta ahora es el del número de alelos. Hasta ahora hemos tratado los problemas como un locus con dos alelos, pero se trata de un modelo poco realista desde el punto de vista de la evolución molecular. Es decir, si secuenciamos una región razonable de un gen en varios indiviudos de la población nos vamos a encontrar con que en la misma existen varias posiciones segregantes (en las que hay variabilidad entre los individuos muestreados). Esto es muy razonable ya que las mutaciones (que son la fuente primaria de variabilidad) ocurren aproximadamente al azar entre las diferentes posiciones posibles en el gen, por lo que en una muestra de secuencias del gen vamos a encontrar muchos alelos diferentes. La idea ahora es ver si podemos trazar y entender la historia <strong>hacia atrás</strong>, es decir, a partir de una muestra del presente extraer conclusiones sobre la historia de la población de la que extrajimos la muestra. Por ejemplo, nos podemos preguntar si a partir de los datos presentes podemos responder algunas de estas cuestiones: ¿Cuál fue el ancestro común más reciente de las copias genéticas existentes en el presente? ¿Cuál era el tamaño de la población en el momento del evento de coalescencia? ¿Con qué frecuencia se “extinguen” las copias genéticas? ¿Qué régimen migratorio operaba en la población histórica?</p>
<p>Una representación de la situación se puede ver en la figura <a href="deriva.html#fig:figura3p10">3.15</a>, donde la generación presente (generación <span class="math inline">\(0\)</span>) aparece en la parte de abajo de la figura y a medida de que nos retrotraemos en el tiempo, generación a generación, vamos subiendo en el gráfico.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:figura3p10"></span>
<img src="ApuntesGeneticaII_files/figure-html/figura3p10-1.png" alt="Evolución del linaje de los alelos encontrados en la generación presente (generación 0) hacia $t$ generaciones atrás. Figura propia generada con el paquete &quot;learnPopGen&quot; (Liam Revell) de R (función modificada por nosotros)." width="672" />
<p class="caption">
Figure 3.15: Evolución del linaje de los alelos encontrados en la generación presente (generación 0) hacia <span class="math inline">\(t\)</span> generaciones atrás. Figura propia generada con el paquete “learnPopGen” (Liam Revell) de R (función modificada por nosotros).
</p>
</div>
<p>En la generación presente, que es lo que usualmente tenemos para muestrear, tenemos 3 alelos diferentes, marcados por los colores (notar que hay 3 colores, uno entre el verde y el rojo). Cada una de las copias presentes proviene de una copia en la generación anterior. Si conociésemos de cuál exactamente, la podríamos unir con una línea (técnicamente, con una <strong>arista</strong> en el <strong>grafo</strong> que representa la evolución de nuestra población de alelos en el tiempo). Notar que el tamaño de la población de alelos es fija, 20 en nuestra figura. A medida de que vamos hacia atrás, las copias de cada generación deben venir de alguna copia de la generación anterior. Sin embargo, como el muestreo en el modelo de Wright-Fisher es con reposición, como vimos antes, con probabilidad <span class="math inline">\(1/(2N)\)</span> podemos volver a extraer una copia del mismo alelo para la nueva generación. Como el tamaño de la población de alelos es fijo, entonces si alguno de ellos es muestreado en forma repetida, algún otro deberá NO dejara copias, es decir, se perderá para el futuro. Si observas con detenimiento la figura verás que en muchas copias no hay una línea que las una con la generación inmediatamente debajo, que significa que esa copia no ha dejado descendientes y por lo tanto “muere” en nuestra genealogía de los alelos. Más aún, si vuelves a mira con cuidado, seguramente notarás que varios linajes han desaparecido en el tiempo, por ejemplo el naranja y el azul, que como en general no tenemos muestras del pasado no tendríamos capacidad de verlos o conocerlos hoy en día.</p>
<p>Veamos si podemos entender cómo son las distribución de probabilidades asociada con el comportamiento de esta genealogía. De acuerdo con el modelo de Wright-Fisher, si tenemos <span class="math inline">\(2N\)</span> copias de alelos en cada generación, dado de que extraemos una cualquiera (que viene de una copia en particular en la generación anterior), la probabilidad de una la segunda copia que extraemos de la población provenga de la misma ancestral que la de la primera es <span class="math inline">\(1/(2N)\)</span>, por lo que la probabilidad de que vengan de copias ancestrales distintas en la generación previa es de <span class="math inline">\(1-[1/(2N)]\)</span>. Ahora, si deseamos saber cuál es la probabilidad de que la tercera copia que sacamos de la generación presente provenga de una copia diferente a las otras dos, esta copia debe ser primero diferente a la primera (con probabilidad <span class="math inline">\(1-[1/(2N)]\)</span>), pero también a la segunda, ahora con probabilidad <span class="math inline">\(1-[2/(2N)]=(2N-2)/(2N)\)</span> (el <span class="math inline">\(2\)</span> en el numerador de la expresión anterior es porque quedan <span class="math inline">\(2N-2\)</span> posibilidades de copias diferentes); como deben darse los dos eventos, entonces la probabilidad de que la tercera copia sea diferentes a las dos anteriores (también diferentes), es decir que las 3 sean diferentes es <span class="math inline">\(\left[\left(1-\frac{1}{2N}\right)\right] \cdot \left[\left(1-\frac{2}{2N}\right)\right]\)</span>. Claramente la misma lógica se puede aplicar para la cuarta copia, para la quinta y así sucesivamente. Si (siguiendo la notación del libro de <span class="citation"><a href="#ref-Felsenstein2004" role="doc-biblioref">Felsenstein</a> (<a href="#ref-Felsenstein2004" role="doc-biblioref">2004</a>)</span>) llamamos <span class="math inline">\(G_{kk}\)</span> a la probabilidad de que <span class="math inline">\(k\)</span> copias vengan de copias diferentes en la generación previa, entonces tenemos que</p>
<p><span class="math display">\[\begin{equation}
G_{kk}=\left(1-\frac{1}{2N}\right)\left(1-\frac{2}{2N}\right)\left(1-\frac{3}{2N}\right)...\left(1-\frac{k-1}{2N}\right)=\prod_{i=1}^{k-1}\left(1-\frac{i}{2N}\right)
\end{equation}\]</span></p>
<p>Si operamos un poco, reagrupamos y descartamos los términos del orden <span class="math inline">\(\frac{1}{N^2}\)</span>, tenemos entonces</p>
<p><span class="math display">\[\begin{equation}
G_{kk}=1-[1+2+3+..+(k-1)]/(2N)+\text{ términos en }\frac{1}{N^2} \text{ y menores}
\end{equation}\]</span></p>
<p>Como <span class="math inline">\(\sum_{i=1}^k=k(k-1)/2\)</span> (como ya lo vimos en la sección <a href="variación-y-equilibrio-de-hardy-weinberg.html#tres-o-más-alelos">Tres o más alelos</a>), entonces,</p>
<p><span class="math display">\[\begin{equation}
G_{kk} \approx 1-\frac{k(k-1)}{4N}
\end{equation}\]</span></p>
<p>o visto de otra forma, la probabilidad de coalescer de dos copias en la generación anterior (que es igual a <span class="math inline">\(1\)</span> menos la probabilidad de que vengan de distintas copias) es de</p>
<p><span class="math display">\[\begin{equation}
P(\text{coalescer})=1-G_{kk} \approx \frac{k(k-1)}{4N}
\end{equation}\]</span></p>
<p>Otra forma de ver lo anterior es que la probabilidad de coalescer es el producto de la probabilidad de extraer un alelo idéntico (<span class="math inline">\(\frac{1}{2N}\)</span>), multiplicada por el número de posibilidades de a dos, que es <span class="math inline">\(k(k-1)/2\)</span> (despreciando la posibilidad de que 3 o más coalescan en la misma generación, un evento extremádamente improbable cuando <span class="math inline">\(k \ll N\)</span>),</p>
<p><span class="math display">\[\begin{equation}
P(\text{coalescer})= \frac{1}{2N} \cdot \frac{k(k-1)}{2} = \frac{k(k-1)}{4N}
\end{equation}\]</span></p>
<p>Si recuerdas, la distribución geométrica era la que correspondía al número de fracasos hasta obtener el primer éxito. Tiene la forma <span class="math inline">\(\Pr(X=k)=(1-p)^{k-1}p\)</span>, con parámetro <span class="math inline">\(p\)</span> igual la probabilidad de éxito, media igual a <span class="math inline">\(1/p\)</span> y varianza <span class="math inline">\((1-p)/p^2\)</span> (con soporte en <span class="math inline">\(k \in \{1,2,3,...\}\)</span>. La distribución exponencial tiene forma <span class="math inline">\(\lambda e^{-\lambda x}\)</span>, con soporte en <span class="math inline">\(x \in [0,\infty )\)</span>, media <span class="math inline">\(1/p\)</span> y varianza <span class="math inline">\(1/p^2\)</span>. Ahora, si llamamos <span class="math inline">\(u_{k}\)</span> a la variable aleatoria para el tiempo (en generaciones) hasta la primer coalescencia, que me lleva de <span class="math inline">\(k\)</span> a <span class="math inline">\(k-1\)</span> alelos, la misma tendrá una distribución geométrica (muy bien aproximada por una exponencial cuando <span class="math inline">\(k \ll N\)</span>) y como <span class="math inline">\(p=\frac{k(k-1)}{4N}\)</span>, entonces <span class="math inline">\(\frac{1}{p}=\frac{4N}{k(k-1)}\)</span>, por lo tanto con media</p>
<p><span class="math display" id="eq:coale6">\[\begin{equation}
\mathbb{E}(u_{k})=\frac{4N}{k(k-1)} \text{ generaciones}
\tag{3.52}
\end{equation}\]</span></p>
<p>y varianza</p>
<p><span class="math display" id="eq:coale7">\[\begin{equation}
\mathbb{V}(u_{k})=\frac{16N^2}{[k(k-1)]^2}  \text{ generaciones}^2
\tag{3.53}
\end{equation}\]</span></p>
<p>Es decir, tenemos la distribución del tiempo hasta el primer evento de coalescencia, que me reducirá el número de alelos diferentes en 1. Por esta razón, el siguiente tiempo de coalescencia tendra también una distribución aproximadamente exponencial, pero ahora su esperanza será</p>
<p><span class="math display" id="eq:coale8">\[\begin{equation}
\mathbb{E}(u_{k-1})=\frac{4N}{(k-1)(k-2)} \text{ generaciones}
\tag{3.54}
\end{equation}\]</span></p>
<p>Como el denominador es menor que en <a href="deriva.html#eq:coale6">(3.52)</a>, el tiempo esperado para el próximo evento de coalescencia será mayor. De hecho, si dividimos la ecuación <a href="deriva.html#eq:coale8">(3.54)</a> entre la ecuación <a href="deriva.html#eq:coale6">(3.52)</a>, tendremos la relación entre los tiempos para el primer evento de coalescencia y para el segundo.</p>
<p><span class="math display" id="eq:coale9">\[\begin{equation}
\frac{\mathbb{E}(u_{k-1})}{\mathbb{E}(u_{k})}=\frac{4N}{(k-1)(k-2)} \frac{k(k-2)}{4N}=\frac{k}{k-2} 
\tag{3.55}
\end{equation}\]</span></p>
<p>El proceso se repite y los tiempos serán cada vez mayores, hasta llegar al último evento de coalescencia que es cuando pasamos de <span class="math inline">\(k=2\)</span> alelos a <span class="math inline">\(k=1\)</span> alelo. Para este último evento tendremos entonces que la esperanza es igual a</p>
<p><span class="math display" id="eq:coale10">\[\begin{equation}
\mathbb{E}(u_{2})=\frac{4N}{2(2-1)}= \frac{4N}{2} = 2N\text{ generaciones}
\tag{3.56}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:coalescenteTree"></span>
<img src="figuras/coalescenteTree2.png" alt="Árbol genético representando los tiempos del proceso coalescente, cuya esperanza está dada por $4N/(k(k-1))$ para $k$ alelos. Con 5 alelos incialmente el tiempo es $4N/20=2/10N$ y así sucesivamente. Se aprecia claramente que hacia atrás los tiempos son cada vez mayores. Elaboración propia a partir de idea en @HartlClark2007." width="710" />
<p class="caption">
Figure 3.16: Árbol genético representando los tiempos del proceso coalescente, cuya esperanza está dada por <span class="math inline">\(4N/(k(k-1))\)</span> para <span class="math inline">\(k\)</span> alelos. Con 5 alelos incialmente el tiempo es <span class="math inline">\(4N/20=2/10N\)</span> y así sucesivamente. Se aprecia claramente que hacia atrás los tiempos son cada vez mayores. Elaboración propia a partir de idea en <span class="citation"><a href="#ref-HartlClark2007" role="doc-biblioref">Hartl and Clark</a> (<a href="#ref-HartlClark2007" role="doc-biblioref">2007</a>)</span>.
</p>
</div>
<p>Como se aprecia en la figura <a href="deriva.html#fig:coalescenteTree">3.16</a>, en el caso de 5 alelos iniciales, los tiempos de los intervalos hasta el próximo evento de coalescencia van creciendo de acuerdo a la progresión <span class="math inline">\(\frac{4N}{(5 \cdot 4)}=\frac{2N}{10}=\frac{N}{5}\)</span>, <span class="math inline">\(\frac{4N}{(4 \cdot 3)}=\frac{2N}{6}=\frac{N}{3}\)</span>, <span class="math inline">\(\frac{4N}{(3 \cdot 2)}=\frac{4N}{6}=\frac{2N}{3}\)</span> y <span class="math inline">\(\frac{4N}{(2 \cdot 1)}=\frac{4N}{2}=2N\)</span>.</p>
<p>Para un muestra conteniendo <span class="math inline">\(k\)</span> alelos diferentes, el tiempo total a la coalescencia, o lo que es lo mismo el tiempo hasta el ancestro más reciente de todos los alelos en la muestra es de</p>
<p><span class="math display" id="eq:coale11">\[\begin{equation}
t=4N(1-\frac{1}{k})
\tag{3.57}
\end{equation}\]</span></p>
<p>con varianza</p>
<p><span class="math display" id="eq:coale12">\[\begin{equation}
\mathbb{V}(t)=4N^2 \sum_{i=2}^k \frac{1}{ {i \choose 2}^2}
\tag{3.58}
\end{equation}\]</span></p>
<p>(según <span class="citation"><a href="#ref-Kingman1982a" role="doc-biblioref">Kingman</a> (<a href="#ref-Kingman1982a" role="doc-biblioref">1982a</a>)</span>; <span class="citation"><a href="#ref-Kingman1982b" role="doc-biblioref">Kingman</a> (<a href="#ref-Kingman1982b" role="doc-biblioref">1982b</a>)</span>; <span class="citation"><a href="#ref-Tajima1983" role="doc-biblioref">Tajima</a> (<a href="#ref-Tajima1983" role="doc-biblioref">1983</a>)</span>, ecuaciones 10 y 11).</p>
<p>Un primer resultado de la ecuación <a href="deriva.html#eq:coale12">(3.58)</a> es que a medida de que el número de alelos se acerca a <span class="math inline">\(2N\)</span> (el máximo), como <span class="math inline">\(\frac{1}{(2N)} \to 0\)</span>, el tiempo al ancestro común de todos los alelos tenderá a <span class="math inline">\(4N\)</span>. Otro resultado más interesante es provisto por <span class="citation"><a href="#ref-RosenbergNordborg2002" role="doc-biblioref">Rosenberg and Nordborg</a> (<a href="#ref-RosenbergNordborg2002" role="doc-biblioref">2002</a>)</span>, que muestran que la probabilidad de que el ancestro común a los alelos en la muestra sea el mismo que el ancestro común a todos los alelos de la población se guía por la relación <span class="math inline">\(\frac{(k-1)}{(k+2}\)</span>, una relación que crece muy rápido (por ejemplo, para <span class="math inline">\(k=3\)</span>, <span class="math inline">\(\frac{(3-1)}{(3+2)}=\frac{2}{5}=0,40\)</span>, pero para <span class="math inline">\(k=10\)</span> ya es <span class="math inline">\(\frac{(10-1)}{(10+2)}=\frac{9}{12}=\frac{3}{4}=0,75\)</span>). Esto, de alguna manera, nos da cierta garantía de que aún con una muestra relativamente pequeña es posible identificar correctamente los patrones evolutivos de la población.</p>
<p>Una de las aplicaciones del modelo coalescente tiene que ver con el supuesto de tamaño poblacional constante. Como la sucesión de intervalos de coalescencia (la esperanza) depende del tamaño poblacional, ecuación <a href="deriva.html#eq:coale6">(3.52)</a>, una reducción del tamaño poblacional, por ejemplo a la mitad implicaría también reducir a la mitad el tiempo esperado, o lo que es lo mismo duplicar la velocidad de aparición de estos eventos. Esto tiene dos aristas. Por un lado, si de otra forma conseguimos reconstruir un árbol de alelos, por ejemplo a partir de las secuencias y comparamos los dos árboles, el del coalescente y el molecular (sumado a otra información, usualmente biológica o histórica) podemos en algunos casos asignar estas discrepancias a fluctuaciones del tamaño poblacional. Por el otro lado, si conocemos alguna función del tamaño poblacional en función del tiempo, <span class="math inline">\(N(t)\)</span>, y suponemos por ejemplo que el tiempo en una nueva escala ficticia <span class="math inline">\(\tau\)</span> pasa proporcional a <span class="math inline">\(\frac{N(t)}{N(0)}\)</span> (con <span class="math inline">\(N(0)\)</span> el tamaño poblacional actual), tenemos que para pequeños intervalo de tiempo ficticio</p>
<p><span class="math display" id="eq:coale13">\[\begin{equation}
d\tau = \frac{N(0)}{N(t)} dt
\tag{3.59}
\end{equation}\]</span></p>
<p>por lo que</p>
<p><span class="math display" id="eq:coale14">\[\begin{equation}
\tau = \int d\tau= \int \frac{N(0)}{N(t)} dt = N(0) \int \frac{1}{N(t)} dt
\tag{3.60}
\end{equation}\]</span></p>
<p>O sea, si conocemos una función que nos relacione el tamaño de la población en el tiempo y su inversa es integrable, entonces tenemos una forma de hacer nuestro coalescente independiente del tamaño poblacional. Veamos un ejemplo. El crecimiento exponencial de una población (por ejemplo, las poblaciones bacterianas al comienzo de la etapa de multiplicación) está dado por una función del tiempo de tipo <span class="math inline">\(N_t=N_0 e^{gt}\)</span>, cuando el tiempo va hacia adelante. Ahora, en nuestro caso el tiempo va hacia atrás (en la generación <span class="math inline">\(0\)</span>, <span class="math inline">\(N(0)\)</span> es la población ya crecida al nivel actual y en tiempo <span class="math inline">\(t\)</span> hacia atrás, <span class="math inline">\(N(t)\)</span> es mucho menor en tamaño), por lo que el exponente debe ser negativo</p>
<p><span class="math display" id="eq:coale15">\[\begin{equation}
N(t)=N(0) e^{-gt}
\tag{3.61}
\end{equation}\]</span></p>
<p>Ahora, si sustituimos esta función del tamaño poblacional en <a href="deriva.html#eq:coale14">(3.60)</a> e integramos tenemos que</p>
<p><span class="math display" id="eq:coale16">\[\begin{equation}
\tau = \int_0^t \frac{N(0)}{N(t)} dt = \int_0^t \frac{N(0)}{N(0) e^{-gt}} dt = \int_0^t e^{gt} dt = \frac{1}{g}e^{gt} \bigg\rvert_{t=0}^t = \frac{1}{g} (e^{gt}-1)
\tag{3.62}
\end{equation}\]</span></p>
<p>Despejando <span class="math inline">\(t\)</span> de la ecuación <a href="deriva.html#eq:coale16">(3.62)</a>, tenemos que</p>
<p><span class="math display" id="eq:coale17">\[\begin{equation}
t = \frac{\ln{(1+g\tau)}}{g} 
\tag{3.63}
\end{equation}\]</span></p>
<p>Ahora, para terminar alcanza con generar un modelo coalescente con tamaño fijo igual al inicial <span class="math inline">\(N(0)\)</span> y luego re-escalar los tiempos de acuerdo la ecuación <a href="deriva.html#eq:coale17">(3.63)</a>.</p>
<div class="graybox">
<div class="center">
<p><strong>PARA RECORDAR</strong></p>
</div>
<ul>
<li>En organismos diploides, en poblaciones de N individuos, la probabilidad de coalescer de dos alelos en la generación anterior es</li>
</ul>
<p><span class="math display">\[\begin{equation}
\mathbb{Pr}(\text{coalescer})=\frac{k(k-1)}{4N}
\end{equation}\]</span></p>
<ul>
<li>Como los eventos de coalescencia en cada generación son independientes de la previa, el tiempo a la coalescencia (<span class="math inline">\(u_k\)</span>) tiene distribución geométrica, usualmente aproximada por una distribución exponencial con tasa inversa a la probabilidad de coalescer por generación, es decir</li>
</ul>
<p><span class="math display">\[\begin{equation}
\mathbb{E}(u_k)=\frac{4N}{k(k-1)}
\end{equation}\]</span></p>
<ul>
<li><p>Como además en cada evento de coalescencia <span class="math inline">\(k\)</span> se reduce en uno, los tiempos hacia atrás serán cada vez más largos.</p></li>
<li><p>El tamaño poblacional juega un papel muy importante en los tiempos de coalescencia (está en el numerador de la esperanza), por lo que si el mismo varía a lo largo del tiempo entonces no se cumple uno de los supuestos fundamentales del coalescente. Sin embargo, en los casos en que el tamaño poblacional es una función del tiempo cuya inversa sea integrable, es posible aplicar una transformación del tiempo tal que se puede trabajar en esta escala temporal ficticia con el coalescente sin modificar.</p></li>
</ul>
</div>
<hr />
</div>
<div id="ejercicios-3" class="section level2 unnumbered">
<h2>Ejercicios</h2>
<div id="ejercicio-3.1" class="section level4 unnumbered">
<h4>Ejercicio 3.1</h4>
<p>¿Cuál es la probabilidad de que un alelo del que existe una sola copia
entre todos los <span class="math inline">\(N\)</span> individuos diploides desaparezca en la siguiente
generación? Grafica la función para N entre 1 y 20 individuos. (adaptado de Gillespie)</p>
<p><strong><em>Solución</em></strong></p>
<p>Si asumimos el modelo de Wright-Fisher, la probabilidad de elegir este
alelo en una extracción al azar es de <span class="math inline">\(\frac{1}{2N}\)</span> ya que hay una sola
copia en un total de <span class="math inline">\(2N\)</span> alelos. Por lo tanto, la posibilidad de que no
resulte elegido en una vez es igual a <span class="math inline">\(1-\frac{1}{2N}\)</span>. Como el modelo
de Wright-Fisher implica reponer el alelo que se extrajo para volver a
hacer el sorteo, la elección de los alelos que conformaran la próxima
generación será el resultado de repetir este proceso en forma
independiente <span class="math inline">\(2N\)</span> veces, es decir el resultado de multiplicar
<span class="math inline">\(1-\frac{1}{2N}\)</span> por si mismo <span class="math inline">\(2N\)</span> veces, o lo que es lo mismo
<span class="math inline">\((1-\frac{1}{2N})^{2N}\)</span>. A medida de que N crece este número se aproxima
a <span class="math inline">\(1/e \sim 0,367879\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ejercicio3p1"></span>
<img src="ApuntesGeneticaII_files/figure-html/ejercicio3p1-1.png" alt="Probabilidad de perder un alelo de copia única en función del número de individuos en la población. En rojo la probabilidad $1/e$." width="672" />
<p class="caption">
Figure 3.17: Probabilidad de perder un alelo de copia única en función del número de individuos en la población. En rojo la probabilidad <span class="math inline">\(1/e\)</span>.
</p>
</div>
</div>
<div id="ejercicio-3.2" class="section level4 unnumbered">
<h4>Ejercicio 3.2</h4>
<p>Un productor rural aficcionado a la conservación de razas vacunas posee un rodeo de la raza Texas Longhorn (figura <a href="deriva.html#fig:TexasLonghorn">3.18</a>), que formó a partir de 300 hembras y 300 machos de distintas poblaciones en EEUU. Luego de 3 generaciones (asumimos que no solapantes, aunque no sea muy realista), debió vender el <span class="math inline">\(80\%\)</span> de los animales (misma cantidad de machos y hembras), a parti de los cuál volvió a expandirse lentamente hasta alcanzar el número anterior de animales. Le evolución del número de animales a sido entonces, desde el comienzo: 600, 600, 600, 120, 200, 320, 450 y 600. ¿Cuál es el tamaño efectivo promedio de esta población? Desde el punto de vista genético, ¿se recuperó en la última generación la diversidad existente en la generación inicial?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:TexasLonghorn"></span>
<img src="figuras/TexasLonghorn.png" alt="Vaca de la raza Texas Longhorn, entre Bryan y Houston, Texas, EEUU (tomada de Wikipedia, autor Ed Schipul, CC BY-SA 2.0)." width="813" />
<p class="caption">
Figure 3.18: Vaca de la raza Texas Longhorn, entre Bryan y Houston, Texas, EEUU (tomada de Wikipedia, autor Ed Schipul, CC BY-SA 2.0).
</p>
</div>
<p><strong><em>Solución</em></strong></p>
<p>El tamaño efectivo promedio de una población que fluctua en el número de individuos reproductivos lo calculamos a partir de la media armónica entre el número de individuos a cada generación. Es decir,</p>
<p><span class="math display">\[\begin{equation}
N_e=\frac{t}{\left(\frac{1}{N_0}+\frac{1}{N_1}+\frac{1}{N_2}+...+\frac{1}{N_{t-1}} \right)}
\end{equation}\]</span></p>
<p>con <span class="math inline">\(t\)</span> el número de generaciones, lo que en nuestro caso se transforma en:</p>
<p><span class="math display">\[\begin{equation}
N_e=\frac{8}{\left(\frac{1}{600}+\frac{1}{600}+\frac{1}{600}+\frac{1}{120}+\frac{1}{200}+\frac{1}{320}+\frac{1}{450}+\frac{1}{600}\right)} =\frac{8}{0,02534722}=315,6164 \approx 316 \text{ animales}
\end{equation}\]</span></p>
<p>Es decir, el tamaño efectivo de la población es ahora de <span class="math inline">\(\approx 316\)</span> animales, pese a que el tamaño censal es de 600. Claramente, no se recuperó la diversidad genética que se perdió por el cuello de botella experimentado.</p>
</div>
<div id="ejercicio-3.3" class="section level4 unnumbered">
<h4>Ejercicio 3.3</h4>
<p>La media armónica representa un buen indicador del tamaño efectivo poblacional cuando el número de individuos reproductivos fluctua entre generaciones, a diferencia de la media aritmética (el promedio usual). ¿Se comportan igual la media aritmética y la media armónica con respecto a los valores extremos (<strong>ouliers</strong>)? ¿Cuál es más sensible a los <strong>outliers</strong>? ¿Son ambas medias simétricas con respecto a desviaciones de un solo valor hacia arriba y hacia abajo del conjunto de los otros valores?</p>
<p><strong><em>Solución</em></strong></p>
<p>La media armónica es mucho menos sensible a valores extremos hacia arriba del promedio que hacia abajo. Es decir, su sensibilidad es mucho mayor a valores pequeños que a valores altos. En cambio, la media aritmética es simétrica en este respecto. Por ejemplo, consideremos un conjunto de 7 valores iguales (100 cada uno) y uno distinto, primero con una desviación de 80 hacia arriba y luego de 80 hacia abajo. Es decir nuestros dos juegos serán (100,100,100,100,100,100,100,180) y (100,100,100,100,100,100,100,20). En el primer juego,</p>
<p><span class="math display">\[\begin{equation}
H=\frac{n}{\sum_{i=1}^n \frac{1}{x_i}}=\frac{8}{7 \cdot \frac{1}{100} + \frac{1}{180}} \approx 105,9
\end{equation}\]</span></p>
<p>mientras que en el segundo</p>
<p><span class="math display">\[\begin{equation}
H=\frac{n}{\sum_{i=1}^n \frac{1}{x_i}}=\frac{8}{7 \cdot \frac{1}{100} + \frac{1}{20}} \approx 66,7
\end{equation}\]</span></p>
<p>Es decir, la media armónica <span class="math inline">\(H\)</span> se desvía <span class="math inline">\(5,9\)</span> unidades hacia arriba en el primer caso y <span class="math inline">\(33,7\)</span> unidades en el segundo, pese a que los datos <strong>outliers</strong> se desviaron en ambos caso 80 unidades (arriba primero, abajo en el segundo). Sin embargo, la media aritmética fue igual a <span class="math inline">\(\mu=\frac{\sum_{i=1}^n x_i}{n}=110\)</span> en el primer caso y <span class="math inline">\(\mu=\frac{\sum_{i=1}^n x_i}{n}=90\)</span> en el segundo, ambos desvíos de <span class="math inline">\(10\)</span> unidades hacia arriba o hacia abajo acompañando a los datos.</p>
</div>
<div id="ejercicio-3.4" class="section level4 unnumbered">
<h4>Ejercicio 3.4</h4>
<p>Para una población de 250 individuos diploides, ¿cuáles serán los tiempos sucesivos de coalescencia de 6 alelos (expresados en generaciones)? Si el intervalo generacional es de 20 años, ¿cuántos años se precisan para llegar a la coalescencia de todos los alelos?</p>
<p><strong><em>Solución</em></strong>
Utilizando la ecuación <a href="deriva.html#eq:coale6">(3.52)</a>, tenemos que la <span class="math inline">\(\mathbb{E}(u_k)=4N/[k(k-1)]\)</span>, por lo que para <span class="math inline">\(k=6\)</span> alelos y <span class="math inline">\(N=250\)</span> individuos, el número esperado de generaciones hasta el primer evento coalescente será</p>
<p><span class="math display">\[\begin{equation}
\mathbb{E}(u_k)=\frac{4N}{k(k-1)}=\frac{1000}{6 \cdot 5}=\frac{1000}{30} \approx 33,3 \text{ generaciones}
\end{equation}\]</span></p>
<p>Aplicando la misma ecuación y disminuyendo <span class="math inline">\(k\)</span> en <span class="math inline">\(1\)</span> alelo cada vez, tenemos la sucesión de intervalos, <span class="math inline">\((T_6;T_5;T_4;T_3;T_2)=(33,3; 50; 83,3; 166,7; 500)\)</span>. Si ahora sumamos esos intervalo tenemos en tiempo total al primer coalescente, es decir <span class="math inline">\(33,3+50+83,3+166,7+500=833,3\)</span> generaciones.</p>
<p>Alternativamente, para el tiempo total podríamos haber aplicado la ecuación <a href="deriva.html#eq:coale11">(3.57)</a> para obtener</p>
<p><span class="math display">\[\begin{equation}
t=4N(1-\frac{1}{k})=1000 (1-\frac{1}{6})=1000 \frac{5}{6} \approx 833,3 \text{ generaciones}
\end{equation}\]</span></p>
<p>Para obtener el tiempo esperado en años basta multiplicar este número de generacions por el intervalo entre generacion, 20 años, para obtener que el mismo es igual a <span class="math inline">\(833,3 \text{ generaciones} \cdot 20 \text{ años/generación}=16667 \text{ años}\)</span>.</p>
</div>
<div id="ejercicio-3.5" class="section level4 unnumbered">
<h4>Ejercicio 3.5</h4>
<p><strong><em>Solución</em></strong></p>
<hr />

</div>
</div>
</div>
<h3>Bibliografía</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-CharlesworthLandeSlatkin1982" class="csl-entry">
Charlesworth, Brian, Russel Lande, and Montgomery Slatkin. 1982. <span>“A Neo-Darwinian Commentary on Macro Evolution.”</span> <em>Evolution</em> 36 (3): 474–98.
</div>
<div id="ref-DennyGaines2000" class="csl-entry">
Denny, Mark, and Steven Gaines. 2000. <em>Chance in Biology: Using Probability to Explore Nature</em>. Princeton University Press.
</div>
<div id="ref-Felsenstein2004" class="csl-entry">
Felsenstein, Joseph. 2004. <em>Inferring Phylogenies</em>. Sinauer Associates, Inc.
</div>
<div id="ref-Hamilton2009" class="csl-entry">
Hamilton, Matthew B. 2009. <em>Population Genetics</em>. Wiley-Blackwell.
</div>
<div id="ref-HartlClark2007" class="csl-entry">
Hartl, Daniel L, and Andrew G Clark. 2007. <em>Principles of Population Genetics</em>. 4th. ed. Sinauer.
</div>
<div id="ref-Kimura1962" class="csl-entry">
Kimura, M. 1962. <span>“<span class="nocase"><span>O</span>n the probability of fixation of mutant genes in a population</span>.”</span> <em>Genetics</em> 47 (June): 713–19.
</div>
<div id="ref-KimuraOhta1969" class="csl-entry">
Kimura, M., and T. Ohta. 1969. <span>“<span class="nocase"><span>T</span>he <span>A</span>verage <span>N</span>umber of <span>G</span>enerations until <span>F</span>ixation of a <span>M</span>utant <span>G</span>ene in a <span>F</span>inite <span>P</span>opulation</span>.”</span> <em>Genetics</em> 61 (3): 763–71.
</div>
<div id="ref-Kingman1982a" class="csl-entry">
Kingman, JFC. 1982a. <span>“On the Genealogy of Large Populations.”</span> <em>Journal of Applied Probability</em> 19A: 27–43.
</div>
<div id="ref-Kingman1982b" class="csl-entry">
———. 1982b. <span>“The Coalescent.”</span> <em>Stochastic Processes and Their Applications</em> 13: 235–48.
</div>
<div id="ref-RosenbergNordborg2002" class="csl-entry">
Rosenberg, N. A., and M. Nordborg. 2002. <span>“<span class="nocase"><span>G</span>enealogical trees, coalescent theory and the analysis of genetic polymorphisms</span>.”</span> <em>Nat Rev Genet</em> 3 (5): 380–90.
</div>
<div id="ref-TaglianiRibeiro2011" class="csl-entry">
Tagliani-Ribeiro, A., M. Oliveira, A. K. Sassi, M. R. Rodrigues, M. Zagonel-Oliveira, G. Steinman, U. Matte, N. J. Fagundes, and L. Schuler-Faccini. 2011. <span>“<span class="nocase"><span>T</span>win <span>T</span>own in <span>S</span>outh <span>B</span>razil: a <span>N</span>azi’s experiment or a genetic founder effect?</span>”</span> <em>PLoS One</em> 6 (6): e20328.
</div>
<div id="ref-Tajima1983" class="csl-entry">
Tajima, F. 1983. <span>“Evolutionary Relationship of DNA Sequences in Finite Populations.”</span> <em>Genetics</em> 105 (2): 437–60.
</div>
<div id="ref-WalshLynch2018" class="csl-entry">
Walsh, Bruce, and Michael Lynch. 2018. <em>Evolution and Selection of Quantitative Traits</em>. Oxford University Press.
</div>
<div id="ref-wright1922" class="csl-entry">
Wright, Sewall. 1922. <span>“<span class="nocase">Coefficients of inbreeding and relationship</span>.”</span> <em>American Naturalist</em> 56: 330–38.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>Gregor Mendel (20 de julio 1822 - 6 de enero de 1884) fue un meteorólogo, biólogo y matemático, nacido en Heizendorf bei Odrau, Imperio Austro-Húngaro (hoy República Checa). Considerado el padre de la “genética moderna,” realizó diversos experimentos con plantas que lo llevaron a postular algunas “leyes,” decenas de años antes de conocerse las bases moleculares de la herencia.<a href="deriva.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Sewall Green Wright (21 de diciembre, 1889 - 3 marzo, 1988), fue
un genetista que realizó notables aportes sobre los efectos de la
selección y la deriva, así como el análisis de pequeñas poblaciones
y el efecto de la consanguinidad . Junto a Ronald A. Fisher y JBS
Haldane establecieron la fundación matemática de la genética de
poblaciones y de la teoría evolutiva.<a href="deriva.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Sir Ronald Aylmer Fisher (17 de febrero 1890 - 29 de julio 1962) fue un matemático, estadístico y biológo evolutivo inglés. A partir de los datos colectados en la Estación Experimental de Rothamsted desarrollo las bases estadísticas para el diseño de experimentos, desarrollo también el análisis de varianza y fue unos de los tres pioneros (junto a Sewall Wright y John Burdon Sanderson Haldane) que participaron de la fundación de la teoría en genética de poblaciones, el neo-darwinismo y la síntesis moderna de la evolución.<a href="deriva.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Jacob Bernoulli (6 de enero 1655 - 16 de agosto 1705) fue un matemático Suizo que realizó diversos descubrimientos importante y uno de promotores tempranos del cálculo integral. Miembro de las academias reales de París y Berlín, la distribución lleva su nombre en homenaje a sus contribuciones.<a href="deriva.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Andrey Andreyevich Markov (14 de junio 1856 – 20 de julio 1922) fue un matemático ruso, ampliamente conocido por sus trabajos en procesos estocásticos.<a href="deriva.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Debido al matemático soviético Andrey Nikolaevich Kolmogorov (25 April 1903 -
20 October 1987). Si bien la ecuación hacia atrás (Kolmogorov Backward Equation) fue un aporte completamente novedoso, la ecuación hacia adelante ya era conocida para los físicos como la ecuación de Fokker-Planck.<a href="deriva.html#fnref21" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variación-y-equilibrio-de-hardy-weinberg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="seleccion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-deriva.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ApuntesGeneticaII.pdf", "ApuntesGeneticaII.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
